[TOC]

# zookeeper

&emsp;&emsp;是一个基于观察者模式设计的分布式服务管理框架，它负责存储和管理客户端关心的数据(例如哪台服务器存储了我需要调用的接口)，然后接受服务端的注册，一旦服务端数据或状态发生变化，Zookeeper就将负责通知在 Zookeeper 上注册的客户端，客户端可以利用这些信息来做出反应。服务器上下线就是在 Zookeeper 中创建和删除节点的动作。对于 Zookeeper 集群来说，服务器与客户端都是客户端，只不过服务器是创建节点，而客户端是负责监听。

![](https://raw.githubusercontent.com/MrSunflowers/images/main/note/images/202204072248175.png)

# zookeeper 集群

1. Zookeeper 集群：由一个领导者（Leader），多个跟随者（Follower）组成，Leader 负责集群状态的更新，这样就不会因为多台服务器同时更新数据导致的数据不一致性问题，主从复制，读写分离。
2. 集群中只要有半数以上节点存活，Zookeeper 集群就能正常服务。所以Zookeeper 适合**安装奇数台服务器**，例如集群 6 台服务器，与 5 台服务器效果相同，都是挂 3 台服务器即集群不可用。
3. 全局数据一致：每个 Zookeeper Server 保存一份相同的数据副本，Client 无论连接到哪个 Zookeeper Server，数据都是一致的。
4. 更新请求顺序执行，来自同一个 Client 的更新请求按其发送顺序依次执行。
5. 数据更新原子性，一次数据更新要么成功，要么失败。
6. 实时性，在一定时间范围内，Client 能读到最新数据。

# zookeeper 数据结构

&emsp;&emsp;ZooKeeper 数据模型的结构与 Unix 文件系统很类似，整体上可以看作是一棵树，每个节点称做一个 ZNode。每一个 ZNode 默认能够存储 1MB 的数据(小的数据量可以保证集群数据同步的速度)，每个 ZNode 都可以通过其路径唯一标识。

# zookeeper 应用场景

- 统一命名服务![](https://raw.githubusercontent.com/MrSunflowers/images/main/note/images/202204062132282.png)
- 统一配置管理![](https://raw.githubusercontent.com/MrSunflowers/images/main/note/images/202204062134619.png)
- 统一集群管理![](https://raw.githubusercontent.com/MrSunflowers/images/main/note/images/202204062134489.png)
- 服务器节点动态上下线![](https://raw.githubusercontent.com/MrSunflowers/images/main/note/images/202204062135276.png)
- 软负载均衡![](https://raw.githubusercontent.com/MrSunflowers/images/main/note/images/202204062135316.png)

# zookeeper 选举机制

&emsp;&emsp;首先，每个 zookeeper 节点都有三个节点值：

- SID：服务器ID。用来唯一标识一台 ZooKeeper 集群中的机器，每台机器不能重复，和myid一致。
- ZXID：事务ID。ZXID是一个事务ID，用来标识一次服务器状态的变更。在某一时刻，集群中的每台机器的 ZXID 值不一定完全一致，这和 ZooKeeper 服务器对于客户端“更新请求”的处理逻辑有关。
- Epoch：每个 Leader 任期的代号。没有 Leader 时同一轮投票过程中的逻辑时钟值是相同的。每投完一次票这个数据就会增加

&emsp;&emsp;假设现在有 5 台服务器

## 第一次启动

&emsp;&emsp;服务器优先投票给自己

- 服务器1启动，发起一次选举。服务器1投自己一票。此时服务器 1 票数一票，不够半数以上（3票），选举无法完成，服务器1状态保持为观察状态 LOOKING；
- 此时服务器2启动，再发起一次选举。也投自己一票，然后与服务器 1 交换选票信息：交换过程中服务器 1 发现服务器 2 的服务器 ID 比自己大，更改选票，将自己手中的选票投给服务器 2。此时服务器 1 票数 0 票，服务器 2 票数 2 票，没有达到半数以上结果，选举无法完成，服务器1，2都状态保持LOOKING
- 接下来服务器3启动，发起一次选举。流程与服务器2相同，也是先投给自己，然后与其他服务器交换选票信息，此时服务器 1 和 2 都会更改选票为服务器 3。此次投票结果：服务器 1 为 0 票，服务器 2 为 0 票，服务器 3 为 3 票。此时服务器 3 的票数已经超过半数，服务器 3 当选Leader。服务器 1，2 更改状态为 FOLLOWING，服务器 3 更改状态为LEADING；
- 服务器4启动，发起一次选举。交换信息发现服务器 1，2，3 已经不是 LOOKING 状态。此时选票为服务器 3 为 3 票，服务器 4 为 1 票。服务器 4 服从多数，更改选票信息给服务器 3，并更改状态为 FOLLOWING；
- 服务器5启动，同4一样。

## 非第一次启动

&emsp;&emsp;当 ZooKeeper 集群中的一台服务器出现以下两种情况之一时，就会开始进入Leader选举：

1. 服务器初始化启动。
2. 服务器运行期间无法和Leader保持连接。

&emsp;&emsp;而当一台机器进入 Leader 选举流程时，当前集群也可能会处于以下两种状态：

1. 集群中本来就已经存在一个Leader。对于已经存在 Leader 的情况，机器试图去选举 Leader 时，会被告知当前服务器的 Leader 信息，对于该机器来说，仅仅需要和 Leader 机器建立连接，并进行状态同步即可。

2. 集群中确实不存在 Leader。假设 ZooKeeper 由 5 台服务器组成，SID 分别为 1、2、3、4、5，ZXID分别为 8、8、8、7、7，并且此时 SID 为 3 的服务器是 Leader。某一时刻，3 和 5 服务器出现故障，因此开始进行 Leader 选举。

&emsp;&emsp;此时服务器 1、2、4 的状态为：

| 服务器 | EPOCH | ZXID | SID  |
| :----: | :---: | :--: | :--: |
|   1    |   1   |  8   |  1   |
|   2    |   1   |  8   |  2   |
|   3    |   1   |  7   |  4   |

&emsp;&emsp;选举Leader规则 ：

1. EPOCH 大的直接胜出
2. EPOCH 相同，事务 id 大的胜出
3. 事务 id 相同，服务器 id 大的胜出

# 常见问题

## zookeeper 作为注册中心的话，在选举期间不可用如何解决

ZooKeeper 作为服务注册中心时，其高可用性对于依赖它的服务至关重要。如果 ZooKeeper 在选举期间不可用，可能会对依赖它的服务造成影响。以下是一些解决策略：

1. **使用 ZooKeeper 集群**：
   确保使用 ZooKeeper 集群而不是单个节点。ZooKeeper 集群通过选举机制来保证在 Leader 节点故障时，集群能够继续工作。集群中的节点数量应为奇数，以确保在选举期间能够快速达成共识。

2. **配置合适的超时参数**：
   ZooKeeper 的配置参数，如 `initLimit`、`syncLimit` 和 `tickTime`，对选举时间有直接影响。合理配置这些参数可以减少选举时间，从而减少服务不可用的时间。

3. **使用 ZooKeeper 的高可用性特性**：
   ZooKeeper 支持配置多个观察者（Observer）节点，这些节点不参与 Leader 选举，但可以提供读取服务。在选举期间，观察者节点仍然可以提供服务，从而减少服务中断。

4. **客户端重试和连接管理**：
   在客户端实现重试逻辑和连接管理，当检测到 ZooKeeper 连接失败时，客户端可以尝试重新连接。客户端库通常已经内置了重试机制，但也可以根据需要进行自定义。

5. **使用 ZooKeeper 的客户端缓存**：
   ZooKeeper 客户端可以启用缓存，这样即使在连接断开的情况下，客户端也可以继续使用缓存中的数据。这可以减少因 ZooKeeper 不可用而导致的服务中断。

6. **监控和告警**：
   实施监控和告警机制，以便在 ZooKeeper 集群出现问题时能够及时发现并采取措施。监控可以包括节点状态、连接数、延迟等关键指标。

通过上述措施，可以在一定程度上减轻 ZooKeeper 在选举期间不可用对服务的影响，提高系统的整体稳定性和可用性。

## 脑裂

ZooKeeper 的脑裂（Split-Brain）是指在分布式系统中，由于网络分区或其他原因导致集群被分割成两个或多个独立的子集，每个子集都认为自己是合法的集群，并且可以独立地进行操作。这种情况下，可能会出现数据不一致、状态冲突等问题。

脑裂问题在 ZooKeeper 中尤其需要关注，因为 ZooKeeper 依赖于集群中的多数节点来达成一致，以保证数据的一致性和可靠性。如果发生脑裂，可能会导致以下问题：

- 数据不一致：不同的 ZooKeeper 集群子集可能会对数据进行不同的修改，导致数据状态不一致。
- 服务不可用：如果脑裂导致集群无法形成多数派，那么 ZooKeeper 服务可能无法提供正常服务。
- 状态冲突：在脑裂恢复后，需要解决不同集群子集之间的状态冲突，这可能需要复杂的恢复过程。

ZooKeeper 的脑裂问题可以通过以下策略来预防：

1. **网络分区检测**：
   - 使用网络分区检测工具，如 Netflix 的 Curator 框架中的 `PartitionDetector`，来检测网络分区并采取相应措施。

2. **合理配置集群大小**：
   - 避免使用偶数节点的集群，因为偶数节点集群在脑裂发生时更容易形成两个相等大小的子集群，从而导致脑裂。推荐使用奇数节点的集群，如 3、5、7 等。

3. **使用观察者节点**：
   - 在 ZooKeeper 集群中引入观察者节点（Observer），这些节点不参与 Leader 选举，但可以提供读取服务。在脑裂发生时，观察者节点可以继续提供服务，减少服务中断。

4. **客户端重试和连接管理**：
   - 在客户端实现重试逻辑和连接管理，当检测到 ZooKeeper 连接失败时，客户端可以尝试重新连接。

5. **监控和告警**：
   - 实施监控和告警机制，以便在脑裂发生时能够及时发现并采取措施。

6. **使用 ZooKeeper 的客户端缓存**：
   - ZooKeeper 客户端可以启用缓存，这样即使在连接断开的情况下，客户端也可以继续使用缓存中的数据。

7. **服务降级和熔断**：
   - 在服务架构中实现降级和熔断机制，当检测到 ZooKeeper 不可用时，可以暂时切换到降级模式或熔断，以避免服务雪崩。

8. **定期测试和演练**：
   - 定期进行故障演练和测试，确保在真实故障发生时，系统能够按照预期工作。

9. **避免使用过时的 ZooKeeper 版本**：
   - 使用最新版本的 ZooKeeper，因为新版本可能包含针对脑裂问题的改进和修复。

10. **合理配置超时参数**：
    - 调整 ZooKeeper 的 `initLimit`、`syncLimit` 和 `tickTime` 等参数，以确保集群在出现网络延迟时仍能正常工作。

通过上述措施，可以在一定程度上预防 ZooKeeper 的脑裂问题，确保集群的稳定性和数据的一致性。然而，需要注意的是，没有任何系统能够完全避免脑裂的发生，因此关键在于设计和实施能够应对脑裂的策略和机制。

ZooKeeper 在脑裂发生后的应急处理方案需要迅速、准确地执行，以最小化对业务的影响。以下是一些关键步骤和策略：

1. **立即识别脑裂**：
   - 监控系统应能够快速识别脑裂事件。这通常通过 ZooKeeper 的状态监控和日志分析来实现。

2. **隔离问题节点**：
   - 如果可能，应迅速隔离导致脑裂的节点，以防止问题扩散。这可能需要手动干预或通过自动化脚本实现。

3. **恢复通信**：
   - 尽快恢复网络分区，确保集群中的所有节点能够相互通信。这可能涉及网络设备的重新配置或故障排除。

4. **重启集群**：
   - 如果脑裂导致集群无法自动恢复，可能需要重启集群。在重启之前，确保所有节点的状态一致，或者至少能够达成一致。

5. **数据一致性检查**：
   - 在集群恢复后，进行数据一致性检查。如果发现数据不一致，需要根据业务需求和数据重要性来决定如何解决。

6. **恢复服务**：
   - 在确认集群状态稳定后，逐步恢复服务。这可能需要客户端的重试逻辑和连接管理来配合。

7. **分析和修复根本原因**：
   - 脑裂事件发生后，应进行彻底的分析，以确定导致脑裂的根本原因。这可能涉及网络、硬件、配置或软件问题。

8. **更新监控和告警**：
   - 根据脑裂事件的分析结果，更新监控系统和告警策略，以防止类似事件再次发生。

9. **文档和复盘**：
   - 记录脑裂事件的详细信息和处理过程，进行复盘会议，总结经验教训，并更新操作手册和应急预案。

10. **培训和演练**：
    - 对运维团队进行培训，确保他们了解脑裂事件的处理流程和策略。定期进行应急演练，提高团队的响应能力和熟练度。

11. **使用 ZooKeeper 的客户端缓存**：
    - 在客户端实现缓存，这样即使在连接断开的情况下，客户端也可以继续使用缓存中的数据。

12. **服务降级和熔断**：
    - 在服务架构中实现降级和熔断机制，当检测到 ZooKeeper 不可用时，可以暂时切换到降级模式或熔断，以避免服务雪崩。

13. **避免使用过时的 ZooKeeper 版本**：
    - 使用最新版本的 ZooKeeper，因为新版本可能包含针对脑裂问题的改进和修复。

通过这些步骤，可以在脑裂发生后迅速采取行动，减少对业务的影响，并提高系统的整体稳定性和可靠性。







