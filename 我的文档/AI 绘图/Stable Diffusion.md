# 功能分区概览

![c30bbfaf3da6c990761888e7b540d94](https://raw.githubusercontent.com/MrSunflowers/images/main/note/images/202412232245373.png)

Stable Diffusion 作图的基本流程，具体分为以下几个步骤：

1. **模型**：可以选择大模型、LoRA模型、超网络、嵌入式模型等；同时 VAE 也是一种特殊的模型，VAE 就像图片最终的滤镜，有的模型中自带了，就不需要开启 VAE 模型了。
2. **文本**：提供正向提示词和反向提示词。
3. **热图**：提供正向提示词、图生图、局部重绘等。
4. **插件**：可以进行风格、脸部、手部等各种全方位的修改。

这些输入共同作用，通过采样器进行处理。采样器包括CLIP终止层数、随机数种子、采样方法和迭代步数等参数。然后经过 VAE 模型进行图像解码，最终生成所需的图像。

![image-20241223231217014](https://raw.githubusercontent.com/MrSunflowers/images/main/note/images/202412232312192.png)

这张图片展示了Stable Diffusion作图的基本流程，并将其与烹饪过程进行了类比。具体内容如下：

1. **模型=料包**：
   - 大模型=大料包
   - lora模型=小料包
   - 嵌入式=坏掉的部分
   - 模型训练=自制料包

2. **文本=食材**：
   - 正向提示词=好食材
   - 反向提示词=坏食材

3. **热图=样品**：
   - 图生图=整体二次加工
   - 局部重绘=局部二次加工

4. **插件=调整**：
   - 风格、构图、尺寸等
   - 味道、摆盘、大小等

5. **VAE模型=最后一道工序**：
   - VAE模型=浇油

6. **采样器=做菜煲**：
   - CLIP 终止层数=读取做菜要求
   - 随机数种子=做菜指南
   - 采样方法=选择一种做法
   - 迭代步数=做几步完成

![image-20241223231151161](https://raw.githubusercontent.com/MrSunflowers/images/main/note/images/202412232311298.png)

# 采样器

![image-20241223231743907](https://raw.githubusercontent.com/MrSunflowers/images/main/note/images/202412232317975.png)

Stable Diffusion 的作图方式更像是从杂乱的画面中挑选符合我们设置的，将不符合的元素一点点擦除，与人类的作画方式正好相反。

![image-20241223234614584](https://raw.githubusercontent.com/MrSunflowers/images/main/note/images/202412232346682.png)

## CLIP 终止层数

![image-20241223232145328](https://raw.githubusercontent.com/MrSunflowers/images/main/note/images/202412232321541.png)

这张图片展示了不同 CLIP 终止层数（Clip skip）对于生成图像的影响。具体来说：

1. **Clip skip: 1**：最接近提示词，画面表现差强人意。
2. **Clip skip: 3**：提示词与 AI 相互作用，画面表现最好。
3. **Clip skip: 5**：文本描述细节丢失，画面逐渐离谱。
4. **Clip skip: 7**：文本描述细节丢失，画面逐渐离谱。
5. **Clip skip: 9**：与文本描述不相干，画面表现离谱。
6. **Clip skip: 11**：与文本描述不相干，画面表现离谱。

总结：
- 二次元图像：Clip skip 2-3 效果最好。
- 真实图像：Clip skip 1-2 效果最好。
- 因此，Clip skip 2 是最常用的。
- CLIP 值主要影响整体画风，这个数字也是临摹时的重要数据。

## 随机数种子

![image-20241223232541344](https://raw.githubusercontent.com/MrSunflowers/images/main/note/images/202412232325641.png)

随机数种子有两个功能用法

1. 临摹：要实现临摹的效果，则需要保持随机数种子和变异随机数种子保持一致，且变异强度越小越好。
2. 两个随机数种子的融合

上述图片展示了在不同变异强度（Var. strength）下生成图像的变化，以及在不同变异强度下将两个图像融合的结果。

上半部分展示了同一个角色在不同变异强度（从0.0到1.0）下的变化。变异强度越高，图像的变化越大，细节和特征也会有所不同。

下半部分展示了两个图像（一个男孩和一个女孩）的融合结果，分别在不同变异强度（0.1、0.5、0.9）下的效果。随着变异强度的增加，融合图像更倾向于融合图（女孩）的特征。

总结：
1. 随机数种子可以最大限度地保留图像整体特征，是临摹的最重要依据。
2. 变异强度一是调节当前图像的变化强弱。
3. 变异强度二是调节融合图的依照权重，强度越低越能保留当前图特征，强度越高越偏向融合图特征。

从宽度中调整种子和从高度中调整种子功能暂时不稳定，一般不作修改。

## 采样方法

### 采样器分类

1. **传统采样器**
   - Euler, Heun, LMS。
   - 这三个采样器历史悠久，被认为是最简单，但是不太准确的采样器。

2. **祖先采样器，名称中带 a 的**
   - Euler a, DPM2 a, DPM++ 2S a, DPM2 a Karras, DPM++ 2S a Karras。
   - 这些采样器每一步扩散都会加入额外噪声，采样结果很随机，出图不收敛，不容易复现。

3. **官方采样器最初随 sd v1 版本的发布自带的采样器**
   - DDIM, PLMS。
   - DDIM 是第一个采样器，PLMS 则是 DDIM 的替代品，PLMS 快速更快。

4. **DPM 和 DPM++ 系列**
   - DPM2, DPM2 a, DPM++ 2S a, DPM++ 2M, DPM++ SDE, DPM fast, DPM adaptive。
   - DPM 和 DPM++ 系列是2022年发布的采样器，结构相似，但DPM2比DPM 更准确但速度较慢。DPM++ 是对 DPM 的改进，但可能会很慢。

5. **带有 Karras 字样的采样器**
   - LMS Karras, DPM2 Karras, DPM2 a Karras。
   - 这些采样器随着采样步骤的增加，可以减少截断误差。所以说带有 Karras 的采样器一般效果都不错。

6. **UniPC 采样器**
   - UniPC 采样器是2023年发布的新采样器，可在5-10步内实现高质量的出图。速度更快更好。

7. **带有 a 和 SDE 的采样器不收敛**
   - 采样会增大随机噪声，画面效果不稳定，出图多变。

### 采样方法使用总结

1. **万能油 Euler a**
   - 速度快，质量好，但稳定性一般。
   - 步数：15 到 30 步，符合SD默认值20步。
   - 使用建议：因为速度快，很多人使用这个采样器。

2. **二次元效果最好 DPM++ 2M Karras**
   - 速度快，质量好，稳定性高。
   - 步数：20 到 30 步，符合SD默认值20步。
   - 使用建议：被认为是地表最强的采样器之一，目前使用最多。

3. **真实人像效果最好 DPM++ SDE Karras，其次DPM++ SDE**
   - 质量最好，速度慢，稳定性差。
   - 步数：10 到 15 步。
   - 使用建议：因为质量很高，常用于真实人像绘画。

4. **风景效果最好：UniPc，其次DDIM，PtMS**
   - 步数：15 到 25 步。
   - 使用建议：这是一款新款采样器，拥有对比更强、饱和度更高、更锐的特点，适合风景。

**小结：**
1. 稳定的采样器超过30步，没有什么变化，主打稳定；不稳定的采样器，步数高有惊喜，主打高风险高收益。
2. 采样器主要影响：速度、对比度、饱和度、景深等特征。如果色彩不够好看除了另选采样器，也可以另选VAE模型。

## 迭代步数

![image-20241223234421972](https://raw.githubusercontent.com/MrSunflowers/images/main/note/images/202412232344071.png)

这张图片展示了图像去噪的过程，从左到右依次显示了不同迭代步数（Steps）下的效果。具体来说，从左到右分别是1步、6步、11步、16步、21步和26步。

从图片中可以看到，随着迭代步数的增加，图像逐渐从模糊变为清晰，线条从硬朗变为柔和，肢体从怪异变为合理的变化路径。这说明迭代步数越多，图像的去噪效果越好，细节越丰富。

# 模型

## 模型类型及其应用

![image-20241223234927130](https://raw.githubusercontent.com/MrSunflowers/images/main/note/images/202412232349217.png)

这张图片介绍了五种不同的模型及其特点和应用场景：

1. **Stable Diffusion 大模型**
   - 最重要的大模型，基于图像训练、图片容器，提取图片必须的模型，效果最好，常用于控制画风，多个模型调用相当于不同的画师。但模型的文件包都比较大，一般5个G左右，使用起来不够灵活。

2. **VAE 模型**
   - 图像解码器，搭配主模型，对图像进行灰度修复，相当于高饱和度滤镜。部分合并出来的大模型VAE烂掉了，画面会发灰。

3. **T.I.Embedding 嵌入式模型**
   - 负面影响模型，基于关键词训练，一般用于反向提示词，修正人物肢体，适合控制人物角色，但控图能力有限。哩布哩布叫Textual Inversion，是最轻量的模型，一般模型大小只有几十KB。

4. **Hypernetwork 超网络模型**
   - 大多用于控制图像画风，我们可以将其简单理解为低配版的lora，在国内已逐渐被lora所取代，因为它的训练难度很大且应用范围较窄，所以，模型很少。

5. **Lora 模型**
   - 常用于强化角色某个特征，弥补大模型训练慢、不灵活的短板，目前最热门的扩展模型，体积小且控图效果好，文件大小通常在36-144MB。

### 基础算法版本

- V1.5-像素尺寸：512x512dpi
- V2.1-像素尺寸：768x768dpi
- XL1.0-像素尺寸：1024x1024dpi

这张图片提供了一些关于模型下载和使用的相关信息。以下是内容的总结：

### 模型下载

1. https://www.liblib.ai
   - 哇布哇布 国内起步较早的模型网站，模型丰富，可以在线生成图。
2. https://www.esheep.com/
   - 国内新锐模型网站，有作品热榜、站内私信互动等多种创新性功能。
3. https://huggingface.co/tasks
   - 抱脸网，全世界AI研究与模型共享的前沿阵地，专业度强。
4. https://civitai.com
   - C站 全世界最受欢迎的AI绘画模型分享网站。

常见风格：
- 二次元、2.5D、真实系

下载注意：

- 打版图+触发词+生成信息 一起复制

常用后缀：

1. ckpt
2. pt
3. pth
4. safetensors
5. PNG、WEBP图片格式（特殊）

### 模型识别网站

- https://spell.novelai.dev/ 识别模型的类型

安装方法：

- 启动器打开对应的模型文件夹直接丢进去

### 模型显示

1. 打版图的文件夹名与模型保持一致
2. 主模型以及版本

## 大模型

大模型图片的基本风格

只在生成图片与图片融合时使用，其他模型一定和大模型版本一致才可以一起搭配使用

## LoRA 模型

针对大模型生成的图片的某一特征加强，比如细化某个部分的画面，LoRA 模型在点击时以提示词的方式参与运算

## 超网络模型

同 LoRA 模型

## 嵌入式模型

去除某些异常的点，比如残肢

## VAE模型

画面的滤镜风格，运算的最后一步，有的需要有的不需要

## 总结

![image-20241224234024779](https://raw.githubusercontent.com/MrSunflowers/images/main/note/images/202412242340925.png)

这张图片展示了使用Stable Diffusion模型进行图像生成的步骤和方法。以下是具体内容：

### 模型选择
1. **Stable Diffusion模型**
   - **首选大模型**：可以选择不同的模型，如Counterfeit V2.5.safetensors [a074b88]。
   - **主打**：整体风格。

2. **VAE模型**
   - **主打**：画面清晰。

3. **T.I.Embedding嵌入模型**
   - **主打**：修复错误。

4. **Lora模型**
   - **主打**：独立特征。

### 使用方法
- **模型选择区**：注意与大模型对应版本才会显示。
- **混合大模型介入的时机**：可以在0-1之间调整百分比，当前设置为0.8。

### 提示词与触发词
- 在生成图像时，可以在提示词框中添加多个模型触发词。
- **权重值**：范围为0-2，默认值为1，值越大画面越容易失控，有时候可以是负值。

### 示例提示词
```
Dragon,battle,cloud,cloudy sky,glowing,grass,landscape,lens flare,light rays,lightning,monster,no humans,open mouth,outdoors,realistic,sharp teeth
<lora:万字_电影感_龙虎LORAv1.0:0.8>,<lora:绝美华丽脸模型_v1.0:1>
```

### 其他注意事项
- 可以多个模型混合，点选之后会出现现在提示词内，再添加触发词。
- 另外可以修改权重，范围0-2，默认值为1，值越大画面越容易失控，有时候可以是负值。

# 文生图

## 提示词

提示词分为正向提示词和反向提示词

### 提示词语法

- **品质**：质量、相机、光线、渲染器等
- **主语**：主体对象、主要场景
- **细节**：时间、情绪、动作、做什么、色彩、构图等
- **模型**：附加的模型

### 提示词语法注意事项

- 提示词没有绝对的顺序，前面的权重自然高于后面，后面权重也可以随意升降。

![image-20241224234651118](https://raw.githubusercontent.com/MrSunflowers/images/main/note/images/202412242346270.png)

![image-20241224235005680](https://raw.githubusercontent.com/MrSunflowers/images/main/note/images/202412242350882.png)

这张图片展示了SD提示词的玩法和一些符号的使用方法。以下是具体内容：

### 权重符号

- `[提示词]=提示词x0.9倍`
- `{提示词}=提示词x1.05倍`
- `(提示词)=提示词x1.1倍`
- `(提示词:0-1.5)=提示词x0-1.5倍`
- `*` 叠加使用加倍
- `1.5倍之后当心炸图`

### 分隔符号

- `. \ / ! ? % ^ * ; : = \ ~ , 空格 换行`

### 链接符号

- `+`
- `空格 and 空格`

### 迭代符号

- `(狗:猫:0.6) 60%之前是狗，60%之后变猫`

### 示例

图片展示了不同步数（Steps: 1, 4, 8, 12, 16, 20）的生成过程，从一个模糊的图像逐渐变为清晰的猫和狗的图像。

### 小结

1. 稳定的采样器超过30步，没什么变化，主打稳定；不稳定的采样器，步数高有惊喜，主打高风险高收益。
2. 采样器主要影响：速度、对比度、饱和度、景深等特征，如果色彩不够好看除了另选采样器，也可以另选VAE模型。