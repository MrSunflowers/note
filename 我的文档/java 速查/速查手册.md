[TOC]

# java 基础

## 什么是B/S架构？什么是C/S架构

B/S架构和C/S架构是两种常见的软件架构模式，它们分别代表了不同的软件系统设计和部署方式。

1.  C/S架构（Client/Server Architecture）：
    C/S架构是一种客户端/服务器架构，它将应用程序分为两个部分：客户端（Client）和服务器（Server）。在这种架构中，客户端负责用户界面的展示和用户交互，而服务器则负责数据的存储、处理和管理。客户端和服务器之间通过网络进行通信。

C/S架构的优点包括：

*   性能较好：客户端通常会处理一些本地的计算任务，减轻服务器的负担，从而提高整体性能。
*   用户体验好：客户端可以提供丰富的用户界面和交互体验。
*   安全性较高：由于数据处理主要在服务器端进行，客户端通常不直接处理敏感数据，因此安全性相对较高。

C/S架构的缺点包括：

*   维护成本高：客户端需要在每个用户的设备上安装和更新，增加了维护成本。
*   可扩展性差：随着用户数量的增加，服务器端的负载可能会成为瓶颈。
*   跨平台能力有限：客户端通常需要为不同的操作系统开发不同的版本。

1.  B/S架构（Browser/Server Architecture）：
    B/S架构是一种浏览器/服务器架构，它将应用程序分为三个部分：浏览器（Browser）、Web服务器（Web Server）和数据库服务器（Database Server）。在这种架构中，用户通过浏览器访问Web服务器，Web服务器再与数据库服务器交互，获取数据并返回给浏览器。

B/S架构的优点包括：

*   易于部署和维护：用户只需通过浏览器访问，无需在客户端安装任何软件，降低了维护成本。
*   跨平台能力强：只要浏览器支持，就可以在不同的操作系统上运行。
*   可扩展性好：通过增加服务器或使用负载均衡技术，可以轻松应对用户数量的增加。

B/S架构的缺点包括：

*   性能可能受限：由于所有处理都在服务器端进行，如果服务器性能不足，可能会导致响应速度变慢。
*   安全性问题：由于数据处理和存储都在服务器端，如果服务器安全措施不足，可能会面临数据泄露的风险。

随着互联网技术的发展，B/S架构因其易用性和灵活性而越来越受到青睐，尤其在Web应用和移动应用领域。然而，C/S架构在需要高性能和复杂交互的应用场景中仍然有其独特的优势。

## Java的数据结构有那些？

Java语言提供了丰富的数据结构，这些数据结构主要包含在`java.util`包中。以下是一些常用的Java数据结构：

1.  **集合框架（Collection Framework）**：
    *   **List**：有序集合，允许重复元素。
        *   `ArrayList`：基于数组实现，随机访问速度快，增删操作慢。
        *   `LinkedList`：基于链表实现，增删操作速度快，随机访问速度慢。
        *   `Vector`：类似于ArrayList，但它是线程安全的。
        *   `Stack`：继承自Vector，实现了一个后进先出（LIFO）的栈。
    *   **Set**：不允许重复元素的集合。
        *   `HashSet`：基于哈希表实现，无序，允许null值。
        *   `LinkedHashSet`：基于HashSet，维护元素插入顺序。
        *   `TreeSet`：基于红黑树实现，元素自动排序。
    *   **Queue**：队列，先进先出（FIFO）的数据结构。
        *   `LinkedList`：实现了Queue接口，可以作为队列使用。
        *   `PriorityQueue`：基于优先级堆的无界队列，元素按照自然顺序或自定义比较器排序。
        *   `ArrayDeque`：基于数组实现的双端队列，可以作为栈或队列使用。

2.  **映射（Map）**：
    *   `HashMap`：基于哈希表实现，允许null键和null值，无序。
    *   `LinkedHashMap`：继承自HashMap，维护元素的插入顺序或访问顺序。
    *   `TreeMap`：基于红黑树实现，元素自动排序。
    *   `Hashtable`：类似于HashMap，但它是线程安全的，不允许null键和null值。
    *   `Properties`：继承自Hashtable，用于处理属性文件。

3.  **其他数据结构**：
    *   `BitSet`：表示一个位向量，可以进行位操作。
    *   `EnumSet`：用于枚举类型的集合，内部实现为位向量。
    *   `Stack`：继承自Vector，实现了一个后进先出（LIFO）的栈。
    *   `PriorityQueue`：实现了一个优先队列，可以按照元素的自然顺序或自定义比较器进行排序。

Java的集合框架提供了强大的数据结构支持，使得开发者可以根据不同的需求选择合适的数据结构来实现算法和应用。此外，Java 8及以后的版本还引入了流（Stream）API，可以对集合进行函数式编程风格的操作。

## instanceof 关键字的作用

`instanceof` 关键字在Java中用于在运行时检查对象是否是特定类的实例。它通常用于类型检查，以确保在进行类型转换之前对象确实是期望的类型。

**`instanceof` 的作用：**

1.  **类型检查**：`instanceof` 可以用来判断一个对象是否是某个类的实例，或者是否实现了某个接口。
2.  **安全的类型转换**：在进行类型转换之前，使用 `instanceof` 可以确保转换是安全的，避免抛出 `ClassCastException`。
3.  **多态性**：在多态的场景中，`instanceof` 可以帮助确定对象的实际类型，从而执行特定类型的方法。

示例代码：

```java
Object obj = new Integer(10);
if (obj instanceof Integer) {
    Integer i = (Integer) obj;
    System.out.println("obj is an Integer: " + i);
} else {
    System.out.println("obj is not an Integer");
}
```

**`instanceof` 的禁忌：**

1.  **过度使用**：过度使用 `instanceof` 可能意味着设计上的问题。如果需要频繁地检查对象类型，可能需要重新考虑设计，使用多态和接口来减少类型检查的需求。
2.  **隐藏的类型转换**：在 `instanceof` 检查之后，如果总是进行类型转换，可能会隐藏潜在的 `ClassCastException`。应该确保类型转换是安全的，并且在转换后进行适当的错误处理。
3.  **滥用多态**：虽然 `instanceof` 可以帮助处理多态，但滥用多态可能会导致代码难以理解和维护。应该在必要时使用，而不是在所有可能的情况下都使用。
4.  **避免在继承层次结构中使用**：在继承层次结构中，如果需要判断一个对象是否是某个特定子类的实例，这可能表明设计上的问题。应该考虑使用接口或抽象类来定义共同的行为。

**最佳实践：**

*   **使用接口和抽象类**：尽量使用接口和抽象类来定义行为，而不是依赖于具体的类。
*   **利用多态**：在可能的情况下，使用多态来减少类型检查的需求。
*   **重构代码**：如果发现代码中频繁使用 `instanceof`，考虑重构代码，以减少类型检查的需要。
*   **异常处理**：在进行类型转换后，应该处理可能抛出的 `ClassCastException`。

instanceof 严格来说是 Java 中的一个双目运算符，用于在运行时判断对象是否为特定类的实例，或者是否实现了特定接口。它通常用于类型检查，以确保在进行类型转换之前对象确实是期望的类型。

**`instanceof` 运算符的语法：**

```java
(对象) instanceof (类或接口)
```

**`instanceof` 的注意事项：**

1.  **左侧必须是对象引用**：`instanceof` 运算符的左侧必须是一个对象引用，不能是基本数据类型。
2.  **右侧必须是类或接口**：`instanceof` 运算符的右侧必须是一个类或接口的名称。
3.  **返回值类型**：`instanceof` 运算符的返回值是一个布尔值（`true` 或 `false`），表示左侧的对象是否是右侧类或接口的实例。
4.  **可以用于多态**：`instanceof` 可以用于多态场景，判断对象是否是某个类的实例，或者是否实现了某个接口。

**`instanceof` 的限制：**

*   **不能用于基本数据类型**：`instanceof` 不能用于基本数据类型，如 `int`、`double` 等。
*   **不能用于检查数组类型**：虽然数组在 Java 中是对象，但 `instanceof` 不能用于检查数组类型。应该使用 `array.getClass().isArray()` 或 `array instanceof Object[]` 等方法来检查数组类型。
*   **不能用于检查是否为 null**：`instanceof` 运算符不能用于检查对象是否为 `null`。如果左侧的对象是 `null`，`instanceof` 运算的结果将总是 `false`。

总之，`instanceof` 是Java中一个有用的工具，但应该谨慎使用，避免过度依赖它来处理类型检查和转换。在设计时，应该优先考虑使用多态和接口来减少对 `instanceof` 的依赖。

## 什么是拆装箱？

在Java中，拆箱（Unboxing）和装箱（Boxing）是自动类型转换的过程，它们涉及到基本数据类型（如int, double等）和它们对应的包装类（如Integer, Double等）之间的转换。

装箱（Boxing）

装箱是指将基本数据类型转换为对应的包装类的过程。Java提供了自动装箱机制，允许在需要时自动将基本数据类型转换为包装类。例如，将一个int类型的值赋给一个Integer类型的变量时，Java会自动进行装箱操作。

```java
int i = 10;
Integer integer = i; // 自动装箱
```

拆箱（Unboxing）

拆箱是指将包装类转换回基本数据类型的过程。同样，Java也提供了自动拆箱机制，允许在需要时自动将包装类转换为基本数据类型。例如，将一个Integer类型的对象赋值给一个int类型的变量时，Java会自动进行拆箱操作。

```java
Integer integer = 10; // 自动装箱
int i = integer; // 自动拆箱
```

使用场景

装箱和拆箱在Java中非常常见，特别是在集合框架（如List, Set, Map等）中使用包装类作为元素类型时。例如，当你将一个Integer对象添加到一个List\<Integer>中时，实际上是在使用自动装箱。

```java
List<Integer> list = new ArrayList<>();
list.add(10); // 自动装箱
```

注意事项

*   **性能影响**：虽然自动装箱和拆箱为编程带来了便利，但它们在性能上是有开销的。在大量数据处理或性能敏感的场景中，应尽量避免不必要的装箱和拆箱操作。
*   **空指针异常**：在拆箱操作中，如果包装类对象为null，尝试拆箱会抛出`NullPointerException`。

```java
Integer integer = null;
int i = integer; // 这里会抛出NullPointerException
```

*   **类型安全**：自动装箱和拆箱可能会导致类型不安全的问题，特别是在使用泛型时。例如，`List<Integer>`和`List<Double>`在泛型上是不兼容的，尽管它们都是`Number`的子类。

\*\*在Java中，如果尝试对一个`null`值进行拆箱操作，将会抛出`NullPointerException`。\*\*拆箱操作是指将包装类（如`Integer`、`Double`等）转换回基本数据类型（如`int`、`double`等）。由于包装类可以持有`null`值，而基本数据类型不能为`null`，因此在尝试将`null`的包装类转换为基本数据类型时，Java运行时会抛出异常。

例如：

```java
Integer nullInteger = null;
int i = nullInteger; // 这里会抛出NullPointerException
```

在上面的代码中，`nullInteger`被赋值为`null`，然后尝试将其拆箱为基本数据类型`int`。由于`nullInteger`是`null`，所以尝试访问其值时会抛出`NullPointerException`。

为了避免在拆箱时出现`NullPointerException`，在进行拆箱操作之前，应该检查包装类对象是否为`null`。例如：

```java
Integer nullInteger = null;
if (nullInteger != null) {
    int i = nullInteger; // 这里不会抛出异常，因为已经检查了nullInteger不为null
} else {
    // 处理null的情况
}
```

在实际编程中，特别是在使用集合或进行泛型编程时，应该特别注意避免对可能为`null`的包装类进行拆箱操作，以防止程序抛出`NullPointerException`。

## Java中的包装类的缓存机制

Java中的包装类（如`Integer`、`Long`、`Short`、`Byte`、`Character`）提供了缓存机制，以提高性能和减少内存使用。这些缓存机制主要针对小范围的整数值，因为这些值在程序中非常常见，如循环计数、数组索引等。

Integer缓存机制

`Integer`类的缓存机制是通过`IntegerCache`类实现的。从Java 5开始，`Integer`类默认缓存了-128到127之间的所有`Integer`对象。这意味着当你创建一个`Integer`对象时，如果它的值在-128到127之间，Java会返回缓存中的同一个对象，而不是创建一个新的对象。

```java
Integer i1 = 127;
Integer i2 = 127;
System.out.println(i1 == i2); // 输出 true，因为它们指向同一个对象

Integer i3 = 128;
Integer i4 = 128;
System.out.println(i3 == i4); // 输出 false，因为它们是不同的对象
```

Long缓存机制

`Long`类也有类似的缓存机制，它默认缓存了-128到127之间的所有`Long`对象。这个范围可以通过`LongCache.low`和`LongCache.high`属性来调整。

Byte和Short缓存机制

`Byte`和`Short`类也有类似的缓存机制，它们默认缓存了-128到127之间的所有对象。

Character缓存机制

`Character`类缓存了0到127之间的所有`Character`对象。这个范围是固定的，不能调整。

缓存机制的注意事项

*   **缓存范围**：缓存的范围是固定的，对于`Integer`和`Long`，这个范围可以通过JVM参数`-XX:AutoBoxCacheMax`来调整，但通常不推荐这样做，因为这可能会导致性能问题。
*   **不可变性**：由于包装类是不可变的，所以缓存的对象可以安全地被多个变量共享。
*   **性能优化**：缓存机制减少了对象的创建和垃圾回收的开销，从而提高了性能。
*   **使用场景**：缓存机制主要适用于那些频繁使用小整数值的场景，如循环计数、数组索引等。

通过这些缓存机制，Java包装类在处理常见数值时能够提供更好的性能和更少的内存占用。

## 缓存机制在并发环境下安全吗？

Java中的包装类（如`Integer`、`Long`、`Short`、`Byte`、`Character`）的缓存机制在设计上考虑了线程安全。这些缓存机制是通过静态初始化实现的，这意味着缓存的实例在类加载时就已经创建，并且是不可变的。因此，这些缓存实例在并发环境下是安全的。

缓存实例的创建和使用

*   **缓存实例的创建**：缓存实例在类加载时创建，这个过程是线程安全的，因为类加载是由类加载器以线程安全的方式执行的。
*   **缓存实例的使用**：一旦缓存实例被创建，它们就成为不可变的，这意味着它们的状态不会改变。由于不可变对象的线程安全特性，这些缓存实例可以被多个线程安全地共享和访问。

缓存机制的线程安全特性

*   **不可变性**：由于缓存实例是不可变的，它们的状态在创建后不会改变，因此不存在线程安全问题。
*   **线程安全的初始化**：缓存实例的创建是线程安全的，因为它们是在类加载时创建的，而**类加载是由类加载器以线程安全的方式执行的。**

注意事项

尽管缓存实例本身是线程安全的，但在使用这些缓存实例时，仍然需要注意以下几点：

*   **避免共享可变状态**：如果在使用缓存实例时，你创建了可变对象并共享它们，那么需要确保这些可变对象的访问是线程安全的。
*   **避免使用缓存实例作为锁**：虽然缓存实例是线程安全的，但它们不应该被用作同步块或方法的锁对象，因为这可能会导致死锁或其他并发问题。

总的来说，Java包装类的缓存机制在设计上是线程安全的，可以被多个线程安全地共享和访问。然而，开发者在使用这些缓存实例时，仍需注意避免共享可变状态和正确使用同步机制。

## 包装类和基本数据类型性能比较如何？

在Java中，基本数据类型（如int, double, char等）和它们对应的包装类（如Integer, Double, Character等）在性能上存在显著差异。这些差异主要体现在以下几个方面：

内存占用

*   **基本数据类型**：占用固定大小的内存空间，例如`int`占用4字节，`double`占用8字节。
*   **包装类**：除了存储基本数据类型值外，还需要额外的内存来存储对象的引用和对象头信息。因此，包装类的内存占用通常比基本数据类型大。

性能

*   **基本数据类型**：由于直接操作内存中的值，基本数据类型的性能通常比包装类要高。基本数据类型的操作（如算术运算、比较等）不需要进行额外的装箱和拆箱操作，因此执行速度更快。
*   **包装类**：包装类的操作涉及到装箱和拆箱，这会增加额外的性能开销。特别是在频繁进行装箱和拆箱操作时，性能影响会更加明显。

使用场景

*   **基本数据类型**：适用于需要高性能和内存效率的场景，如循环计数、数组索引、数学计算等。
*   **包装类**：适用于需要使用对象而非基本数据类型的场景，如泛型集合（如`List<Integer>`）、方法参数传递、反射等。

总结

在性能敏感的应用中，特别是在循环和大量数据处理的情况下，推荐使用基本数据类型以获得更好的性能。然而，在需要使用对象的场景中，如泛型集合或需要使用`null`值时，包装类是必要的选择。

在Java 5及以后的版本中，引入了自动装箱和自动拆箱机制，这使得在使用包装类时更加方便，但同时也增加了性能开销。因此，在性能要求较高的代码中，应尽量避免不必要的自动装箱和拆箱操作。

总之，选择使用基本数据类型还是包装类，应根据具体的应用场景和性能需求来决定。在性能要求较高的场景中，优先考虑使用基本数据类型。

## 针对浮点型数据运算出现的误差的问题，应该怎么解决？

在Java中，浮点数运算可能会出现精度误差，这是由于浮点数的表示方式和计算机的二进制系统所决定的。浮点数通常使用IEEE 754标准表示，该标准定义了浮点数的存储格式，包括符号位、指数位和尾数位。由于浮点数的表示是近似的，因此在进行浮点数运算时可能会出现舍入误差。

以下是一些处理浮点数运算误差的策略：

1.  使用`BigDecimal`类

`BigDecimal`类提供了高精度的浮点数运算，可以避免由于浮点数表示的近似性带来的误差。`BigDecimal`可以精确地表示任意大小和精度的十进制数。

```java
import java.math.BigDecimal;

public class Main {
    public static void main(String[] args) {
        BigDecimal a = new BigDecimal("1.1");
        BigDecimal b = new BigDecimal("1.2");
        BigDecimal c = a.add(b); // 使用add方法进行加法运算
        System.out.println(c); // 输出结果
    }
}
```

1.  设置精度

在使用`BigDecimal`时，可以设置运算的精度，以控制舍入行为。

```java
BigDecimal a = new BigDecimal("1.1");
BigDecimal b = new BigDecimal("1.2");
BigDecimal c = a.add(b).setScale(2, RoundingMode.HALF_UP); // 设置精度为两位小数
System.out.println(c); // 输出结果
```

1.  使用`Math.round`方法

对于简单的四舍五入需求，可以使用`Math.round`方法，它将浮点数四舍五入到最接近的整数。

```java
double a = 1.1;
double b = 1.2;
double c = Math.round(a + b); // 结果为2
```

1.  使用`DecimalFormat`类

`DecimalFormat`类可以格式化浮点数，以显示特定的小数位数，这有助于控制输出的精度。

```java
import java.text.DecimalFormat;

public class Main {
    public static void main(String[] args) {
        double a = 1.1;
        double b = 1.2;
        DecimalFormat df = new DecimalFormat("#.##"); // 设置两位小数
        System.out.println(df.format(a + b)); // 输出结果
    }
}
```

1.  了解浮点数的限制

了解浮点数的表示限制和可能的误差范围，有助于在设计算法和处理数据时做出合理的决策。

1.  避免不必要的浮点数比较

由于浮点数的精度问题，直接比较两个浮点数是否相等可能会得到错误的结果。通常，应该比较它们的差值是否小于一个很小的阈值。

```java
double a = 1.1;
double b = 1.2;
if (Math.abs(a - b) < 1e-10) {
    // a和b足够接近，可以认为它们相等
}
```

通过上述方法，可以有效地处理和减少浮点数运算中的误差问题。在实际应用中，选择合适的方法取决于具体的应用场景和精度要求。

## float f=3.4;是否正确？

在Java中，声明一个`float`类型的变量并直接赋值为`3.4`是不正确的，因为`3.4`默认被当作`double`类型处理。在Java中，浮点数默认是`double`类型，除非你明确指定它为`float`类型。

要正确地声明一个`float`类型的变量并赋值为`3.4`，你需要在数字后面加上`f`或`F`后缀，以表示这个数字是`float`类型。例如：

```java
float f = 3.4f; // 正确
```

或者

```java
float f = 3.4F; // 正确
```

使用`f`或`F`后缀可以确保编译器将这个数字视为`float`类型，而不是`double`类型。这样，你就可以正确地将`3.4`赋值给一个`float`类型的变量了。

## short s1 = 1; s1 = s1 + 1;有错吗 ? short s1 = 1; s1 += 1; 有错吗？

在Java中，`short`类型是16位的整数类型，其取值范围是-32768到32767。当你尝试执行以下操作时：

```java
short s1 = 1;
s1 = s1 + 1;
```

这里存在一个问题：`s1 + 1`的结果是一个`int`类型，因为Java在执行算术运算时会将操作数提升为`int`类型。因此，你需要显式地将结果转换回`short`类型，否则编译器会报错，提示类型不匹配。

正确的做法是：

```java
short s1 = 1;
s1 = (short)(s1 + 1); // 显式转换回short类型
```

或者使用Java的自动装箱和拆箱机制，将`short`类型自动提升为`int`类型，然后赋值回`short`类型：

```java
short s1 = 1;
s1 += 1; // 自动拆箱和装箱
```

在上面的代码中，`+=`操作符会自动将`s1`的值提升为`int`类型，执行加法操作，然后将结果转换回`short`类型并赋值给`s1`。这种做法是合法的，因为Java会自动处理类型转换，确保类型安全。

总结来说，`short s1 = 1; s1 += 1;`是合法的，而`short s1 = 1; s1 = s1 + 1;`需要显式类型转换。在实际编程中，推荐使用`+=`操作符，因为它简洁且自动处理了类型转换，避免了显式类型转换的需要。

## equals与==的区别

在Java中，`equals`方法和`==`运算符都是用来比较两个对象是否相等的，但它们的比较方式和用途有所不同。

`==`运算符

`==`运算符用于比较两个对象的引用（内存地址）是否相同，即它们是否指向同一个对象实例。对于基本数据类型（如`int`、`double`等），`==`比较的是它们的值是否相等。

```java
int a = 5;
int b = 5;
int c = 10;

System.out.println(a == b); // 输出 true，因为a和b的值相等
System.out.println(a == c); // 输出 false，因为a和c的值不相等

Integer x = 5;
Integer y = 5;
Integer z = 10;

System.out.println(x == y); // 输出 true，因为x和y指向同一个Integer对象
System.out.println(x == z); // 输出 false，因为x和z指向不同的Integer对象
```

`equals`方法

`equals`方法是`Object`类的一个方法，它被所有Java类继承。`equals`方法用于比较两个对象的内容是否相等。对于自定义类，通常需要重写`equals`方法以定义对象相等的逻辑。

```java
String str1 = new String("Hello");
String str2 = new String("Hello");

System.out.println(str1 == str2); // 输出 false，因为str1和str2指向不同的String对象
System.out.println(str1.equals(str2)); // 输出 true，因为equals方法比较的是内容
```

重写`equals`方法

对于自定义类，如果需要根据对象的内容来判断两个对象是否相等，应该重写`equals`方法。例如：

```java
public class Person {
    private String name;
    private int age;

    // 构造方法、getter和setter省略

    @Override
    public boolean equals(Object obj) {
        if (this == obj) return true;
        if (obj == null || getClass() != obj.getClass()) return false;
        Person person = (Person) obj;
        return age == person.age && Objects.equals(name, person.name);
    }
}
```

在上面的`Person`类中，`equals`方法首先检查两个对象是否是同一个对象的引用，然后检查是否为`null`，最后比较两个对象的`name`和`age`字段是否相等。

总结来说，`==`用于比较两个对象的引用是否相同，而`equals`方法用于比较两个对象的内容是否相等。对于自定义类，通常需要重写`equals`方法来定义对象相等的逻辑。

## ++i与i++的区别

在Java中，`++i` 和 `i++` 都是递增运算符，用于将变量的值增加1。然而，它们在使用时有重要的区别，主要体现在它们的返回值和执行时间点上。

`++i`（前缀递增）

*   **返回值**：`++i` 会先将变量的值增加1，然后返回增加后的值。
*   **执行时间点**：`++i` 在表达式求值之前执行，因此它会立即影响变量的值。

`i++`（后缀递增）

*   **返回值**：`i++` 会返回变量增加前的原始值，然后将变量的值增加1。
*   **执行时间点**：`i++` 在表达式求值之后执行，因此它不会立即影响变量的值。

示例

```java
int i = 5;
int j = ++i; // i 现在是 6，j 也是 6
System.out.println("i = " + i); // 输出 i = 6
System.out.println("j = " + j); // 输出 j = 6

int k = 5;
int l = k++; // k 现在是 6，l 是 5
System.out.println("k = " + k); // 输出 k = 6
System.out.println("l = " + l); // 输出 l = 5
```

使用场景

*   如果你需要在表达式中使用变量的递增后的值，应该使用 `++i`。
*   如果你需要在表达式中使用变量的原始值，然后变量递增，应该使用 `i++`。

在循环和其他需要变量递增的场景中，`++i` 和 `i++` 都可以使用，但它们的行为不同。选择使用哪一个取决于你希望变量在表达式求值时处于什么状态。

## Java中各种数据默认值

在Java中，不同的数据类型有不同的默认值。这些默认值在声明变量但未显式初始化时自动赋予。以下是Java中各种数据类型的默认值：

基本数据类型

*   **整数类型** (`byte`, `short`, `int`, `long`):
    *   默认值为 `0`。

*   **浮点类型** (`float`, `double`):
    *   默认值为 `0.0`。

*   **字符类型** (`char`):
    *   默认值为 `'\u0000'`，即空字符。

*   **布尔类型** (`boolean`):
    *   默认值为 `false`。

引用数据类型

*   **类类型** (`Object`, `String`, 自定义类等):
    *   默认值为 `null`。

*   **数组**:
    *   数组的默认值取决于数组的元素类型。对于基本数据类型的数组，每个元素的默认值与单独的变量相同。对于对象类型的数组，每个元素的默认值为 `null`。

示例

```java
int i; // 默认值为 0
long l; // 默认值为 0L
float f; // 默认值为 0.0f
double d; // 默认值为 0.0d
char c; // 默认值为 '\u0000'
boolean b; // 默认值为 false

String str; // 默认值为 null
MyClass obj; // 自定义类，MyClass是任意类名，obj的默认值为 null

int[] intArray; // 默认值为 null
int[] intArray2 = new int[5]; // 数组中的每个元素默认值为 0
```

注意事项

*   **局部变量**：局部变量（在方法内部声明的变量）没有默认值，必须在使用前显式初始化。
*   **静态变量**：静态变量（类变量）在类加载时初始化，如果没有显式初始化，则会根据类型赋予默认值。

了解这些默认值对于编写健壮的Java代码非常重要，特别是在处理可能未初始化的变量时。

## java中是值传递引用传递？

在Java中，参数传递的方式是值传递（pass-by-value）。这意味着当一个方法被调用时，方法参数的值被复制到方法的局部变量中。对于基本数据类型（如int, double, char等），传递的是实际的值。对于对象引用类型（如String, Integer, ArrayList等），传递的是引用的副本，即引用的值（内存地址）。

基本数据类型传递

对于基本数据类型，传递的是实际的值的副本：

```java
public class PassByValueExample {
    public static void main(String[] args) {
        int number = 10;
        System.out.println("Before method call: " + number); // 输出 10
        modify(number);
        System.out.println("After method call: " + number); // 输出 10
    }

    public static void modify(int number) {
        number = 20;
    }
}
```

在上面的例子中，`modify`方法接收一个`int`类型的参数`number`。当`modify`方法被调用时，`number`的值被复制到方法的局部变量中。在`modify`方法内部对`number`的修改不会影响到`main`方法中的`number`变量。

引用类型传递

对于对象引用类型，传递的是引用的副本：

```java
public class PassByValueExample {
    public static void main(String[] args) {
        Integer number = 10;
        System.out.println("Before method call: " + number); // 输出 10
        modify(number);
        System.out.println("After method call: " + number); // 输出 10
    }

    public static void modify(Integer number) {
        number = 20;
    }
}
```

在这个例子中，`modify`方法接收一个`Integer`类型的参数`number`。当`modify`方法被调用时，`number`的引用（内存地址）被复制到方法的局部变量中。在`modify`方法内部对`number`的修改不会影响到`main`方法中的`number`变量，因为它们指向的是不同的对象。

总结

在Java中，无论是基本数据类型还是对象引用类型，传递的都是值的副本。对于基本数据类型，传递的是实际的值；对于对象引用类型，传递的是引用的副本。理解这一点对于编写正确和高效的Java代码非常重要。

## 内部类与静态内部类的区别

在Java中，内部类（Inner Class）是指定义在另一个类的内部的类。内部类可以访问外部类的所有成员（包括私有成员）。根据内部类是否需要外部类的实例来创建，内部类可以分为非静态内部类（Inner Class）和静态内部类（Static Inner Class）。

非静态内部类（Inner Class）

*   **非静态内部类**不能有静态成员（字段、方法、内部类等），因为非静态内部类依赖于外部类的实例。
*   **非静态内部类**可以访问外部类的所有成员，包括私有成员。
*   **非静态内部类**的实例必须与外部类的实例关联。创建非静态内部类的实例时，必须先创建外部类的实例。
*   **非静态内部类**可以访问外部类的实例变量和方法，就像它们是自己的成员一样。

静态内部类（Static Inner Class）

*   **静态内部类**可以有静态成员（字段、方法、内部类等），因为静态内部类不依赖于外部类的实例。
*   **静态内部类**可以访问外部类的静态成员，但不能直接访问外部类的非静态成员，除非通过外部类的实例。
*   **静态内部类**的实例不需要外部类的实例即可创建。
*   **静态内部类**可以被外部类的静态方法直接访问，不需要外部类的实例。

区别总结

1.  **静态与非静态**：静态内部类是通过`static`关键字定义的，而非静态内部类则没有这个关键字。这决定了它们是否可以拥有静态成员以及它们与外部类实例的关系。

2.  **实例化方式**：非静态内部类的实例化需要外部类的实例，而静态内部类的实例化不需要。

3.  **访问权限**：非静态内部类可以访问外部类的所有成员，包括私有成员；静态内部类只能访问外部类的静态成员。

4.  **使用场景**：如果内部类不需要访问外部类的非静态成员，或者你希望内部类可以独立于外部类的实例存在，那么使用静态内部类。如果内部类需要访问外部类的非静态成员，或者需要与外部类的实例紧密相关联，那么使用非静态内部类。

5.  **内存占用**：由于非静态内部类需要外部类的实例，因此在创建非静态内部类的实例时，会同时创建外部类的实例，这可能会增加内存的使用。

## String str=”aaa” , 与String str=new String(“aaa”) 一样吗

在Java中，`String str = "aaa"` 和 `String str = new String("aaa")` 这两种方式创建字符串对象是不同的，主要体现在它们在内存中的存储方式和性能上。

1.  **字符串字面量（String Literal）**:
    *   当使用 `String str = "aaa"` 这种方式时，Java虚拟机会首先检查字符串字面量 `"aaa"` 是否已经存在于字符串常量池（String Pool）中。
    *   如果存在，那么 `str` 将直接指向常量池中的这个字符串对象，不会创建新的对象。
    *   如果不存在，Java虚拟机会在字符串常量池中创建一个新的字符串对象 `"aaa"`，然后 `str` 指向这个对象。

2.  **使用 `new` 关键字创建字符串对象**:
    *   当使用 `String str = new String("aaa")` 这种方式时，不管字符串常量池中是否已经存在 `"aaa"`，都会在堆内存中创建一个新的字符串对象。
    *   这个新创建的对象是 `new String("aaa")` 的结果，而 `"aaa"` 字符串字面量仍然存在于字符串常量池中。
    *   因此，使用 `new` 关键字创建字符串对象会创建两个对象：一个在字符串常量池中，另一个在堆内存中。

性能影响

*   使用字符串字面量的方式创建字符串对象通常更高效，因为它避免了不必要的对象创建，减少了内存的使用。
*   使用 `new` 关键字创建字符串对象则会增加内存的使用，因为它总是创建一个新的对象。

示例

```java
String str1 = "aaa"; // 字符串字面量，可能指向常量池中的对象
String str2 = "aaa"; // 同样指向常量池中的对象，因为字符串字面量是共享的
String str3 = new String("aaa"); // 在堆内存中创建新的字符串对象
```

在上述代码中，`str1` 和 `str2` 指向同一个字符串对象，而 `str3` 指向堆内存中的另一个字符串对象。如果执行 `str1 == str2`，结果将是 `true`，因为它们指向同一个对象。而 `str1 == str3` 或 `str2 == str3` 的结果将是 `false`，因为它们指向不同的对象。

## Hashcode 的作用

在Java中，`hashCode()` 方法是`Object`类的一个方法，它返回一个整数，这个整数是对象的哈希码（hash code）。哈希码是对象的一个标识符，用于在哈希表（如`HashMap`、`HashSet`等）中快速定位对象。`hashCode()`方法在Java集合框架中扮演着非常重要的角色，特别是在实现`equals()`方法的对象中。

以下是`hashCode()`方法的一些关键作用：

1.  **哈希表的性能**：在哈希表中，对象的存储位置是通过对象的哈希码来计算的。当向哈希表中添加、查找或删除元素时，首先计算元素的哈希码，然后根据哈希码来确定元素在哈希表中的位置。这样可以快速定位元素，提高操作的效率。

2.  **对象的唯一性**：虽然`hashCode()`方法返回的哈希码并不保证是唯一的，但通常情况下，不同的对象应该返回不同的哈希码。这样可以减少哈希冲突，提高哈希表的性能。

3.  **`equals()`方法的辅助**：在Java中，如果两个对象通过`equals()`方法比较是相等的，那么它们的`hashCode()`方法返回的哈希码也必须相同。这是为了保证在哈希表中，相等的对象能够被正确地识别和处理。

4.  **缓存**：在某些情况下，对象的哈希码计算可能比较耗时，因此对象可以缓存其哈希码。一旦计算出哈希码，就可以在后续的调用中直接返回，避免重复计算。

5.  **一致性**：当对象的状态发生变化时，其哈希码应该保持不变，除非对象的`equals()`方法定义为在状态变化后返回`false`。这保证了对象在哈希表中的位置不会因为状态的变化而改变。

在实现自定义类时，通常需要重写`hashCode()`方法，以确保当两个对象通过`equals()`方法判断为相等时，它们的`hashCode()`方法返回相同的值。这有助于保持哈希表的正确性和性能。

下面是一个简单的`hashCode()`方法的实现示例：

```java
@Override
public int hashCode() {
    final int prime = 31;
    int result = 1;
    result = prime * result + ((name == null) ? 0 : name.hashCode());
    result = prime * result + age;
    return result;
}
```

在这个例子中，`hashCode()`方法考虑了对象的两个字段：`name`和`age`。它首先初始化一个结果变量，然后根据每个字段的哈希码来计算最终的哈希码。**注意，这里使用了31作为乘数，因为它是奇素数，可以提供更好的哈希分布。**

在Java中，使用31作为乘数来计算哈希码基于以下几点考虑：

1.  **奇数乘法**：使用奇数作为乘数可以避免哈希码的低位和高位发生冲突。如果使用偶数乘以一个整数，那么结果的最低位（即偶数位）将总是0，这会降低哈希码的随机性和分布性。使用奇数可以确保结果的每一位都可能发生变化。

2.  **31的特殊性**：选择31作为乘数是因为它是一个奇素数，而且在乘法运算中，31可以被优化为 `(i << 5) - i`，其中`i`是当前字段的哈希码。这种优化可以提高计算效率，因为位移和减法比直接乘法更快。

3.  **乘法的性能**：乘法运算通常比除法运算快，尤其是在现代处理器上。使用31作为乘数，可以利用处理器的优化来提高性能。

4.  **哈希码的分布**：使用31作为乘数可以产生一个较好的哈希码分布，这有助于减少哈希冲突，提高哈希表的性能。

5.  **可读性和一致性**：使用31作为乘数在Java社区中已经形成了一种约定，这有助于保持代码的可读性和一致性。

下面是一个简单的例子，展示如何使用31来计算哈希码：

```java
int hash = 1;
hash = 31 * hash + field1.hashCode();
hash = 31 * hash + field2.hashCode();
// ... 对其他字段进行同样的操作
```

在这个例子中，`field1.hashCode()`和`field2.hashCode()`是对象中各个字段的哈希码。通过将它们与31相乘并累加到`hash`变量中，我们得到了一个基于这些字段的哈希码。

需要注意的是，虽然31是一个常用的乘数，但并不是唯一的选择。在某些情况下，根据具体的应用场景和性能要求，开发者可能会选择其他数值作为乘数。重要的是选择一个奇数乘数，并且确保它能够提供良好的哈希码分布。

## Java的四种引用，强弱软虚

在Java中，引用类型分为四种：强引用（Strong Reference）、软引用（Soft Reference）、弱引用（Weak Reference）和虚引用（Phantom Reference）。每种引用类型都有其特定的用途和行为。

强引用（Strong Reference）

强引用是最常见的引用类型。当一个对象通过强引用被引用时，它不会被垃圾回收器回收，即使内存不足。只有当没有任何强引用指向该对象时，它才会被垃圾回收器回收。

```java
Object strongRef = new Object();
```

软引用（Soft Reference）

软引用是一种比强引用弱的引用。当一个对象只有软引用指向它时，它只有在内存不足的情况下才会被垃圾回收器回收。软引用通常用于实现内存敏感的缓存。

```java
SoftReference<Object> softRef = new SoftReference<>(new Object());
```

弱引用（Weak Reference）

弱引用比软引用更弱。当一个对象只有弱引用指向它时，它随时都可能被垃圾回收器回收，即使在内存充足的情况下。弱引用通常用于实现映射表，如`WeakHashMap`。

```java
WeakReference<Object> weakRef = new WeakReference<>(new Object());
```

虚引用（Phantom Reference）

虚引用是最弱的引用类型。它不会影响对象的生命周期，即使有虚引用指向对象，该对象也可能被垃圾回收器回收。虚引用主要用于跟踪对象被垃圾回收器回收的活动。虚引用必须与引用队列（ReferenceQueue）一起使用，以便在对象被回收时得到通知。

```java
ReferenceQueue<Object> queue = new ReferenceQueue<>();
PhantomReference<Object> phantomRef = new PhantomReference<>(new Object(), queue);
```

虚引用的主要用途是实现更精细的控制，比如在对象被回收后执行一些清理工作。

每种引用类型都有其特定的使用场景，开发者可以根据需要选择合适的引用类型来管理对象的生命周期。在实际应用中，软引用和弱引用常用于缓存和映射表，而虚引用则用于更高级的内存管理。

在实际开发中，软引用（Soft Reference）和弱引用（Weak Reference）的选择取决于你希望如何管理对象的生命周期以及你对内存使用的敏感程度。

软引用（Soft Reference）

软引用用于实现内存敏感的缓存。当内存不足时，JVM会回收这些对象，以避免`OutOfMemoryError`。因此，软引用适合于那些可以被回收但又希望尽可能长时间保留的对象。

**使用场景**：

*   缓存：当你需要缓存一些数据，但又不想因为缓存而耗尽内存导致应用崩溃时，可以使用软引用。
*   图像处理：在图像处理应用中，可以使用软引用缓存图像，当内存不足时，这些图像可以被回收。

**示例**：

```java
SoftReference<byte[]> softRef = new SoftReference<>(new byte[1024 * 1024]);
```

弱引用（Weak Reference）

弱引用用于那些即使被引用也随时可能被垃圾回收器回收的对象。弱引用不会阻止对象被回收，因此适合于那些生命周期短暂的对象。

**使用场景**：

*   映射表：在`WeakHashMap`中，键是弱引用，这样当键不再被其他地方引用时，整个键值对可以被回收。
*   临时对象：当你需要创建一些临时对象，但又不希望这些对象影响垃圾回收时，可以使用弱引用。

**示例**：

```java
WeakReference<String> weakRef = new WeakReference<>(new String("临时字符串"));
```

如何选择

选择软引用还是弱引用，主要取决于你对对象生命周期的控制需求：

*   如果你希望对象在内存不足时被回收，但又希望尽可能长时间地保留它们，那么应该使用软引用。
*   如果你希望对象在没有其他强引用时被回收，那么应该使用弱引用。

在实际应用中，软引用和弱引用的使用需要谨慎，因为它们可能会导致对象的生命周期变得难以预测。在使用这些引用时，应该确保你的应用逻辑能够处理对象可能随时被回收的情况。

## finalize() 方法

`finalize()` 方法是Java中一个特殊的方法，它属于`Object`类，因此所有Java对象都继承了这个方法。`finalize()`方法的目的是在垃圾收集器执行时，为对象提供一个执行清理工作的机会。当一个对象不再被任何引用所指向时，垃圾收集器可能会在回收该对象之前调用它的`finalize()`方法。

`finalize()`方法的声明如下：

```java
protected void finalize() throws Throwable {
    // 清理代码
}
```

需要注意的是，`finalize()`方法的使用存在一些限制和问题：

1.  **不确定性**：垃圾收集器何时调用`finalize()`方法是不确定的。它可能在对象被回收之前、之后，或者根本不调用。因此，不应该依赖`finalize()`方法来执行关键的清理工作。

2.  **性能影响**：`finalize()`方法的执行会增加垃圾收集的开销，因为它需要额外的处理来调用对象的`finalize()`方法。

3.  **资源释放**：如果对象持有外部资源（如文件、数据库连接等），应该使用`try-finally`块或`try-with-resources`语句来确保这些资源被正确释放，而不是依赖`finalize()`方法。

4.  **异常处理**：`finalize()`方法可以抛出任何异常，但这些异常会被垃圾收集器忽略。因此，不应该在`finalize()`方法中抛出异常。

5.  **不推荐使用**：由于上述原因，Java官方文档明确指出，`finalize()`方法不应该被使用。在Java 9及以后的版本中，`finalize()`方法被标记为`@Deprecated`，并推荐使用其他方式来管理资源。

由于`finalize()`方法的这些限制和问题，现代Java开发中通常不推荐使用它。相反，应该使用`try-finally`块、`try-with-resources`语句或`AutoCloseable`接口来确保资源的正确释放。这些方法提供了更明确、更可靠的方式来管理资源，避免了`finalize()`方法的不确定性。

## 排序都有哪几种方法？请列举

排序算法是计算机科学中一个非常重要的主题，用于将一系列元素按照一定的顺序排列。排序算法的种类繁多，每种算法都有其特定的使用场景和性能特点。以下是一些常见的排序算法：

1.  **冒泡排序（Bubble Sort）**
    *   简单直观，通过重复遍历待排序的数列，比较相邻元素，如果顺序错误就交换它们。
    *   时间复杂度：平均和最坏情况为O(n^2)，最好情况为O(n)。

冒泡排序的基本步骤：

1.  **比较相邻元素**：从数列的第一个元素开始，比较相邻的两个元素。如果第一个比第二个大，就交换它们两个。
2.  **每一轮遍历**：对每一对相邻元素做同样的工作，从开始第一对到结尾的最后一对。这步做完后，最后的元素会是最大的数。
3.  **重复步骤**：针对所有的元素重复以上的步骤，除了最后一个。
4.  **持续减少未排序数列的长度**：每次遍历后，未排序的数列长度减1，直到所有元素都已排序。

示例：

```java
public class BubbleSortExample {

    public static void bubbleSort(int[] arr) {
        // 获取数组的长度
        int n = arr.length;
        // 外层循环控制排序的轮数
        for (int i = 0; i < n - 1; i++) {
            // 内层循环负责每轮的比较和交换
            for (int j = 0; j < n - 1 - i; j++) {
                // 如果当前元素大于下一个元素，则交换它们
                if (arr[j] > arr[j + 1]) {
                    // 交换arr[j]和arr[j+1]
                    int temp = arr[j];
                    arr[j] = arr[j + 1];
                    arr[j + 1] = temp;
                }
            }
        }
    }

    public static void main(String[] args) {
        // 待排序的数组
        int[] arr = {64, 34, 25, 12, 22, 11, 90};

        // 打印原始数组
        System.out.println("Original array:");
        printArray(arr);

        // 调用冒泡排序方法
        bubbleSort(arr);

        // 打印排序后的数组
        System.out.println("Sorted array:");
        printArray(arr);
    }

    // 辅助方法，用于打印数组
    private static void printArray(int[] arr) {
        for (int value : arr) {
            System.out.print(value + " ");
        }
        System.out.println();
    }
}
```

冒泡排序虽然简单，但效率较低，特别是对于大数据集来说，它不是一种高效的排序方法。在实际应用中，通常会使用更高效的排序算法，如快速排序、归并排序或堆排序。

1.  **选择排序（Selection Sort）**
    *   每次从待排序的数据元素中选出最小（或最大）的一个元素，存放在序列的起始位置，直到全部待排序的数据元素排完。
    *   时间复杂度：平均和最坏情况为O(n^2)。

选择排序的基本步骤：

1.  **初始化**：将数组的第一个元素视为已排序部分，剩余的视为未排序部分。
2.  **选择最小（或最大）元素**：在未排序部分中找到最小（或最大）的元素。
3.  **交换**：将找到的最小（或最大）元素与未排序部分的第一个元素交换位置。
4.  **重复**：重复步骤2和3，直到未排序部分为空。

示例：

```java
public class SelectionSortExample {

    public static void selectionSort(int[] arr) {
        // 遍历数组中的每个元素
        for (int i = 0; i < arr.length - 1; i++) {
            // 假设当前索引处的元素是最小的
            int minIndex = i;
            // 遍历未排序部分的元素
            for (int j = i + 1; j < arr.length; j++) {
                // 如果找到更小的元素，则更新最小索引
                if (arr[j] < arr[minIndex]) {
                    minIndex = j;
                }
            }
            // 如果最小元素不是当前索引处的元素，则交换它们
            if (minIndex != i) {
                int temp = arr[i];
                arr[i] = arr[minIndex];
                arr[minIndex] = temp;
            }
        }
    }

    public static void main(String[] args) {
        // 待排序的数组
        int[] arr = {64, 25, 12, 22, 11};

        // 打印原始数组
        System.out.println("Original array:");
        printArray(arr);

        // 调用选择排序方法
        selectionSort(arr);

        // 打印排序后的数组
        System.out.println("Sorted array:");
        printArray(arr);
    }

    // 辅助方法，用于打印数组
    private static void printArray(int[] arr) {
        for (int value : arr) {
            System.out.print(value + " ");
        }
        System.out.println();
    }
}
```

选择排序算法虽然简单，但效率较低，特别是对于大数据集来说，它不是一种高效的排序方法。在实际应用中，通常会使用更高效的排序算法，如快速排序、归并排序或堆排序。

1.  **插入排序（Insertion Sort）**
    *   通过构建有序序列，对于未排序数据，在已排序序列中从后向前扫描，找到相应位置并插入。
    *   时间复杂度：平均和最坏情况为O(n^2)，最好情况为O(n)。

它的工作原理是通过构建有序序列，对于未排序数据，在已排序序列中从后向前扫描，找到相应位置并插入。插入排序在实现上，通常使用in-place排序（即只需用到O(1)的额外空间的排序），因而在从后向前扫描过程中，需要反复把已排序元素逐步向后挪位，为最新元素提供插入空间。

插入排序的基本步骤：

1.  从第一个元素开始，该元素可以认为已经被排序。
2.  取出下一个元素，在已经排序的元素序列中从后向前扫描。
3.  如果该元素（已排序）大于新元素，将该元素移到下一位置。
4.  重复步骤3，直到找到已排序的元素小于或者等于新元素的位置。
5.  将新元素插入到该位置后。
6.  重复步骤2\~5。

示例：

```java
public class InsertionSortExample {

    public static void insertionSort(int[] arr) {
        // 遍历数组中的每个元素
        for (int i = 1; i < arr.length; i++) {
            // 选择当前元素作为要插入的值
            int current = arr[i];
            // j是已排序部分的最后一个元素的索引
            int j = i - 1;

            // 将已排序部分的元素向后移动，直到找到正确的位置插入current
            while (j >= 0 && arr[j] > current) {
                // 将大于current的元素向后移动
                arr[j + 1] = arr[j];
                // 移动到前一个元素
                j--;
            }
            // 将current插入到正确的位置
            arr[j + 1] = current;
        }
    }

    public static void main(String[] args) {
        // 待排序的数组
        int[] arr = {9, 5, 1, 4, 3};

        // 打印原始数组
        System.out.println("Original array:");
        printArray(arr);

        // 调用插入排序方法
        insertionSort(arr);

        // 打印排序后的数组
        System.out.println("Sorted array:");
        printArray(arr);
    }

    // 辅助方法，用于打印数组
    private static void printArray(int[] arr) {
        for (int value : arr) {
            System.out.print(value + " ");
        }
        System.out.println();
    }
}
```

1.  **快速排序（Quick Sort）**
    *   采用分治法策略，通过一个基准元素将数组分为两部分，一边的元素都比基准小，另一边的元素都比基准大，然后递归地对这两部分继续进行排序。
    *   时间复杂度：平均情况为O(n log n)，最坏情况为O(n^2)。

示例

```java
import java.util.Random;

public class QuickSortExample {

    // 快速排序方法，接受数组以及要排序的子数组的起始和结束索引
    public static void quickSort(int[] arr, int low, int high) {
        // 如果子数组的起始索引小于结束索引，说明子数组中至少有两个元素，需要进行排序
        if (low < high) {
            // 调用partition方法进行分区，并获取分区后的基准值索引
            int index = partition(arr, low, high);

            // 递归地对基准值左侧的子数组进行快速排序
            quickSort(arr, low, index - 1);
            // 递归地对基准值右侧的子数组进行快速排序
            quickSort(arr, index + 1, high);
        }
    }

    // 分区方法，用于将数组分为两部分，并返回基准值的最终索引
    private static int partition(int[] arr, int low, int high) {
        // 随机选择一个基准值索引，以避免最坏情况下的性能
        Random random = new Random();
        int pivotIndex = low + random.nextInt(high - low + 1);
        // 将随机选择的基准值与子数组的最后一个元素交换位置
        swap(arr, pivotIndex, high);

        // 选择最后一个元素作为基准值
        int pivot = arr[high];

        // i用于记录小于基准值的元素的最后一个位置
        int i = (low - 1);

        // 遍历子数组，将小于基准值的元素移动到基准值的左侧
        for (int j = low; j < high; j++) {
            // 如果当前元素小于或等于基准值
            if (arr[j] <= pivot) {
                // 将i加1，并交换arr[i]和arr[j]的位置
                i++;
                swap(arr, i, j);
            }
        }

        // 将基准值放到正确的位置（i+1），此时i+1左边的元素都小于基准值
        swap(arr, i + 1, high);

        // 返回基准值的最终索引
        return i + 1;
    }

    // 交换数组中两个元素的位置
    private static void swap(int[] arr, int i, int j) {
        int temp = arr[i];
        arr[i] = arr[j];
        arr[j] = temp;
    }

    // 主方法，用于演示快速排序的过程
    public static void main(String[] args) {
        // 创建一个待排序的数组
        int[] arr = {10, 7, 8, 9, 1, 5};
        // 获取数组的长度
        int n = arr.length;

        // 打印原始数组
        System.out.println("Original array:");
        printArray(arr);

        // 调用快速排序方法对数组进行排序
        quickSort(arr, 0, n - 1);

        // 打印排序后的数组
        System.out.println("Sorted array:");
        printArray(arr);
    }

    // 辅助方法，用于打印数组中的所有元素
    private static void printArray(int[] arr) {
        for (int value : arr) {
            System.out.print(value + " ");
        }
        System.out.println();
    }
}
```

1.  **归并排序（Merge Sort）**
    *   采用分治法策略，将数组分成两半，分别排序，然后合并。
    *   时间复杂度：稳定排序，平均和最坏情况均为O(n log n)。

2.  **堆排序（Heap Sort）**
    *   利用堆这种数据结构所设计的一种排序算法，通过构建一个大顶堆或小顶堆，然后依次取出堆顶元素并重新调整堆结构。
    *   时间复杂度：平均和最坏情况均为O(n log n)。

3.  **计数排序（Counting Sort）**
    *   非比较排序，适用于一定范围内的整数排序。通过统计每个整数出现的次数，然后根据统计结果进行排序。
    *   时间复杂度：O(n + k)，其中k是整数的范围。

4.  **桶排序（Bucket Sort）**
    *   将数组分到有限数量的桶里，每个桶再个别排序（有可能再使用别的排序算法或是以递归方式继续使用桶排序进行排序）。
    *   时间复杂度：平均情况为O(n + k)，其中k是桶的数量。

5.  **基数排序（Radix Sort）**
    *   非比较排序，通过键值的各个位的值，将要排序的元素分配到有限数量的桶里，再从桶中收集元素。
    *   时间复杂度：平均和最坏情况均为O(nk)，其中n是元素数量，k是位数。

每种排序算法都有其适用场景，例如，快速排序在大多数情况下效率较高，但对小规模数据或已排序数据效率不高；归并排序在数据量大时性能稳定，但需要额外的存储空间；计数排序和桶排序适用于特定范围内的整数排序等。在实际应用中，选择合适的排序算法可以显著提高程序的性能。

## 泛型擦除

Java中的泛型是一种在**编译时**提供类型安全的机制，允许在定义类、接口和方法时使用类型参数。泛型的主要目的是允许程序员编写通用的代码，这些代码可以适用于多种数据类型，同时保持类型安全。泛型在Java 5中引入。

泛型的基本概念

泛型允许你定义类、接口和方法时使用类型参数（如`<T>`），这些类型参数在使用时会被具体类型（如`Integer`、`String`等）替换。例如，`List<T>`是一个泛型接口，可以被实例化为`List<Integer>`、`List<String>`等。

泛型的好处

1.  **类型安全**：泛型确保在编译时类型检查，避免了类型转换错误和`ClassCastException`。
2.  **代码重用**：泛型允许编写通用的代码，可以适用于多种数据类型，减少了代码的重复。
3.  **清晰的API**：泛型使得API更加清晰，因为类型参数直接表明了方法或类的预期类型。

泛型擦除

尽管泛型提供了类型安全，但Java的泛型实现采用了类型擦除（Type Erasure）机制。这意味着泛型信息在编译后会被擦除，运行时不会保留泛型类型信息。具体来说，泛型类型参数会被替换为它们的边界类型（如果没有指定边界，则为`Object`），泛型类和接口会被转换为非泛型类和接口。

例如，考虑以下泛型类：

```java
public class Box<T> {
    private T t;

    public void set(T t) {
        this.t = t;
    }

    public T get() {
        return t;
    }
}
```

在编译后，`Box<T>`会被转换为：

```java
public class Box {
    private Object t;

    public void set(Object t) {
        this.t = t;
    }

    public Object get() {
        return t;
    }
}
```

**泛型擦除的主要原因**是为了保持向后兼容性，因为Java泛型是在Java 5中引入的，而在此之前，Java代码已经广泛使用了。泛型擦除确保了泛型代码可以与非泛型代码无缝交互。

泛型擦除的限制

由于泛型擦除，以下限制存在：

1.  **不能创建泛型数组**：因为数组需要在运行时知道其确切类型，而泛型信息在运行时被擦除了。
2.  **不能使用基本类型作为泛型类型参数**：因为基本类型不能作为对象使用，而泛型擦除后，类型参数会被替换为`Object`类型。
3.  **不能使用instanceof检查泛型类型**：因为泛型信息在运行时被擦除，所以无法使用`instanceof`来检查泛型类型。

尽管存在这些限制，泛型仍然是Java中非常强大的特性，它极大地提高了代码的类型安全性和可读性。

## try catch finally return 的执行顺序

在Java中，`try-catch-finally`语句块用于处理异常。`finally`块无论是否发生异常都会执行，而`return`语句则用于从方法中返回一个值。当`try`块或`catch`块中包含`return`语句时，`finally`块的执行顺序可能会引起一些混淆。以下是`try-catch-finally`块中`return`语句的执行顺序：

1.  **执行`try`块**：首先执行`try`块中的代码。
2.  **异常发生**：如果在`try`块中发生异常，控制流会跳转到与之匹配的`catch`块。
3.  **执行`catch`块**：如果存在匹配的`catch`块，执行`catch`块中的代码。如果`catch`块中包含`return`语句，那么`finally`块会在`return`语句执行之前执行。
4.  **执行`finally`块**：无论是否发生异常，`finally`块都会执行。如果`try`块或`catch`块中包含`return`语句，`finally`块会在`return`语句执行之前执行，但`finally`块中的`return`语句会覆盖`try`或`catch`块中的`return`语句。
5.  **返回值**：`finally`块执行完毕后，方法返回`finally`块中`return`的值，或者如果`finally`块中没有`return`语句，则返回`try`或`catch`块中`return`的值。

下面是一个简单的例子来说明这个执行顺序：

```java
public class TryCatchFinallyExample {
    public static int exampleMethod() {
        try {
            System.out.println("Try block");
            return 1; // ①
        } catch (Exception e) {
            System.out.println("Catch block");
            return 2; // ②
        } finally {
            System.out.println("Finally block");
            return 3; // ③
        }
    }

    public static void main(String[] args) {
        int result = exampleMethod();
        System.out.println("Returned value: " + result);
    }
}
```

输出将会是：

    Try block
    Finally block
    Returned value: 3

在这个例子中，尽管`try`块中有一个`return`语句，`finally`块中的`return`语句仍然会覆盖它，并且方法返回`finally`块中的值。如果`finally`块中没有`return`语句，那么方法将返回`try`块中的值。

# java 集合

## java 中都有哪些常用数据结构

Java 提供了丰富的数据结构，这些数据结构被封装在 `java.util` 包中。以下是一些常用的 Java 数据结构：

1.  **List**：有序集合，可以包含重复元素。
    *   **ArrayList**：基于动态数组实现，允许所有元素，包括null。
    *   **LinkedList**：基于链表实现，允许快速插入和删除操作。
    *   **Vector**：类似于ArrayList，但它是线程安全的。

2.  **Set**：不允许重复元素的集合。
    *   **HashSet**：基于哈希表实现，不保证元素的顺序。底层基于 HashMap 实现。
    *   **LinkedHashSet**：基于哈希表和链表实现，保持插入顺序。
    *   **TreeSet**：基于红黑树实现，保持元素的自然排序或自定义排序。

3.  **Queue**：用于处理先进先出（FIFO）的数据结构。
    *   **LinkedList**：实现了Queue接口，可以作为队列使用。
    *   **PriorityQueue**：基于优先级堆实现的队列，元素按照优先级顺序被移除。

4.  **Deque**：双端队列，允许在两端进行插入和删除操作。
    *   **ArrayDeque**：基于动态数组实现的双端队列。
    *   **LinkedList**：也可以作为双端队列使用。

5.  **Map**：存储键值对的数据结构。
    *   **HashMap**：基于哈希表实现，允许null键和null值。
    *   **LinkedHashMap**：基于哈希表和链表实现，保持插入顺序或访问顺序。
    *   **TreeMap**：基于红黑树实现，保持键的自然排序或自定义排序。
    *   **Hashtable**：类似于HashMap，但它是线程安全的，不允许null键和null值。

6.  **Stack**：基于后进先出（LIFO）原则的栈。
    *   **Stack**：继承自Vector，提供了栈的基本操作。

7.  **BitSet**：用于表示一系列布尔值的集合，每个值只占用一位。

8.  **Properties**：用于处理属性文件的类，它继承自Hashtable，通常用于配置文件。

9.  **EnumSet**：用于枚举类型的Set实现，内部使用位向量实现，效率高。

10. **NavigableMap** 和 **NavigableSet**：提供导航功能的接口，如查找最接近的元素等。

这些数据结构提供了不同的操作和性能特性，适用于不同的应用场景。例如，如果你需要快速查找元素，可以使用HashMap；如果你需要保持元素的插入顺序，可以使用LinkedHashMap；如果你需要一个线程安全的集合，可以使用Collections提供的同步包装器，或者使用Vector、Hashtable等线程安全的集合类。

## List

在Java中，`List` 是一个接口，它继承自 `Collection` 接口。`List` 接口代表了一个有序的集合，其中可以包含重复的元素。`List` 接口定义了多种操作，包括添加、删除、获取元素等。`List` 接口的实现类允许我们以索引的方式访问元素，这使得 `List` 成为处理有序数据集合的首选。

### List 接口的主要特点：

*   **有序**：`List` 中的元素是有序的，这意味着元素的顺序是按照它们被添加到列表中的顺序排列的。
*   **可重复**：`List` 允许包含重复的元素。
*   **索引访问**：可以通过元素的索引来访问列表中的元素，索引从0开始。
*   **动态数组**：`List` 的实现通常基于动态数组，这意味着列表的大小可以根据需要自动调整。

### List 接口的主要实现类：

1.  **ArrayList**：
    *   基于动态数组实现，允许所有元素，包括null。
    *   随机访问元素非常快，但插入和删除操作相对较慢，尤其是当操作位于列表的开头或中间时。
    *   非线程安全。

2.  **LinkedList**：
    *   基于双向链表实现，允许快速的插入和删除操作，尤其是在列表的开头和结尾。
    *   随机访问元素相对较慢，因为需要遍历链表。
    *   非线程安全。

3.  **Vector**：
    *   类似于 `ArrayList`，但它是线程安全的。
    *   所有方法都是同步的，这使得它在多线程环境中更加安全，但性能较低。
    *   由于线程安全的开销，`Vector` 在单线程环境中通常不推荐使用。

### List 接口的常用方法：

*   `add(E element)`：在列表末尾添加一个元素。
*   `add(int index, E element)`：在指定位置插入一个元素。
*   `remove(int index)`：移除指定位置的元素。
*   `remove(Object o)`：移除列表中第一个匹配指定元素的元素。
*   `get(int index)`：返回指定位置的元素。
*   `set(int index, E element)`：用指定元素替换列表中指定位置的元素。
*   `size()`：返回列表中的元素数量。
*   `contains(Object o)`：判断列表中是否包含指定的元素。
*   `indexOf(Object o)`：返回指定元素在列表中首次出现的索引，如果不存在则返回-1。

`List` 接口是Java集合框架中的核心接口之一，它提供了丰富的操作集合的方法，使得开发者可以根据具体需求选择合适的实现类。

### ArrayList 添加元素源码分析

首先，我们来看 `ArrayList` 类中添加元素的主要方法 `add(E e)` 的实现。这个方法是 `ArrayList` 类中定义的，用于向列表的末尾添加一个元素。

```java
public boolean add(E e) {
    // 确保数组容量足够，如果不够则进行扩容
    ensureCapacityInternal(size + 1);  // Increments modCount!!
    // 将元素添加到数组的size位置，并将size加1
    elementData[size++] = e;
    return true;
}
```

接下来，我们详细解释一下 `ensureCapacityInternal(int minCapacity)` 方法，这个方法用于确保 `ArrayList` 的内部数组有足够的空间来容纳新的元素。

```java
private void ensureCapacityInternal(int minCapacity) {
    // 如果是第一次添加元素，minCapacity为1，否则为当前size加1
    if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) {
        minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity);
    }
    // 确保数组容量足够
    ensureExplicitCapacity(minCapacity);
}

private void ensureExplicitCapacity(int minCapacity) {
    // 修改次数加1，用于检测并发修改异常
    modCount++;

    // 如果当前容量小于所需的最小容量，则进行扩容
    if (minCapacity - elementData.length > 0)
        grow(minCapacity);
}
```

`grow(int minCapacity)` 方法是 `ArrayList` 扩容的核心方法，它会创建一个新的数组，并将旧数组中的元素复制到新数组中。

```java
private void grow(int minCapacity) {
    // 计算新数组的容量
    int oldCapacity = elementData.length;
    int newCapacity = oldCapacity + (oldCapacity >> 1); // 新容量为旧容量的1.5倍
    if (newCapacity - minCapacity < 0)
        newCapacity = minCapacity;
    if (newCapacity - MAX_ARRAY_SIZE > 0)
        newCapacity = hugeCapacity(minCapacity);
    // 创建新数组，并将旧数组中的元素复制到新数组中
    elementData = Arrays.copyOf(elementData, newCapacity);
}
```

`hugeCapacity(int minCapacity)` 方法用于处理当新容量超过 `Integer.MAX_VALUE` 时的情况。

```java
private static int hugeCapacity(int minCapacity) {
    if (minCapacity < 0) // 如果minCapacity小于0，抛出异常
        throw new OutOfMemoryError();
    // 返回Integer.MAX_VALUE或minCapacity中的较大值
    return (minCapacity > MAX_ARRAY_SIZE) ?
        Integer.MAX_VALUE :
        MAX_ARRAY_SIZE;
}
```

以上就是 `ArrayList` 添加元素的主要步骤和相关方法的解释。在实际使用中，我们通常不需要直接操作这些底层方法，而是直接调用 `add(E e)` 方法来添加元素。`ArrayList` 会自动处理扩容和元素的添加。

### ArrayList 的扩容机制

`ArrayList` 的扩容机制是自动的，当添加元素到 `ArrayList` 时，如果当前数组的容量不足以容纳新元素，`ArrayList` 会自动进行扩容。扩容机制是 `ArrayList` 实现动态数组的关键部分。

扩容机制的步骤：

1.  **检查容量**：当调用 `add` 方法添加元素时，`ArrayList` 首先检查当前数组的容量是否足够。如果当前容量足够，直接将元素添加到数组的末尾。

2.  **自动扩容**：如果当前容量不足，`ArrayList` 会进行扩容。扩容的大小是基于当前容量的，而不是基于添加的元素数量。默认情况下，`ArrayList` 的扩容策略是将容量增加到原来的1.5倍。

3.  **创建新数组**：扩容时，`ArrayList` 会创建一个新的数组，其容量是原数组容量的1.5倍（或指定的其他大小，如果在构造 `ArrayList` 时指定了初始容量）。然后，将原数组中的所有元素复制到新数组中。

4.  **添加新元素**：复制完成后，新元素被添加到新数组的末尾。

5.  **引用更新**：最后，`ArrayList` 将内部数组的引用更新为新数组的引用，以便后续的访问和操作。

扩容的性能影响：

*   **增加内存使用**：每次扩容都会创建一个新的数组，这会消耗额外的内存空间。
*   **复制元素**：扩容时需要将原数组中的所有元素复制到新数组中，这会增加操作的时间复杂度。因此，频繁的扩容操作可能会导致性能下降。

`ArrayList` 的扩容机制是其核心特性之一，它允许 `ArrayList` 在添加元素时动态地增加其内部数组的大小。当 `ArrayList` 的容量不足以容纳新元素时，它会自动扩容。下面是 `ArrayList` 源码中关于扩容机制的实现，以及扩容时机的描述。

扩容时机

`ArrayList` 在添加元素时会检查当前容量是否足够。如果当前容量不足以容纳新元素，它会进行扩容。具体来说，当执行 `add` 方法时，会调用 `ensureCapacityInternal` 方法来检查容量。

扩容机制

`ArrayList` 的扩容机制是通过 `grow` 方法实现的。当需要扩容时，`grow` 方法会计算新的容量，然后使用 `Arrays.copyOf` 方法创建一个新的数组，并将旧数组中的元素复制到新数组中。

源码示例

以下是 `ArrayList` 源码中关于扩容机制的简化示例：

```java
import java.util.Arrays;
import java.util.Objects;

public class ArrayList<E> extends AbstractList<E>
        implements List<E>, RandomAccess, Cloneable, java.io.Serializable {

    // ... 其他成员变量和方法 ...

    // 添加元素到列表末尾
    public boolean add(E e) {
        // 确保容量足够
        ensureCapacityInternal(size + 1);  // Increments modCount!!
        elementData[size++] = e;
        return true;
    }

    // 确保容量足够
    private void ensureCapacityInternal(int minCapacity) {
        // 如果当前容量为默认空数组，则使用默认容量
        if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) {
            minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity);
        }
        ensureExplicitCapacity(minCapacity);
    }

    // 确保容量足够，如果不够则扩容
    private void ensureExplicitCapacity(int minCapacity) {
        modCount++; // 修改次数，用于快速失败机制

        // 如果当前容量小于所需最小容量，则扩容
        if (minCapacity - elementData.length > 0)
            grow(minCapacity);
    }

    // 扩容方法
    private void grow(int minCapacity) {
        // 旧容量
        int oldCapacity = elementData.length;
        // 新容量为旧容量的1.5倍
        int newCapacity = oldCapacity + (oldCapacity >> 1);
        // 如果新容量小于所需最小容量，则使用所需最小容量
        if (newCapacity - minCapacity < 0)
            newCapacity = minCapacity;
        // 如果新容量大于最大容量，则使用最大容量
        if (newCapacity - MAX_ARRAY_SIZE > 0)
            newCapacity = hugeCapacity(minCapacity);
        // 使用新容量创建新数组，并复制旧数组中的元素
        elementData = Arrays.copyOf(elementData, newCapacity);
    }

    // ... 其他成员变量和方法 ...
}
```

在上述代码中，`ensureCapacityInternal` 方法首先检查 `elementData` 是否为默认空数组，如果是，则使用默认容量 `DEFAULT_CAPACITY`（通常是10）。然后，`ensureExplicitCapacity` 方法会检查当前容量是否足够，如果不够，则调用 `grow` 方法进行扩容。

`grow` 方法首先计算新容量，新容量是旧容量的1.5倍（通过位运算实现），然后检查新容量是否满足最小容量要求。如果新容量小于最小容量，则使用最小容量。如果新容量大于最大容量（`MAX_ARRAY_SIZE`），则调用 `hugeCapacity` 方法来处理。最后，使用 `Arrays.copyOf` 方法创建一个新数组，并将旧数组中的元素复制到新数组中。

## Map

### HashMap

#### HashMap 中数据的存储结构

JDK1.7前 : 数组+链表

JDK1.8+ : 数组+链表+红黑树

每个哈希桶位中可以存在多个node节点，其中node节点为key+value+hashCode+next 组成，其中k,v存储了存放的数据信息，next存储当哈希冲突时指向下个node的信息。

![](https://raw.githubusercontent.com/MrSunflowers/images/main/note/images/202205141420146.png)

#### HashMap 中链表转为红黑树的条件

**链表长度大于8且数组长度大于等于64(不满足则会发生扩容代替升级)，当删除小于6时重新变为链表**，根据**泊松分布**，在负载因子默认为0.75的时候，单个hash槽内元素个数为8的概率小于百万分之一，所以将7作为一个分水岭，等于7的时候不转换，大于等于8的时候才进行转换，**小于等于6的时候就转化回链表结构**。

#### HashMap 扰动算法计算 hashCode

HashMap 中每个 node 节点中存储的 hashCode 并不是直接调用 Object::hashCode() 方法得出的哈希值，而是经过一种叫做扰动算法处理过的哈希值，具体的处理逻辑是使用 key 的 hash 值经过无符号右移 16 位，再与 key 原来的 hash 值进行进行与异或运算（如果a、b两个值不相同，则异或结果为1。如果a、b两个值相同，异或结果为0），在源码中的体现如下：

```java
static final int hash(Object key) {
   int h;
   return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
}
```

采用这种算法其实是对虚拟机哈希算法的补充，目的是使散列更加均匀。因为 table 当前的长度是不固定的，在进行存放和寻址时肯定要尽可能多的让表的长度和 key 的 hash 值产生联系，最简单的联系就是使用 key 的 hash 值对表的长度取余。

当表的长度为 2 的 n 次幂时，`hashCode % table.length = hashCode & (table.length-1)` ，由于 table.length 为 2 的次方数，转换为 2 进制是：1 0000（16） 这种形式，也就是高位为 1 ，其余全部为 0，其进行减一操作后变为 1111（15）也就是高位为 0 ，其余全部为 1，且 java 中 hashCode 为 32 位，此时如果仅仅使用 `hashCode & (table.length-1)` 操作，则算出来的值只保留了 hash 值低四位的特征，前面还有28位的特征全部丢失了：

假设 key 调用 hashCode() 方法后的值不做右移 16 和按位异或运算，直接和 (n-1) 做与运算

    1111 1111 1111 1111 1111 0000 1100 0001
    0000 0000 0000 0000 0000 0000 0000 1111 ----> n-1
    0000 0000 0000 0000 0000 0000 0000 0001 ----> 结果是1

结果是1

假设这时再来一个key2值，它调用hashCode()方法后的值为:

    1100 1001 1101 1101 0011 0000 1100 0001
    0000 0000 0000 0000 0000 0000 0000 1111 ---->n-1
    0000 0000 0000 0000 0000 0000 0000 0001 ----> 结果是1

结果仍然是1

再把上面的key2值的hash值做右移16和按位异或运算，再和(n-1)做与运算

    1100 1001 1101 1101 0011 0000 1100 0001
    0000 0000 0000 0000 1100 1001 1101 0011 ----> 右移16位后的值（h >>> 16）
    1100 1001 1101 1101 1111 1001 0001 0010 ----> 异或运算
    0000 0000 0000 0000 0000 0000 0000 1111 ----> n-1
    0000 0000 0000 0000 0000 0000 0000 0010 ----> 结果是2

结果是2

key的hash值经过无符号右移16位，再与key原来的hash值进行 ^ 运算，就能很好的保留hash值的所有特征，这种离散效果才是我们最想要的

![](https://raw.githubusercontent.com/MrSunflowers/images/main/note/images/202205112221896.png)

#### HashMap 寻址算法

由于散列表的长度是2的次方数，比如16,32,64等，寻址算法为 哈希码按位与散列表的长度减一 ：hashCode&(table.length-1) ，其实就等于取余 hashCode%table.length，**注意：只有散列表的长度是2的次方数时两个才相等**

总结：哈希码的高16位与低16位进行异或扰动，然后对链表长度取余计算出地址。

#### HashMap 中的散列表是什么时候创建的

HashMap 中的散列表使用懒加载的方式创建，**在第一次 put 数据的时候创建**，默认初始化容量为16，如果传入17则会寻找2的倍数最小值，应该找到的是32

```java
static final int tableSizeFor(int cap) {
    int n = cap - 1;
    n |= n >>> 1;
    n |= n >>> 2;
    n |= n >>> 4;
    n |= n >>> 8;
    n |= n >>> 16;
    return (n < 0) ? 1 : (n >= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;
}
```

向右移位1、2、4、8、16，这主要是为了把二进制的各个位置都填上1，当二进制的各个位置都是1以后，就是一个标准的2的倍数减1了，最后把结果加1再返回即可。

![](https://raw.githubusercontent.com/MrSunflowers/images/main/note/images/202205112235605.png)

#### HashMap put 的流程

1.  通过扰动算法计算 key 的哈希码
2.  判断当前散列表是否为空，是空则创建散列表，默认长度为 16
3.  计算需要插入到桶数组的位置下标，这里会有四种情况
    1.  如果下标位置没有元素，直接新建节点插入
    2.  如果下标位置不为空，且此位置还没有形成链表，则判断当前节点与目标节点的key是否相同，相同则用新value替换旧value，否则新建节点插入1.7为头插法，1.8为尾插法
    3.  此位置已经形成链表，迭代查找node，是否有重复的，与5相同，插入后检查是否需要树化，判断链表长度是否大于8，且桶数组长度大于64，满足条件则转换为红黑树存储，否则进行扩容处理
    4.  如果已经树化，则新建节点插入树中
4.  判断元素个数是否到达扩容临界点（数组容量\*负载因子），到达则扩容

#### HashMap get的流程

1.  通过扰动算法计算 key 的哈希码
2.  计算需要插入到桶数组的位置下标，这里也会有四种情况
    1.  如果下标位置为空，则返回空，说明没有查找到
    2.  如果下标位置不为空，且此位置还没有形成链表，则判断当前节点与目标节点的key是否相同，相同则返回value
    3.  如果已经树化，则从树中查找
    4.  如果已经形成链表，则遍历链表查找元素

#### HashMap 的负载因子为什么是 0.75

负载因子是和扩容机制有关的，如果当前容器的容量，达到了我们设定的最大值，就要开始执行扩容操作。举个例子：

比如说当前的容器容量是16，负载因子是0.75,16\*0.75=12，也就是说，**默认情况下当容量达到了12的时候就会进行扩容操作。**

当负载因子是1.0的时候，也就意味着，只有当数组的8个值（这个图表示了8个）全部填充了，才会发生扩容。这就带来了很大的问题，因为Hash冲突时避免不了的。当负载因子是1.0的时候，意味着会出现大量的Hash的冲突，底层的红黑树变得异常复杂。对于查询效率极其不利。这种情况就是牺牲了时间来保证空间的利用率。

负载因子过大，虽然空间利用率上去了，但是时间效率降低了

负载因子是0.5的时候，这也就意味着，当数组中的元素达到了一半就开始扩容，既然填充的元素少了，Hash冲突也会减少，那么底层的链表长度或者是红黑树的高度就会降低。查询效率就会增加。

**负载因子0.75**

这是时间和空间的权衡，大致意思就是说负载因子是0.75的时候，空间利用率比较高，而且避免了相当多的Hash冲突，使得底层的链表或者是红黑树的高度比较低，提升了空间效率。

#### HashMap 扩容过程

1.  **判断旧的表是已经否达到了最大扩容容量**，也就是 1<<30 ，（由于 java 中 int 类型最大为 32 位，而最高位为符号位，所以 hashMap 数组的最大值等于 int 的最大值，为 2 的 31 次幂减一），达到最大扩容容量后将临界值变为 `Integer.MAX_VALUE` 并返回旧表。
2.  否则进行扩容，扩容将旧表容量和扩容临界值都左移一位，即乘以 2
3.  遍历旧表的每个桶位，分为以下情况：
    1.  如果当前位置没有链化，则直接使用 node 中存储的 hash 值与\*\*新表长度 -1 \*\* `(e.hash & (newCap - 1))` 进行与运算得到新表中的位置
    2.  如果已经链化，则遍历链中的每个元素，根据 node 中存储的 hash 值与**旧表长度**进行与运算是否为 0  `((e.hash & oldCap) == 0)` 来分为两种情况，为 0 则说明该元素到新表中位置相同，否则使用该元素在旧表的位置加上旧表的长度作为新表中的位置，原因是新表的长度是旧表长度左移一位得到的，所以只需要关注最高位是否变化就可以知道新表的位置

#### ArrayList、Hashtable、HashMap初始化大小

*   ArrayList初始化n=10个空间扩容(n3)/2 + 1,如果不够设置传入的值

*   HashMap初始化n=16空间扩容2n,在并发环境下，1.7 可能会形成环状链表（扩容时可能造成）

*   Hashtable初始化n=11空间扩容2n+1

*   jdk1.6ConcurrentHashMap初始化segments=16个空间每个segments是初始化一个HashEntry 扩容segments=n2

*   jdk1.7ConcurrentHashMap初始化segments=16个空间每个segments是初始化两个HashEntry 扩容segments=n\*2

### HashMap 源码实现

HashMap是应用更广泛的`哈希表`实现，而且大部分情况下，都能在常数时间性能的情况下进行put和get操作。要掌握HashMap，主要从如下几点来把握：

*   jdk1.7中底层是由**数组（也有叫做“位桶”的）+链表**实现；jdk1.8中底层是由**数组+链表/红黑树**实现
*   可以存储null键和null值，线程不安全。在HashMap中，null可以作为键，这样的键只有一个，但可以有一个或多个键所对应的值为null。`当get()方法返回null值时，即可以表示HashMap中没有该key，也可以表示该key所对应的value为null`。因此，在HashMap中不能由get()方法来判断HashMap中是否存在某个key，应该用`containsKey()`方法来判断。而在Hashtable中，无论是key还是value都不能为null。
*   初始size为**16**，扩容：newsize = oldsize\*2，`size一定为2的n次幂`
*   扩容针对整个Map，每次扩容时，原来数组中的元素依次重新计算存放位置，并重新插入
*   插入元素后才判断该不该扩容，有可能无效扩容（插入后如果扩容，如果没有再次插入，就会产生无效扩容）
*   当Map中元素总数超过Entry数组的75%，触发扩容操作，为了减少链表长度，元素分配更均匀
*   1.7中是**先扩容后插入**新值的，1.8中是**先插值再扩容**

`为什么说HashMap是线程不安全的？`在接近临界点时，若此时两个或者多个线程进行put操作，都会进行resize（扩容）和reHash（为key重新计算所在位置），而reHash在并发的情况下可能会形成`链表环`。总结来说就是在多线程环境下，使用HashMap进行put操作会引起死循环，导致CPU利用率接近100%，所以在并发情况下不能使用HashMap。为什么在并发执行put操作会引起死循环？是因为多线程会导致HashMap的Entry链表形成环形数据结构，一旦形成环形数据结构，Entry的next节点永远不为空，就会产生死循环获取Entry。jdk1.7的情况下，并发扩容时容易形成链表环，此情况在1.8时就好太多太多了。因为在1.8中当链表长度大于阈值（默认长度为8）时，链表会被改成树形（红黑树）结构。

#### jdk1.7中HashMap的实现

##### 初始容量及存储形式

HashMap底层维护的是数组+链表，我们可以通过一小段源码来看看：

```java
 /**
  * The default initial capacity - MUST be a power of two.
  *  即 默认初始大小，值为16
  */
 static final int DEFAULT_INITIAL_CAPACITY = 1 << 4; // aka 16

 /**
  * The maximum capacity, used if a higher value is implicitly specified
  * by either of the constructors with arguments.
  * MUST be a power of two <= 1<<30.
  *  即 最大容量，必须为2^30
  */
 static final int MAXIMUM_CAPACITY = 1 << 30;

 /**
  * The load factor used when none specified in constructor.
  * 负载因子为0.75
  */
 static final float DEFAULT_LOAD_FACTOR = 0.75f;

 /**
  * The bin count threshold for using a tree rather than list for a
  * bin.  Bins are converted to trees when adding an element to a
  * bin with at least this many nodes. The value must be greater
  * than 2 and should be at least 8 to mesh with assumptions in
  * tree removal about conversion back to plain bins upon
  * shrinkage.
  * 大致意思就是说hash冲突默认采用单链表存储，当单链表节点个数大于8时，会转化为红黑树存储
  */
 static final int TREEIFY_THRESHOLD = 8;

 /**
  * The bin count threshold for untreeifying a (split) bin during a
  * resize operation. Should be less than TREEIFY_THRESHOLD, and at
  * most 6 to mesh with shrinkage detection under removal.
  * hash冲突默认采用单链表存储，当单链表节点个数大于8时，会转化 
     为红黑树存储。
* 当红黑树中节点少于6时，则转化为单链表存储
  */
 static final int UNTREEIFY_THRESHOLD = 6;

 /**
  * The smallest table capacity for which bins may be treeified.
  * (Otherwise the table is resized if too many nodes in a bin.)
  * Should be at least 4 * TREEIFY_THRESHOLD to avoid conflicts
  * between resizing and treeification thresholds.
  * hash冲突默认采用单链表存储，当单链表节点个数大于8时，会转化为红黑树存储。
  * 但是有一个前提：要求数组长度大于64，否则不会进行转化
  */
 static final int MIN_TREEIFY_CAPACITY = 64;
```

通过以上代码可以看出初始容量（16）、负载因子以及对数组的说明。数组中的每一个元素其实就是Entry\<K,V>\[] table，Map中的key和value就是以Entry的形式存储的。Entry包含四个属性：key、value、hash值和用于单向链表的next。关于Entry\<K,V>的具体定义参看如下源码：

```java
static class Entry<K,V> implements Map.Entry<K,V> {
    final K key;
    V value;
    Entry<K,V> next;
    int hash;
 
    Entry(int h, K k, V v, Entry<K,V> n) {
        value = v;
        next = n;
        key = k;
        hash = h;
    }
 
    public final K getKey() {
        return key;
    }
 
    public final V getValue() {
        return value;
    }
 
    public final V setValue(V newValue) {
        V oldValue = value;
        value = newValue;
        return oldValue;
    }
 
    public final boolean equals(Object o) {
        if (!(o instanceof Map.Entry))
            return false;
        Map.Entry e = (Map.Entry)o;
        Object k1 = getKey();
        Object k2 = e.getKey();
        if (k1 == k2 || (k1 != null && k1.equals(k2))) {
            Object v1 = getValue();
            Object v2 = e.getValue();
            if (v1 == v2 || (v1 != null && v1.equals(v2)))
                return true;
        }
        return false;
    }
 
    public final int hashCode() {
        return Objects.hashCode(getKey()) ^ Objects.hashCode(getValue());
    }
 
    public final String toString() {
        return getKey() + "=" + getValue();
    }
 
    /**
     * This method is invoked whenever the value in an entry is
     * overwritten by an invocation of put(k,v) for a key k that's already
     * in the HashMap.
     */
    void recordAccess(HashMap<K,V> m) {
    }
 
    /**
     * This method is invoked whenever the entry is
     * removed from the table.
     */
    void recordRemoval(HashMap<K,V> m) {
    }
}
```

##### 负载因子

HashMap的初始值要考虑加载因子:

*   哈希冲突：若干Key的哈希值按数组大小取模后，如果落在同一个数组下标上，将组成一条Entry链，对Key的查找需要遍历Entry链上的每个元素执行equals()比较。
*   加载因子：为了降低哈希冲突的概率，默认当HashMap中的键值对达到数组大小的75%时，即会触发扩容。因此，如果预估容量是100，即需要设定100/0.75＝134的数组大小。
*   空间换时间：如果希望加快Key查找的时间，还可以进一步降低加载因子，加大初始大小，以降低哈希冲突的概率。

HashMap和Hashtable都是用hash算法来决定其元素的存储，因此HashMap和Hashtable的hash表包含如下属性：

*   容量（capacity）：hash表中桶的数量
*   初始化容量（initial capacity）：创建hash表时桶的数量，HashMap允许在构造器中指定初始化容量
*   尺寸（size）：当前hash表中记录的数量
*   负载因子（load factor）：负载因子等于“size/capacity”。负载因子为0，表示空的hash表，0.5表示半满的散列表，依此类推。轻负载的散列表具有冲突少、适宜插入与查询的特点（但是使用Iterator迭代元素时比较慢）

除此之外，hash表里还有一个“负载极限”，“负载极限”是一个0～1的数值，“负载极限”决定了hash表的最大填满程度。当hash表中的负载因子达到指定的“负载极限”时，hash表会自动成倍地增加容量（桶的数量），并将原有的对象重新分配，放入新的桶内，这称为rehashing。

HashMap和Hashtable的构造器允许指定一个负载极限，HashMap和Hashtable默认的“负载极限”为0.75，这表明当该hash表的3/4已经被填满时，hash表会发生rehashing。

“负载极限”的默认值（0.75）是时间和空间成本上的一种折中：

*   `较高`的“负载极限”可以降低hash表所占用的内存空间，但会增加查询数据的时间开销，而查询是最频繁的操作（HashMap的get()与put()方法都要用到查询）
*   `较低`的“负载极限”会提高查询数据的性能，但会增加hash表所占用的内存开销

程序猿可以根据实际情况来调整“负载极限”值。

##### put 流程

当向 HashMap 中 `put`一对键值时，它会根据 key的 hashCode 值计算出一个位置， 该位置就是此对象准备往数组中存放的位置。 该计算过程参看如下代码：

```java
transient int hashSeed = 0;
final int hash(Object k) {
     int h = hashSeed;
     if (0 != h && k instanceof String) {
         return sun.misc.Hashing.stringHash32((String) k);
     }
 
     h ^= k.hashCode();
 
     // This function ensures that hashCodes that differ only by
     // constant multiples at each bit position have a bounded
     // number of collisions (approximately 8 at default load factor).
     h ^= (h >>> 20) ^ (h >>> 12);
     return h ^ (h >>> 7) ^ (h >>> 4);
 }
 
 /**
  * Returns index for hash code h.
  */
 static int indexFor(int h, int length) {
     // assert Integer.bitCount(length) == 1 : "length must be a non-zero power of 2";
     return h & (length-1);
 }
```

通过hash计算出来的值将会使用**indexFor**方法找到它应该所在的table下标。当两个key通过hashCode计算相同时，则发生了hash冲突(碰撞)，HashMap解决hash冲突的方式是用链表(**拉链法**)。当发生hash冲突时，则将存放在数组中的Entry设置为新值的next（这里要注意的是，比如A和B都hash后都映射到下标i中，之前已经有A了，当map.put(B)时，将B放到下标i中，A则为B的next，所以新值存放在数组中，旧值在新值的链表上）。`即将新值作为此链表的头节点`，为什么要这样操作？据说后插入的Entry被查找的可能性更大（因为get查询的时候会遍历整个链表），此处有待考究，如果有哪位大神知道，请留言告知。有一种说法就是链表查找复杂度高，可插入和删除性能高，如果将新值插在末尾，就需要先经过一轮遍历，这个时间复杂度高，开销大，如果是插在头结点，省去了遍历的开销，还发挥了链表插入性能高的优势。

**如果该位置没有对象存在，就将此对象直接放进数组当中；如果该位置已经有对象存在了，则顺着此存在的对象的链开始寻找(为了判断是否值相同，map不允许\<key,value>键值对重复)， 如果此链上有对象的话，再去使用 equals方法进行比较，如果对此链上的每个对象的 equals 方法比较都为 false，则将该对象放到数组当中，然后将数组中该位置以前存在的那个对象链接到此对象的后面。**

`添加节点到链表中`：找到数组下标后，会先进行key判重，如果没有重复，就准备将新值放入到链表的表头。

```java
void addEntry(int hash, K key, V value, int bucketIndex) {
    // 如果当前 HashMap 大小已经达到了阈值，并且新值要插入的数组位置已经有元素了，那么要扩容
    if ((size >= threshold) && (null != table[bucketIndex])) {
        // 扩容
        resize(2 * table.length);
        // 扩容以后，重新计算 hash 值
        hash = (null != key) ? hash(key) : 0;
        // 重新计算扩容后的新的下标
        bucketIndex = indexFor(hash, table.length);
    }
    // 往下看
    createEntry(hash, key, value, bucketIndex);
}
// 这个很简单，其实就是将新值放到链表的表头，然后 size++
void createEntry(int hash, K key, V value, int bucketIndex) {
    Entry<K,V> e = table[bucketIndex];
    table[bucketIndex] = new Entry<>(hash, key, value, e);
    size++;
}
```

这个方法的主要逻辑就是先判断是否需要扩容，需要带的话先扩容，然后再将这个新的数据插入到扩容后的数组的相应位置处的链表的表头。

##### 扩容

扩容就是用一个新的大数组替换原来的小数组，并将原来数组中的值迁移到新的数组中。由于是双倍扩容，迁移过程中，会将原来table\[i]中的链表的所有节点，分拆到新的数组的newTable\[i]和newTable\[i+oldLength]位置上。如原来数组长度是16，那么扩容后，原来table\[0]处的链表中的所有元素会被分配到新数组中newTable\[0]和newTable\[16]这两个位置。扩容期间，由于会新建一个新的空数组，并且用旧的项填充到这个新的数组中去。所以，在这个填充的过程中，如果有线程获取值，很可能会取到 null 值，而不是我们所希望的、原来添加的值。

哈希数组（默认数组大小是16，每对key-value键值对其实是存在map的内部类entry里的），数组的每个元素都是一个单链表的头节点，跟着的蓝色链表是用来解决冲突的，如果不同的key映射到了数组的同一位置处，就将其放入单链表中。

前面说过HashMap的key是允许为null的，当出现这种情况时，会放到table\[0]中。

```java
private V putForNullKey(V value) {
    for (Entry<K,V> e = table[0]; e != null; e = e.next) {
        if (e.key == null) {
            V oldValue = e.value;
            e.value = value;
            e.recordAccess(this);
            return oldValue;
        }
    }
    modCount++;
    addEntry(0, null, value, 0);
    return null;
}
```

当size>=threshold（ threshold等于“容量\*负载因子”）时，会发生`扩容`。

```java
void addEntry(int hash, K key, V value, int bucketIndex) {
    if ((size >= threshold) && (null != table[bucketIndex])) {
        resize(2 * table.length);
        hash = (null != key) ? hash(key) : 0;
        bucketIndex = indexFor(hash, table.length);
    }
 
    createEntry(hash, key, value, bucketIndex);
}
```

`特别提示：jdk1.7中resize，只有当 size>=threshold并且 table中的那个槽中已经有Entry时，才会发生resize`。即有可能虽然size>=threshold，但是必须等到相应的槽至少有一个Entry时，才会扩容,可以通过上面的代码看到每次resize都会扩大一倍容量（2 \* table.length）。

#### jdk1.8中HashMap的实现

在jdk1.8中HashMap的内部结构可以看作是数组(Node\<K,V>\[] table)和链表的复合结构，数组被分为一个个桶（bucket），通过哈希值决定了键值对在这个数组中的寻址（哈希值相同的键值对，则以链表形式存储。有一点需要注意，如果链表大小超过阈值（TREEIFY\_THRESHOLD,8），图中的链表就会被改造为树形（红黑树）结构。

```java
transient Node<K,V>[] table;
```

Entry的名字变成了Node，原因是和红黑树的实现TreeNode相关联。**1.8与1.7最大的不同就是利用了红黑树，即由数组+链表（或红黑树）组成。**

在分析jdk1.7中HashMap的hash冲突时，不知大家是否有个疑问就是万一发生碰撞的节点非常多怎么办？如果说成百上千个节点在hash时发生碰撞，存储一个链表中，那么如果要查找其中一个节点，那就不可避免的花费O(N)的查找时间，这将是多么大的性能损失。这个问题终于在JDK1.8中得到了解决，在最坏的情况下，链表查找的时间复杂度为`O(n)`,而红黑树一直是`O(logn)`,这样会提高HashMap的效率。

jdk1.7中HashMap采用的是位桶+链表的方式，即我们常说的**散列链表**的方式，而jdk1.8中采用的是位桶+链表/红黑树的方式，也是非线程安全的。当某个位桶的链表的长度达到某个阀值的时候，这个链表就将转换成红黑树。

jdk1.8中，当同一个hash值的节点数不小于8时，将不再以单链表的形式存储了，会被调整成一颗红黑树（上图中null节点没画）。这就是jdk1.7与jdk1.8中HashMap实现的最大区别。

HashMap根据链地址法（`拉链法`）来解决冲突，**在jdk1.8中，如果`链表长度大于8且节点数组长度大于64的时候`，就把链表下所有的节点转为红黑树**。

##### put 流程

通过分析put方法的源码，可以让这种区别更直观：

```java
static final int TREEIFY_THRESHOLD = 8;
 
public V put(K key, V value) {
        return putVal(hash(key), key, value, false, true);
 }
  
  
final V putVal(int hash, K key, V value, boolean onlyIfAbsent,
                   boolean evict) {
        Node<K,V>[] tab;
    Node<K,V> p;
    int n, i;
    //如果当前map中无数据，执行resize方法。并且返回n
        if ((tab = table) == null || (n = tab.length) == 0)
            n = (tab = resize()).length;
     //如果要插入的键值对要存放的这个位置刚好没有元素，那么把他封装成Node对象，放在这个位置上即可
        if ((p = tab[i = (n - 1) & hash]) == null)
            tab[i] = newNode(hash, key, value, null);
    //否则的话，说明这上面有元素
        else {
            Node<K,V> e; K k;
        //如果这个元素的key与要插入的一样，那么就替换一下。
            if (p.hash == hash &&
                ((k = p.key) == key || (key != null && key.equals(k))))
                e = p;
        //1.如果当前节点是TreeNode类型的数据，执行putTreeVal方法
            else if (p instanceof TreeNode)
                e = ((TreeNode<K,V>)p).putTreeVal(this, tab, hash, key, value);
            else {
        //还是遍历这条链子上的数据，跟jdk7没什么区别
                for (int binCount = 0; ; ++binCount) {
                    if ((e = p.next) == null) {
                        p.next = newNode(hash, key, value, null);
            //2.完成了操作后多做了一件事情，判断，并且可能执行treeifyBin方法
                        if (binCount >= TREEIFY_THRESHOLD - 1) // -1 for 1st
                            treeifyBin(tab, hash);
                        break;
                    }
                    if (e.hash == hash &&
                        ((k = e.key) == key || (key != null && key.equals(k))))
                        break;
                    p = e;
                }
            }
            if (e != null) { // existing mapping for key
                V oldValue = e.value;
                if (!onlyIfAbsent || oldValue == null) //true || --
                    e.value = value;
           //3.
                afterNodeAccess(e);
                return oldValue;
            }
        }
        ++modCount;
    //判断阈值，决定是否扩容
        if (++size > threshold)
            resize();
        //4.
        afterNodeInsertion(evict);
        return null;
    }
```

以上代码中的特别之处如下：

```java
if (binCount >= TREEIFY_THRESHOLD - 1) // -1 for 1st
       treeifyBin(tab, hash);
```

`treeifyBin()`就是将链表转换成红黑树。

##### 树化操作

树化操作的过程有点复杂，可以结合源码来看看。将原本的单链表转化为双向链表，再遍历这个双向链表转化为红黑树。

```java
final void treeifyBin(Node<K,V>[] tab, int hash) {
     int n, index; Node<K,V> e;
     //树形化还有一个要求就是数组长度必须大于等于64，否则继续采用扩容策略
     if (tab == null || (n = tab.length) < MIN_TREEIFY_CAPACITY)
         resize();
     else if ((e = tab[index = (n - 1) & hash]) != null) {
         TreeNode<K,V> hd = null, tl = null;//hd指向首节点，tl指向尾节点
         do {
             TreeNode<K,V> p = replacementTreeNode(e, null);//将链表节点转化为红黑树节点
            if (tl == null) // 如果尾节点为空，说明还没有首节点
                hd = p;  // 当前节点作为首节点
            else { // 尾节点不为空，构造一个双向链表结构，将当前节点追加到双向链表的末尾
                p.prev = tl; // 当前树节点的前一个节点指向尾节点
                tl.next = p; // 尾节点的后一个节点指向当前节点
            }
            tl = p; // 把当前节点设为尾节点
        } while ((e = e.next) != null); // 继续遍历单链表
        //将原本的单链表转化为一个节点类型为TreeNode的双向链表
        if ((tab[index] = hd) != null) // 把转换后的双向链表，替换数组原来位置上的单向链表
            hd.treeify(tab); // 将当前双向链表树形化
    }
}
```

> 大家要特别注意一点，树化有个要求就是数组长度必须大于等于MIN\_TREEIFY\_CAPACITY（64），否则继续采用扩容策略。

总的来说，HashMap默认采用数组+单链表方式存储元素，当元素出现哈希冲突时，会存储到该位置的单链表中。但是单链表不会一直增加元素，当元素个数超过8个时，会尝试将单链表转化为红黑树存储。但是在转化前，会再判断一次当前数组的长度，只有数组长度大于`64`才处理。否则，进行扩容操作。

将双向链表转化为红黑树的实现：

```java
 final void treeify(Node<K,V>[] tab) {
     TreeNode<K,V> root = null;  // 定义红黑树的根节点
     for (TreeNode<K,V> x = this, next; x != null; x = next) { // 从TreeNode双向链表的头节点开始逐个遍历
         next = (TreeNode<K,V>)x.next; // 头节点的后继节点
         x.left = x.right = null;
         if (root == null) {
             x.parent = null;
             x.red = false;
             root = x; // 头节点作为红黑树的根，设置为黑色
        }
        else { // 红黑树存在根节点
            K k = x.key; 
            int h = x.hash;
            Class<?> kc = null;
            for (TreeNode<K,V> p = root;;) { // 从根开始遍历整个红黑树
                int dir, ph;
                K pk = p.key;
                if ((ph = p.hash) > h) // 当前红黑树节点p的hash值大于双向链表节点x的哈希值
                    dir = -1;
                else if (ph < h) // 当前红黑树节点的hash值小于双向链表节点x的哈希值
                    dir = 1;
                else if ((kc == null &&
                          (kc = comparableClassFor(k)) == null) ||
                         (dir = compareComparables(kc, k, pk)) == 0) // 当前红黑树节点的hash值等于双向链表节点x的哈希值，则如果key值采用比较器一致则比较key值
                    dir = tieBreakOrder(k, pk); //如果key值也一致则比较className和identityHashCode

                TreeNode<K,V> xp = p; 
                if ((p = (dir <= 0) ? p.left : p.right) == null) { // 如果当前红黑树节点p是叶子节点，那么双向链表节点x就找到了插入的位置
                    x.parent = xp;
                    if (dir <= 0) //根据dir的值，插入到p的左孩子或者右孩子
                        xp.left = x;
                    else
                        xp.right = x;
                    root = balanceInsertion(root, x); //红黑树中插入元素，需要进行平衡调整(过程和TreeMap调整逻辑一模一样)
                    break;
                }
            }
        }
    }
    //将TreeNode双向链表转化为红黑树结构之后，由于红黑树是基于根节点进行查找，所以必须将红黑树的根节点作为数组当前位置的元素
    moveRootToFront(tab, root);
}
```

然后将红黑树的根节点移动端数组的索引所在位置上：

```java
static <K,V> void moveRootToFront(Node<K,V>[] tab, TreeNode<K,V> root) {
     int n;
     if (root != null && tab != null && (n = tab.length) > 0) {
         int index = (n - 1) & root.hash; //找到红黑树根节点在数组中的位置
         TreeNode<K,V> first = (TreeNode<K,V>)tab[index]; //获取当前数组中该位置的元素
         if (root != first) { //红黑树根节点不是数组当前位置的元素
             Node<K,V> rn;
             tab[index] = root;
             TreeNode<K,V> rp = root.prev;
            if ((rn = root.next) != null) //将红黑树根节点前后节点相连
                ((TreeNode<K,V>)rn).prev = rp;
            if (rp != null)
                rp.next = rn;
            if (first != null) //将数组当前位置的元素，作为红黑树根节点的后继节点
                first.prev = root;
            root.next = first;
            root.prev = null;
        }
        assert checkInvariants(root);
    }
}
```

`putVal`方法处理的逻辑比较多，包括初始化、扩容、树化，近乎在这个方法中都能体现，针对源码简单讲解下几个关键点：

*   如果Node\<K,V>\[] table是null，resize方法会负责初始化，即如下代码：

```java
if ((tab = table) == null || (n = tab.length) == 0)
    n = (tab = resize()).length;
```

*   resize方法兼顾两个职责，创建初始存储表格，或者在容量不满足需求的时候，进行扩容（resize）。在放置新的键值对的过程中，如果发生下面条件，就会发生扩容。

```java
if (++size > threshold)
    resize();
```

*   具体键值对在哈希表中的位置（数组index）取决于下面的位运算：

```java
i = (n - 1) & hash
```

仔细观察哈希值的源头，会发现它并不是key本身的hashCode，而是来自于HashMap内部的另一个hash方法。**为什么这里需要将高位数据移位到低位进行异或运算呢**？这是因为有些数据计算出的哈希值差异主要在高位，而HashMap里的哈希寻址是忽略容量以上的高位的，那么这种处理就可以有效避免类似情况下的哈希碰撞。

在jdk1.8中取消了indefFor()方法，直接用(tab.length-1)\&hash，所以看到这个，代表的就是数组的下角标。

```java
static final int hash(Object key) {
    int h;
    return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
}
```

为什么HashMap为什么要树化？

之前在极客时间的专栏里看到过一个解释。本质上这是个安全问题。因为在元素放置过程中，如果一个对象哈希冲突，都被放置到同一个桶里，则会形成一个链表，我们知道链表查询是线性的，会严重影响存取的性能。而在现实世界，构造哈希冲突的数据并不是非常复杂的事情，恶意代码就可以利用这些数据大量与服务器端交互，导致服务器端CPU大量占用，这就构成了哈希碰撞拒绝服务攻击，国内一线互联网公司就发生过类似攻击事件。

> 用哈希碰撞发起拒绝服务攻击(DOS，Denial-Of-Service attack),常见的场景是攻击者可以事先构造大量相同哈希值的数据，然后以JSON数据的形式发送给服务器，服务器端在将其构建成为Java对象过程中，通常以Hashtable或HashMap等形式存储，哈希碰撞将导致哈希表发生严重退化，算法复杂度可能上升一个数据级，进而耗费大量CPU资源。

##### 为什么要将链表中转红黑树的阈值设为 8

我们可以这么来看，`当链表长度大于或等于阈值（默认为 8）的时候，如果同时还满足容量大于或等于 MIN_TREEIFY_CAPACITY（默认为 64）的要求，就会把链表转换为红黑树`。同样，后续如果由于删除或者其他原因调整了大小，当红黑树的节点小于或等于 6 个以后，又会恢复为链表形态。

每次遍历一个链表，平均查找的时间复杂度是 O(n)，n 是链表的长度。红黑树有和链表不一样的查找性能，由于红黑树有自平衡的特点，可以防止不平衡情况的发生，所以可以始终将查找的时间复杂度控制在 O(log(n))。最初链表还不是很长，所以可能 O(n) 和 O(log(n)) 的区别不大，但是如果链表越来越长，那么这种区别便会有所体现。所以为了提升查找性能，需要把链表转化为红黑树的形式。

还要注意很重要的一点，单个 TreeNode 需要占用的空间大约是普通 Node 的两倍，所以只有当包含足够多的 Nodes 时才会转成 TreeNodes，而是否足够多就是由 TREEIFY\_THRESHOLD 的值决定的。而当桶中节点数由于移除或者 resize 变少后，又会变回普通的链表的形式，以便节省空间。

默认是链表长度达到 8 就转成红黑树，而当长度降到 6 就转换回去，这体现了`时间和空间平衡的思想`，最开始使用链表的时候，空间占用是比较少的，而且由于链表短，所以查询时间也没有太大的问题。可是当链表越来越长，需要用红黑树的形式来保证查询的效率。

在理想情况下，链表长度符合`泊松分布`，各个长度的命中概率依次递减，当长度为 8 的时候，是最理想的值。

事实上，链表长度超过 8 就转为红黑树的设计，更多的是为了防止用户自己实现了不好的哈希算法时导致链表过长，从而导致查询效率低，而此时转为红黑树更多的是一种保底策略，用来保证极端情况下查询的效率。

通常如果 hash 算法正常的话，那么链表的长度也不会很长，那么红黑树也不会带来明显的查询时间上的优势，反而会增加空间负担。所以通常情况下，并没有必要转为红黑树，所以就选择了概率非常小，小于千万分之一概率，也就是长度为 8 的概率，把长度 8 作为转化的默认阈值。

如果开发中发现 HashMap 内部出现了红黑树的结构，那可能是我们的哈希算法出了问题，所以需要选用合适的hashCode方法，以便减少冲突。

### ConcurrentHashMap

`ConcurrentHashMap` 是 Java 中的一个线程安全的哈希表实现，它属于 `java.util.concurrent` 包。它在多线程环境下提供了比 `HashMap` 更好的性能和并发控制。`ConcurrentHashMap` 的设计目标是提供一个线程安全的哈希表，同时尽量减少锁的使用，以提高并发性能。

以下是 `ConcurrentHashMap` 的一些关键特性：

1.  **线程安全**：底层采用分段的数组+链表实现，`ConcurrentHashMap` 通过使用分段锁（Segmented Locking）来实现线程安全。在早期版本中，它使用了多个锁来保护不同的哈希桶（bucket），这样可以允许多个线程同时访问不同的桶，从而提高并发性能。在 Java 8 及以后的版本中，`ConcurrentHashMap` 采用了更细粒度的锁机制，即使用了 `volatile` 关键字和 CAS（Compare-And-Swap）操作来减少锁的使用，进一步提高了性能。

2.  **分段锁**：在 Java 8 之前，`ConcurrentHashMap` 使用了分段锁技术，将哈希表分成多个段（segment），每个段都有自己的锁。这样，当多个线程需要访问不同的段时，它们可以同时进行，而不会相互阻塞。这种设计允许在多线程环境下进行读写操作，而不会影响到其他线程的操作。但是效率提升N倍，默认提升16倍。(读操作不加锁，由于HashEntry的value变量是 volatile的，也能保证读取到最新的值。)，有些方法需要跨段，比如size()和containsValue()，它们可能需要锁定整个表而而不仅仅是某个段，这需要按顺序锁定所有段，操作完毕后，又按顺序释放所有段的锁

3.  **无锁操作**：在 Java 8 及以后的版本中，`ConcurrentHashMap` 通过使用 `volatile` 关键字和 CAS 操作来实现无锁的读写操作。这使得在没有竞争的情况下，读写操作可以不加锁地进行，从而提高了性能。

4.  **延迟初始化**：`ConcurrentHashMap` 的桶数组（bucket array）是延迟初始化的，这意味着只有在第一次插入元素时，才会创建桶数组。这种设计可以减少不必要的内存分配，尤其是在哈希表初始化后没有立即使用的情况下。

5.  **扩容机制**：`ConcurrentHashMap` 的扩容机制与 `HashMap` 类似，但它是分段进行的。在扩容时，每个段可以独立地进行扩容操作，这样可以减少扩容对性能的影响。段内扩容（段内元素超过该段对应Entry数组长度的75%触发扩容，不会对整个Map进行扩容），插入前检测需不需要扩容，有效避免无效扩容

6.  **迭代器**：`ConcurrentHashMap` 提供了弱一致性的迭代器（Weakly Consistent Iterator）。这意味着迭代器可能不会反映最新的更新，但不会抛出 `ConcurrentModificationException` 异常。这种迭代器适用于不需要实时反映最新状态的场景。

`ConcurrentHashMap` 是一个非常强大的并发数据结构，适用于需要在多线程环境下进行高效读写操作的场景。它在 Java 8 中的实现进行了优化，进一步提高了性能和并发能力。

#### Java 8 中的实现进行了哪些优化

Java 8 对 `ConcurrentHashMap` 的实现进行了显著的优化，这些优化主要集中在提高并发性能和减少内存占用上。以下是 Java 8 中 `ConcurrentHashMap` 实现的一些关键优化：

1.  **无锁化**：Java 8 中的 `ConcurrentHashMap` 引入了无锁（lock-free）和无阻塞（wait-free）的编程技术，特别是在读取操作中。通过使用 `volatile` 关键字和 CAS（Compare-And-Swap）操作，`ConcurrentHashMap` 能够在没有锁的情况下进行读取操作，从而减少了锁的开销和提高了并发性能。

2.  **分段锁的取消**：在 Java 8 之前，`ConcurrentHashMap` 使用了分段锁（segment）来减少锁的粒度，从而提高并发性能。然而，这种设计在某些情况下仍然会导致锁竞争。Java 8 中，`ConcurrentHashMap` 取消了分段锁的概念，转而使用了更细粒度的锁机制，即每个数组元素（桶）都可能有一个锁。这种设计使得在没有竞争的情况下，读写操作可以不加锁地进行，进一步提高了性能。

3.  **数组的延迟初始化**：Java 8 中的 `ConcurrentHashMap` 实现了延迟初始化数组，这意味着只有在第一次插入元素时，才会创建数组。这种设计减少了不必要的内存分配，特别是在哈希表初始化后没有立即使用的情况下。

4.  **扩容机制的优化**：Java 8 中的 `ConcurrentHashMap` 在扩容时采用了更高效的策略。扩容操作现在是分段进行的，每个桶可以独立地进行扩容，这减少了扩容对性能的影响。

5.  **更高效的哈希算法**：Java 8 中的 `ConcurrentHashMap` 使用了更高效的哈希算法，这有助于减少哈希冲突，从而提高性能。

6.  **更简洁的代码**：由于去除了分段锁的概念，Java 8 中的 `ConcurrentHashMap` 代码更加简洁，易于理解和维护。

7.  **更好的迭代器**：Java 8 中的 `ConcurrentHashMap` 提供了更强的迭代器，这些迭代器能够反映最新的更新，同时仍然保持了弱一致性，即在迭代过程中，如果哈希表被修改，迭代器不会抛出 `ConcurrentModificationException` 异常。

这些优化使得 Java 8 中的 `ConcurrentHashMap` 在多线程环境下提供了更好的性能和更灵活的并发控制。

#### ConcurrentHashMap的分段锁是如何实现的

在Java 8中，`ConcurrentHashMap` 的实现已经不再使用分段锁（segment）的概念，而是采用了更细粒度的锁机制。在Java 8之前，`ConcurrentHashMap` 通过分段锁来实现线程安全，每个段（segment）都是一个独立的锁，可以独立地进行读写操作。但在Java 8中，`ConcurrentHashMap` 采用了`Node`数组和`CAS`操作来实现线程安全，同时引入了`TreeNode`和`TreeBin`来处理红黑树结构，以优化性能。

下面，我将结合Java 8中`ConcurrentHashMap`的部分源码来解释其线程安全的实现方式。请注意，由于`ConcurrentHashMap`的实现较为复杂，这里仅提供一个高层次的概述。

```java
// Node是ConcurrentHashMap中的内部类，用于存储键值对
static class Node<K,V> implements Map.Entry<K,V> {
    final int hash;
    final K key;
    volatile V val;
    volatile Node<K,V> next;
    // ... 其他成员和方法 ...
}

// ConcurrentHashMap的主类
public class ConcurrentHashMap<K,V> extends AbstractMap<K,V>
    implements ConcurrentMap<K,V>, Serializable {
    // ... 其他成员和方法 ...

    // Node数组，用于存储键值对
    transient volatile Node<K,V>[] table;

    // 初始化或扩容时的辅助变量
    private transient volatile Node<K,V>[] nextTable;

    // ... 其他成员和方法 ...
}
```

在Java 8中，`ConcurrentHashMap` 使用了`Node`数组来存储键值对。每个`Node`对象代表一个键值对，并且可能指向链表中的下一个节点。当发生哈希冲突时，这些节点会形成链表。如果链表长度超过阈值（默认为8），链表会转换为红黑树以优化性能。

在`ConcurrentHashMap`中，对数组的访问和修改是通过`volatile`关键字来保证内存可见性的，这样可以避免在多线程环境下出现数据不一致的问题。同时，`ConcurrentHashMap`使用了`CAS`操作来实现无锁的并发更新。例如，在`put`方法中，如果发现某个位置的节点为空，会尝试使用`CAS`操作来设置新节点，如果成功则表示更新成功，否则会进行重试。

```java
final V putVal(K key, V value, boolean onlyIfAbsent) {
    // ... 省略部分代码 ...
    for (Node<K,V>[] tab = table;;) {
        Node<K,V> f; int n, i, fh;
        // ... 省略部分代码 ...
        else if ((f = tabAt(tab, i = (n - 1) & hash)) == null) {
            // 如果该位置为空，使用CAS操作设置新节点
            if (casTabAt(tab, i, null,
                         new Node<K,V>(hash, key, value, null)))
                break;                   // no lock when adding to empty bin
        }
        // ... 省略部分代码 ...
    }
    // ... 省略部分代码 ...
}
```

在上述代码中，`tabAt`方法用于获取数组中指定位置的节点，`casTabAt`方法用于使用`CAS`操作设置新节点。如果`CAS`操作成功，则表示成功添加了新节点，否则会进行重试。

`ConcurrentHashMap`的这种设计使得它在多线程环境下能够提供良好的性能和线程安全。它避免了分段锁带来的复杂性和性能开销，同时通过`volatile`和`CAS`操作保证了数据的一致性和线程安全。

### 分析Hashtable、HashMap、TreeMap的区别

*   `HashMap`是继承自`AbstractMap`类，而`HashTable`是继承自`Dictionary`类。不过它们都同时实现了map、Cloneable（可复制）、Serializable（可序列化）这三个接口。存储的内容是基于key-value的键值对映射，不能有重复的key，而且一个key只能映射一个value。HashSet底层就是基于HashMap实现的。
*   Hashtable的key、value都不能为null；HashMap的key、value可以为null，不过只能有一个key为null，但可以有多个null的value；TreeMap键、值都不能为null。
*   Hashtable、HashMap具有**无序**特性。TreeMap是利用`红黑树`实现的（树中的每个节点的值都会大于或等于它的左子树中的所有节点的值，并且小于或等于它的右子树中的所有节点的值），实现了SortMap接口，能够对保存的记录根据键进行排序。所以一般需求排序的情况下首选TreeMap，`默认按键的升序排序`（深度优先搜索），也可以自定义实现Comparator接口实现排序方式。

一般情况下我们选用HashMap，因为HashMap的键值对在取出时是随机的，其依据键的hashCode和键的equals方法存取数据，具有很快的访问速度，所以在Map中插入、删除及索引元素时其是效率最高的实现。而TreeMap的键值对在取出时是排过序的，所以效率会低点。

`TreeMap`是基于红黑树的一种提供顺序访问的Map，与HashMap不同的是它的get、put、remove之类操作都是o(log(n))的时间复杂度，具体顺序可以由指定的Comparator来决定，或者根据键的自然顺序来判断。

**对HashMap做下总结**：
HashMap基于哈希散列表实现 ，可以实现对数据的读写。**将键值对传递给put方法时，它调用键对象的hashCode()方法来计算hashCode，然后找到相应的bucket位置（即数组）来储存值对象。当获取对象时，通过键对象的equals()方法找到正确的键值对，然后返回值对象**。HashMap使用链表来解决hash冲突问题，当发生冲突了，对象将会储存在链表的头节点中。HashMap在每个链表节点中储存键值对对象，当两个不同的键对象的hashCode相同时，它们会储存在同一个bucket位置的链表中，如果链表大小超过阈值（TREEIFY\_THRESHOLD,8），链表就会被改造为树形结构。

**有个问题要特别声明下**：

*   HashMap在jdk1.7中采用**表头插入法**，在扩容时会**改变**链表中元素原本的顺序，以至于在并发场景下导致链表成环的问题。
*   在jdk1.8中采用的是**尾部插入法**，在扩容时会保持链表元素原本的顺序，就不会出现链表成环的问题了。

**我们可以简单列下HashMap在1.7和1.8之间的变化：**

*   1.7中采用数组+链表，1.8采用的是数组+链表/红黑树，即在1.7中链表长度超过一定长度后就改成红黑树存储。
*   1.7扩容时需要重新计算哈希值和索引位置，1.8并不重新计算哈希值，巧妙地采用和扩容后容量进行&操作来计算新的索引位置。
*   1.7是采用表头插入法插入链表，1.8采用的是尾部插入法。
*   在1.7中采用表头插入法，在扩容时会改变链表中元素原本的顺序，以至于在并发场景下导致链表成环的问题；在1.8中采用尾部插入法，在扩容时会保持链表元素原本的顺序，就不会出现链表成环的问题了。

### HashMap和HashTable和ConcurrentHashMap的区别

`HashMap`、`HashTable` 和 `ConcurrentHashMap` 都是 Java 中用于存储键值对的集合类，它们都实现了 `Map` 接口。但它们在实现细节、线程安全性和性能方面存在显著差异。下面是它们之间的一些主要区别：

1.  **线程安全**：
    *   `HashMap` 是非线程安全的，不保证在多线程环境下的操作是安全的。
    *   `HashTable` 是线程安全的，其所有方法都通过同步机制（synchronized）来保证线程安全。这意味着在多线程环境下，每次只有一个线程可以访问 `HashTable`，这会降低并发性能。
    *   `ConcurrentHashMap` 是线程安全的，但它的实现方式比 `HashTable` 更为精细。它使用了分段锁（Segmented Locking）技术，允许多个读操作同时进行，以及对不同段的写操作同时进行，从而提高了并发性能。

2.  **性能**：
    *   `HashMap` 在单线程环境下性能最好，因为它没有同步开销。
    *   `HashTable` 由于同步机制，性能较差，尤其是在多线程环境下。
    *   `ConcurrentHashMap` 在多线程环境下性能最好，因为它使用了分段锁，减少了锁的粒度，提高了并发性能。

3.  **null 值**：
    *   `HashMap` 允许键和值为 `null`。
    *   `HashTable` 不允许键或值为 `null`，尝试插入 `null` 值会抛出 `NullPointerException`。
    *   `ConcurrentHashMap` 也允许键和值为 `null`，但不建议使用 `null` 值，因为这可能会导致混淆。

4.  **迭代器**：
    *   `HashMap` 的迭代器是快速失败的（fail-fast），如果在迭代过程中集合被修改，迭代器会抛出 `ConcurrentModificationException`。
    *   `HashTable` 的迭代器不是快速失败的，但它的 `entrySet().iterator()` 返回的迭代器是快速失败的。
    *   `ConcurrentHashMap` 的迭代器也是快速失败的。

5.  **初始容量和负载因子**：
    *   `HashMap`、`HashTable` 和 `ConcurrentHashMap` 都允许在构造时指定初始容量和负载因子，但它们的默认值可能不同。例如，`HashMap` 的默认初始容量是 16，负载因子是 0.75，而 `ConcurrentHashMap` 的默认初始容量是 16，负载因子是 0.75，但 `HashTable` 的默认初始容量是 11，负载因子也是 0.75。

6.  **计算index的方法**：
    *   `HashTable`:index = (hash & 0x7FFFFFFF) % tab.length
    *   `HashMap`:index = hash & (tab.length – 1)

### 为什么 ConcurrentHashMap 和 HashMap 的初始容量为 16 但 HashTable 的默认初始容量却是 11

`HashMap` 和 `ConcurrentHashMap` 的默认初始容量为 16，而 `HashTable` 的默认初始容量为 11，这主要是因为它们在设计时采用了不同的哈希策略和冲突解决机制。

1.  **HashMap 和 ConcurrentHashMap**:
    *   **容量为2的幂次**：`HashMap` 和 `ConcurrentHashMap` 的默认容量设置为 16，且总是2的幂次，这是为了优化哈希表的性能。当容量为2的幂次时，可以利用位运算来计算哈希值对应的数组索引，这样可以提高效率。例如，通过 `(n - 1) & hash` 来计算索引，其中 `n` 是数组的长度，`hash` 是元素的哈希值。当 `n` 是2的幂次时，`(n - 1)` 是一个全1的二进制数，这样可以确保哈希值的低位与 `(n - 1)` 进行位与操作时，能够均匀地分布到数组的不同位置，从而减少哈希冲突。
    *   **负载因子**：`HashMap` 和 `ConcurrentHashMap` 的默认负载因子都是 0.75，这意味着当哈希表中的元素数量达到容量的75%时，会进行扩容操作，以保持哈希表的性能。

2.  **HashTable**:
    *   **容量为质数**：`HashTable` 的默认容量为 11，且总是质数。这是因为质数的特性使得它们在哈希函数中可以提供更好的分布效果，从而减少哈希冲突。在早期的 `HashTable` 实现中，使用质数作为容量可以提高哈希表的性能，尤其是在处理大量数据时。
    *   **负载因子**：`HashTable` 的默认负载因子也是 0.75，与 `HashMap` 和 `ConcurrentHashMap` 相同。

总结来说，`HashMap` 和 `ConcurrentHashMap` 选择2的幂次作为默认容量，主要是为了利用位运算来优化哈希计算和索引计算的效率。而 `HashTable` 选择质数作为默认容量，是为了利用质数在哈希函数中的分布特性来减少冲突。尽管 `HashTable` 的设计在某些方面与 `HashMap` 和 `ConcurrentHashMap` 不同，但它们都是为了实现高效、安全的哈希表数据结构。随着Java版本的更新，`HashTable` 的使用已经不如 `HashMap` 和 `ConcurrentHashMap` 那么广泛，因为后者提供了更好的并发性能和更灵活的配置选项。

## set

### TreeSet

`TreeSet` 是 Java 集合框架中的一个类，它实现了 `Set` 接口，基于红黑树的数据结构来存储元素。`TreeSet` 提供了元素的自动排序功能，这意味着当你向 `TreeSet` 添加元素时，这些元素会根据它们的自然顺序（如果元素实现了 `Comparable` 接口）或者根据提供的 `Comparator`（如果元素没有实现 `Comparable` 接口）进行排序。

`TreeSet` 的特点包括：

1.  **自动排序**：`TreeSet` 会自动根据元素的自然顺序或提供的 `Comparator` 对元素进行排序。这意味着当你遍历 `TreeSet` 时，元素会按照排序后的顺序出现。

2.  **不允许重复元素**：`TreeSet` 是一个不允许重复元素的集合，如果尝试添加一个已经存在于集合中的元素，该操作将不会有任何效果。

3.  **基于红黑树**：`TreeSet` 内部使用红黑树来存储元素。红黑树是一种自平衡的二叉查找树，它保证了最坏情况下的时间复杂度为 O(log n)，这使得 `TreeSet` 在添加、删除和查找元素时都具有较高的效率。

4.  **线程不安全**：`TreeSet` 不是线程安全的，如果需要在多线程环境中使用，需要额外的同步机制。

5.  **无序迭代**：虽然 `TreeSet` 会根据元素的自然顺序或 `Comparator` 对元素进行排序，但迭代器返回的元素顺序是固定的，即按照排序后的顺序。

下面是一个简单的 `TreeSet` 使用示例：

```java
import java.util.TreeSet;
import java.util.Comparator;

public class TreeSetExample {
    public static void main(String[] args) {
        // 使用自然顺序
        TreeSet<Integer> naturalOrderSet = new TreeSet<>();
        naturalOrderSet.add(5);
        naturalOrderSet.add(3);
        naturalOrderSet.add(9);
        System.out.println("Natural order set: " + naturalOrderSet);

        // 使用自定义比较器
        TreeSet<Integer> customComparatorSet = new TreeSet<>(new Comparator<Integer>() {
            @Override
            public int compare(Integer o1, Integer o2) {
                return o2.compareTo(o1); // 降序排序
            }
        });
        customComparatorSet.add(5);
        customComparatorSet.add(3);
        customComparatorSet.add(9);
        System.out.println("Custom comparator set: " + customComparatorSet);
    }
}
```

在上述代码中，我们创建了两个 `TreeSet` 实例，一个使用自然顺序，另一个使用自定义的比较器来实现降序排序。`TreeSet` 的使用非常简单，只需要添加元素即可，它会自动处理排序和去重。

# java IO

## IO 原理

在传统的I/O操作中，数据传输通常涉及用户空间和内核空间之间的数据复制。为了理解这一过程，我们需要先了解操作系统中用户空间和内核空间的概念。

**用户空间与内核空间**

在现代操作系统中，内存空间被分为两个主要部分：

1. **用户空间（User Space）**：这是应用程序运行的地方。用户空间中的代码不能直接访问硬件资源，也不能执行特权操作。用户空间的程序通过系统调用（System Calls）请求操作系统内核来执行这些操作。

2. **内核空间（Kernel Space）**：这是操作系统内核运行的地方。内核空间拥有对硬件资源的直接访问权限，并负责管理系统的资源，如CPU、内存、磁盘等。内核空间可以执行特权操作，如管理文件系统、网络通信、进程调度等。

**数据复制过程**

在传统的I/O操作中，数据从一个设备（如磁盘、网络接口等）传输到用户空间的过程通常涉及以下步骤：

1. **应用程序发起I/O请求**：应用程序通过系统调用请求操作系统内核读取数据。

2. **数据从设备传输到内核空间**：内核空间负责从设备读取数据。数据首先被读入内核空间的缓冲区。

3. **数据从内核空间复制到用户空间**：内核将数据从其缓冲区复制到应用程序在用户空间分配的缓冲区中。

4. **应用程序处理数据**：应用程序现在可以处理这些数据。

5. **数据写回操作**：如果应用程序需要将数据写回磁盘或发送到网络，这个过程会重复，数据首先从用户空间复制到内核空间的缓冲区，然后由内核负责将数据写入设备。

**为什么需要复制数据？**

数据在用户空间和内核空间之间复制的原因是出于安全和隔离的考虑。操作系统通过这种方式确保用户空间的程序不能直接访问或修改内核空间的数据，从而保护系统的稳定性和安全性。此外，这种隔离也使得操作系统可以更有效地管理资源和执行任务。

**性能影响**

尽管这种数据复制机制提供了必要的安全性和隔离性，但它也带来了性能开销。每次数据从内核空间复制到用户空间，或者从用户空间复制到内核空间，都会消耗CPU资源和时间。在处理大量数据或进行高吞吐量的I/O操作时，这种开销可能会成为性能瓶颈。

为了解决这个问题，现代操作系统和编程语言提供了多种优化技术，例如：

- **零拷贝（Zero-Copy）技术**：通过减少数据在用户空间和内核空间之间的复制次数来提高性能。例如，直接从内核空间的缓冲区将数据发送到网络接口，而不需要先复制到用户空间。

- **内存映射（Memory-Mapped Files）**：允许文件数据直接映射到用户空间的内存地址，应用程序可以直接读写这些内存地址，从而避免了数据在用户空间和内核空间之间的复制。

- **异步I/O（Asynchronous I/O）**：允许应用程序在I/O操作进行时继续执行其他任务，而不是等待I/O操作完成。这样可以提高应用程序的响应性和吞吐量。

通过这些技术，现代系统能够更有效地处理I/O操作，减少不必要的数据复制，从而提高整体性能。

## 内存映射文件

内存映射文件（Memory-Mapped Files）是一种允许文件数据直接映射到用户空间内存的技术。这种技术通过操作系统内核将文件的一部分或全部映射到进程的虚拟地址空间中，使得文件数据看起来像是进程内存的一部分。当应用程序访问这些内存地址时，实际上是在访问文件数据，而不需要进行数据在用户空间和内核空间之间的显式复制。

**内存映射文件的工作原理**

1. **映射文件到内存**：操作系统内核将文件的特定区域映射到进程的虚拟地址空间。这通常通过`mmap`系统调用实现。

2. **访问映射区域**：应用程序通过普通的内存访问指令（如读取或写入操作）来访问映射区域。这些操作实际上是对文件数据的访问。

3. **内核处理访问**：当应用程序访问映射区域时，如果数据不在物理内存中（即发生了页面错误），内核会从磁盘读取相应的数据到物理内存，并更新页表，使得虚拟地址映射到正确的物理地址。

4. **数据修改**：如果应用程序修改了映射区域的数据，这些修改会直接反映到物理内存中。当数据被修改后，内核会标记这些页面为“脏”（dirty），表示它们需要被写回到磁盘。

5. **同步到磁盘**：当需要将脏页面写回到磁盘时，内核会负责将这些数据写回文件。这个过程是异步的，应用程序可以继续执行其他任务。

**为什么内存映射文件能避免数据复制**

内存映射文件之所以能避免数据在用户空间和内核空间之间的复制，是因为它利用了虚拟内存管理机制。当应用程序访问映射区域时，实际上是在访问内核管理的物理内存，而不是直接访问磁盘上的文件。这样，数据的读取和写入操作都是在内核空间内部完成的，不需要将数据从内核空间复制到用户空间，或者反过来。

**优点**

- **性能提升**：由于避免了数据在用户空间和内核空间之间的复制，内存映射文件可以显著提高文件I/O操作的性能。

- **简化编程**：应用程序可以像操作普通内存一样操作文件数据，简化了文件I/O的编程模型。

- **共享内存**：多个进程可以映射同一个文件，实现进程间的共享内存通信。

**注意事项**

- **内存管理**：虽然内存映射文件可以提高性能，但需要谨慎管理内存使用，因为映射的文件会占用进程的虚拟地址空间。

- **同步问题**：由于数据修改是异步写回磁盘的，需要确保数据的一致性和完整性，可能需要使用同步机制（如`msync`系统调用）。

- **文件大小限制**：映射的文件大小受到系统可用内存和虚拟地址空间大小的限制。

内存映射文件是现代操作系统中一种高效的文件I/O技术，它通过减少数据复制和利用虚拟内存管理机制来提高性能。然而，它也要求开发者了解其工作原理和限制，以确保正确和高效地使用。

## java 中 io 底层的执行流程

[深入理解javaio读写原理及底层流程 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/442239987)

**Java IO读写原理**

无论是Socket的读写还是文件的读写，在Java层面的应用开发或者是linux系统底层开发，都属于输入input和输出output的处理，简称为IO读写。在原理上和处理流程上，都是一致的。区别在于参数的不同。

用户程序进行IO的读写，基本上会用到read\&write两大系统调用。可能不同操作系统，名称不完全一样，但是功能是一样的。

先强调一个基础知识：read系统调用，并不是把数据直接从物理设备，读数据到内存。write系统调用，也不是直接把数据，写入到物理设备。

read系统调用，是把数据从内核缓冲区复制到进程缓冲区；而write系统调用，是把数据从进程缓冲区复制到内核缓冲区。这个两个系统调用，都不负责数据在内核缓冲区和磁盘之间的交换。底层的读写交换，是由操作系统kernel内核完成的。

**内核态（Kernel Mode）和用户态（User Mode）**

在现代操作系统中，为了保护系统资源和提高安全性，通常会将CPU的运行模式分为内核态和用户态。

1.  **用户态（User Mode）**：这是应用程序运行的模式，它限制了应用程序可以执行的指令和访问的内存区域。在用户态下，应用程序不能直接执行某些特权指令，比如直接访问硬件设备、修改系统数据结构等。这样可以防止应用程序错误或恶意行为对系统造成损害。

2.  **内核态（Kernel Mode）**：这是操作系统内核运行的模式，拥有对硬件资源的完全访问权限。当应用程序需要执行一些需要特权的操作时，比如文件读写、网络通信、设备驱动操作等，它必须通过系统调用（System Call）来请求操作系统内核的帮助。系统调用是操作系统提供的接口，允许用户态程序请求内核态服务。

当系统调用发生时，操作系统会执行以下步骤：

*   **保存当前进程的状态**：操作系统会保存当前用户态程序的寄存器状态、程序计数器等信息，以便在系统调用完成后能够恢复到之前的状态继续执行。
*   **切换到内核态**：CPU模式切换到内核态，以便执行系统调用请求的操作。
*   **执行系统调用**：操作系统内核执行请求的操作，比如读取文件、分配内存等。
*   **恢复用户态程序的状态**：系统调用完成后，操作系统会恢复之前保存的用户态程序的状态信息，包括寄存器、程序计数器等。
*   **返回用户态**：CPU模式切换回用户态，用户态程序继续执行。

这个过程确保了系统资源的安全性和程序的正确执行。通过这种方式，操作系统能够有效地管理资源，同时为应用程序提供必要的服务。

**内核缓冲与进程缓冲区**

缓冲区的目的，是为了减少频繁的系统IO调用。大家都知道，系统调用需要保存之前的进程数据和状态等信息，而结束调用之后回来还需要恢复之前的信息，即操作系统中的内核态（Kernel Mode）和用户态（User Mode）之间的转换，为了减少这种损耗时间、也损耗性能的系统调用，于是出现了缓冲区。

有了缓冲区，操作系统使用read函数把数据从内核缓冲区复制到进程缓冲区，write把数据从进程缓冲区复制到内核缓冲区中。等待缓冲区达到一定数量的时候，再进行IO的调用，提升性能。至于什么时候读取和存储则由内核来决定，用户程序不需要关心。

在linux系统中，系统内核也有个缓冲区叫做内核缓冲区。每个进程有自己独立的缓冲区，叫做进程缓冲区。

所以，用户程序的IO读写程序，大多数情况下，并没有进行实际的IO操作，而是在读写自己的进程缓冲区。

**java IO读写的底层流程**

用户程序进行IO的读写，基本上会用到系统调用read\&write，read把数据从内核缓冲区复制到进程缓冲区，write把数据从进程缓冲区复制到内核缓冲区，它们不等价于数据在内核缓冲区和磁盘之间的交换。

![v2-2d43966234dc1bedb3dee6cd94f7cbba\_r](https://raw.githubusercontent.com/MrSunflowers/images/main/note/images/202406161703450.jpg)

首先看看一个典型Java 服务端处理网络请求的典型过程：

（1）客户端请求

Linux通过网卡，读取客户断的请求数据，将数据读取到内核缓冲区。

（2）获取请求数据

服务器从内核缓冲区读取数据到Java进程缓冲区。

（1）服务器端业务处理

Java服务端在自己的用户空间中，处理客户端的请求。

（2）服务器端返回数据

Java服务端已构建好的响应，从用户缓冲区写入系统缓冲区。

（3）发送给客户端

Linux内核通过网络 I/O ，将内核缓冲区中的数据，写入网卡，网卡通过底层的通讯协议，会将数据发送给目标客户端。

**四种主要的IO模型**

服务器端编程经常需要构造高性能的IO模型，常见的IO模型有四种：

（1）同步阻塞IO（Blocking IO）

首先，解释一下这里的阻塞与非阻塞：

阻塞IO，指的是需要内核IO操作彻底完成后，才返回到用户空间，执行用户的操作。阻塞指的是用户空间程序的执行状态，用户空间程序需等到IO操作彻底完成。传统的IO模型都是同步阻塞IO。在java中，默认创建的socket都是阻塞的。

其次，解释一下同步与异步：

同步IO，是一种用户空间与内核空间的调用发起方式。同步IO是指用户空间线程是主动发起IO请求的一方，内核空间是被动接受方。异步IO则反过来，是指内核kernel是主动发起IO请求的一方，用户线程是被动接受方。

（4）同步非阻塞IO（Non-blocking IO）

非阻塞IO，指的是用户程序不需要等待内核IO操作完成后，内核立即返回给用户一个状态值，用户空间无需等到内核的IO操作彻底完成，可以立即返回用户空间，执行用户的操作，处于非阻塞的状态。

简单的说：阻塞是指用户空间（调用线程）一直在等待，而且别的事情什么都不做；非阻塞是指用户空间（调用线程）拿到状态就返回，IO操作可以干就干，不可以干，就去干的事情。

非阻塞IO要求socket被设置为NONBLOCK。

强调一下，这里所说的NIO（同步非阻塞IO）模型，并非Java的NIO（New IO）库。

（3）IO多路复用（IO Multiplexing）

即经典的Reactor设计模式，有时也称为异步阻塞IO，Java中的Selector和Linux中的epoll都是这种模型。

（5）异步IO（Asynchronous IO）

异步IO，指的是用户空间与内核空间的调用方式反过来。用户空间线程是变成被动接受的，内核空间是主动调用者。

这一点，有点类似于Java中比较典型的模式是回调模式，用户空间线程向内核空间注册各种IO事件的回调函数，由内核去主动调用。

**同步阻塞IO（Blocking IO）**

在linux中的Java进程中，默认情况下所有的socket都是blocking IO。在阻塞式 I/O 模型中，应用程序在从IO系统调用开始，一直到到系统调用返回，这段时间是阻塞的。返回成功后，应用进程开始处理用户空间的缓存数据。

![img](https://raw.githubusercontent.com/MrSunflowers/images/main/note/images/202406161705643.jpeg)

举个栗子，发起一个blocking socket的read读操作系统调用，流程大概是这样：

（1）当用户线程调用了read系统调用，内核（kernel）就开始了IO的第一个阶段：准备数据。很多时候，数据在一开始还没有到达（比如，还没有收到一个完整的Socket数据包），这个时候kernel就要等待足够的数据到来。

（2）当kernel一直等到数据准备好了，它就会将数据从kernel内核缓冲区，拷贝到用户缓冲区（用户内存），然后kernel返回结果。

（3）从开始IO读的read系统调用开始，用户线程就进入阻塞状态。一直到kernel返回结果后，用户线程才解除block的状态，重新运行起来。

所以，blocking IO的特点就是在内核进行IO执行的两个阶段，用户线程都被block了。

BIO的优点：

程序简单，在阻塞等待数据期间，用户线程挂起。用户线程基本不会占用 CPU 资源。

BIO的缺点：

一般情况下，会为每个连接配套一条独立的线程，或者说一条线程维护一个连接成功的IO流的读写。在并发量小的情况下，这个没有什么问题。但是，当在高并发的场景下，需要大量的线程来维护大量的网络连接，内存、线程切换开销会非常巨大。因此，基本上，BIO模型在高并发场景下是不可用的。

**同步非阻塞NIO（None Blocking IO）**

在linux系统下，可以通过设置socket使其变为non-blocking。NIO 模型中应用程序在一旦开始IO系统调用，会出现以下两种情况：

（1）在内核缓冲区没有数据的情况下，系统调用会立即返回，返回一个调用失败的信息。

（2）在内核缓冲区有数据的情况下，是阻塞的，直到数据从内核缓冲复制到用户进程缓冲。复制完成后，系统调用返回成功，应用进程开始处理用户空间的缓存数据。

![img](https://raw.githubusercontent.com/MrSunflowers/images/main/note/images/202406161706092.jpeg)

举个栗子。发起一个non-blocking socket的read读操作系统调用，流程是这个样子：

（1）在内核数据没有准备好的阶段，用户线程发起IO请求时，立即返回。用户线程需要不断地发起IO系统调用。

（2）内核数据到达后，用户线程发起系统调用，用户线程阻塞。内核开始复制数据。它就会将数据从kernel内核缓冲区，拷贝到用户缓冲区（用户内存），然后kernel返回结果。

（3）用户线程才解除block的状态，重新运行起来。经过多次的尝试，用户线程终于真正读取到数据，继续执行。

NIO的特点：

应用程序的线程需要不断的进行 I/O 系统调用，轮询数据是否已经准备好，如果没有准备好，继续轮询，直到完成系统调用为止。

NIO的优点：每次发起的 IO 系统调用，在内核的等待数据过程中可以立即返回。用户线程不会阻塞，实时性较好。

NIO的缺点：需要不断的重复发起IO系统调用，这种不断的轮询，将会不断地询问内核，这将占用大量的 CPU 时间，系统资源利用率较低。

总之，NIO模型在高并发场景下，也是不可用的。一般 Web 服务器不使用这种 IO 模型。一般很少直接使用这种模型，而是在其他IO模型中使用非阻塞IO这一特性。java的实际开发中，也不会涉及这种IO模型。

再次说明，Java NIO（New IO） 不是IO模型中的NIO模型，而是另外的一种模型，叫做IO多路复用模型（ IO multiplexing ）。

**IO多路复用模型(I/O multiplexing）**

如何避免同步非阻塞NIO模型中轮询等待的问题呢？这就是IO多路复用模型。

IO多路复用模型，就是通过一种新的系统调用，一个进程可以监视多个文件描述符，一旦某个描述符就绪（一般是内核缓冲区可读/可写），内核kernel能够通知程序进行相应的IO系统调用。

目前支持IO多路复用的系统调用，有 select，epoll等等。select系统调用，是目前几乎在所有的操作系统上都有支持，具有良好跨平台特性。epoll是在linux 2.6内核中提出的，是select系统调用的linux增强版本。

IO多路复用模型的基本原理就是select/epoll系统调用，单个线程不断的轮询select/epoll系统调用所负责的成百上千的socket连接，当某个或者某些socket网络连接有数据到达了，就返回这些可以读写的连接。因此，好处也就显而易见了——通过一次select/epoll系统调用，就查询到到可以读写的一个甚至是成百上千的网络连接。

IO多路复用模型是一种高效的网络编程技术，它允许单个线程或进程同时管理多个网络连接。这种模型的核心思想是**利用操作系统的内核机制**来监视多个socket连接的状态，当这些连接中有数据可读或可写时，操作系统会通知应用程序，从而避免了应用程序对每个socket进行轮询检查的低效做法。

select和epoll是两种常见的IO多路复用技术，它们在不同的操作系统中实现略有不同，但基本原理相似。

1.  **select系统调用**：
    *   select系统调用是较早的IO多路复用技术，它允许应用程序监视一组文件描述符（包括socket）的状态。
    *   应用程序调用select时，需要提供一个文件描述符集合，内核会检查这些文件描述符是否有事件发生（比如可读、可写或异常）。
    *   如果没有事件发生，select调用会阻塞，直到至少有一个文件描述符满足条件。
    *   当有事件发生时，select返回，应用程序可以遍历文件描述符集合，找出哪些描述符有事件发生，然后进行相应的处理。

2.  **epoll系统调用**：
    *   epoll是Linux特有的IO多路复用技术，相比select，它在处理大量文件描述符时更加高效。
    *   epoll使用一个事件表来管理所有被监视的文件描述符，应用程序可以添加、删除或修改事件表中的文件描述符。
    *   epoll有两种工作模式：水平触发（LT）和边缘触发（ET）。水平触发是默认模式，类似于select，只要有数据可读或可写，就会通知应用程序；边缘触发则只有在状态改变时才会通知。
    *   epoll通过内核事件通知机制，减少了不必要的系统调用和上下文切换，提高了性能。

**IO多路复用模型的好处**：

*   **提高效率**：通过单个线程或进程管理多个socket连接，减少了线程或进程的创建和上下文切换的开销。
*   **资源节省**：不需要为每个socket分配一个线程或进程，节省了系统资源。
*   **易于编程**：相比于多线程或多进程模型，IO多路复用模型的编程模型更加简单，易于理解和维护。

综上所述，IO多路复用模型通过select/epoll这样的系统调用，使得单个线程能够高效地管理多个网络连接，从而提高了网络服务的性能和可扩展性。

因此，IO多路复用模型是一种操作系统层面的优化。它利用了操作系统的内核提供的机制来提高网络编程的效率和性能

举个栗子。发起一个多路复用IO的的read读操作系统调用，流程是这个样子：

![img](https://raw.githubusercontent.com/MrSunflowers/images/main/note/images/202406161706487.jpeg)

在这种模式中，首先不是进行read系统调动，而是进行select/epoll系统调用。当然，这里有一个前提，需要将目标网络连接，提前注册到select/epoll的可查询socket列表中。然后，才可以开启整个的IO多路复用模型的读流程。

（1）进行select/epoll系统调用，查询可以读的连接。kernel会查询所有select的可查询socket列表，当任何一个socket中的数据准备好了，select就会返回。

当用户进程调用了select，那么整个线程会被block（阻塞掉）。

（2）用户线程获得了目标连接后，发起read系统调用，用户线程阻塞。内核开始复制数据。它就会将数据从kernel内核缓冲区，拷贝到用户缓冲区（用户内存），然后kernel返回结果。

（3）用户线程才解除block的状态，用户线程终于真正读取到数据，继续执行。

多路复用IO的特点：

IO多路复用模型，建立在操作系统kernel内核能够提供的多路分离系统调用select/epoll基础之上的。多路复用IO需要用到两个系统调用（system call）， 一个select/epoll查询调用，一个是IO的读取调用。

和NIO模型相似，多路复用IO需要轮询。负责select/epoll查询调用的线程，需要不断的进行select/epoll轮询，查找出可以进行IO操作的连接。

另外，多路复用IO模型与前面的NIO模型，是有关系的。对于每一个可以查询的socket，一般都设置成为non-blocking模型。只是这一点，对于用户程序是透明的（不感知）。

多路复用IO的优点：

用select/epoll的优势在于，它可以同时处理成千上万个连接（connection）。与一条线程只绑定一个连接相比，I/O多路复用技术的最大优势是：系统不必创建线程，也不必维护这些线程，从而大大减小了系统的开销。

Java的NIO（new IO）技术，使用的就是IO多路复用模型。在linux系统上，使用的是epoll系统调用。

多路复用IO的缺点：

本质上，select/epoll系统调用，属于同步IO，也是阻塞IO。都需要在读写事件就绪后，自己负责进行读写，也就是说这个读写过程是阻塞的。

既在同步IO模型中，包括select和epoll在内的IO多路复用技术，虽然可以同时监控多个socket，但当某个socket上的数据就绪时，应用程序仍需要自己负责将数据从内核空间的缓冲区复制到用户空间的缓冲区。这个过程是阻塞的，意味着应用程序在数据复制期间无法执行其他任务。

如何充分的解除线程的阻塞呢？那就是异步IO模型。

**异步IO模型（asynchronous IO）**

如何进一步提升效率，解除最后一点阻塞呢？这就是异步IO模型，全称asynchronous I/O，简称为AIO。

AIO的基本流程是：用户线程通过系统调用，告知kernel内核启动某个IO操作，用户线程返回。kernel内核在整个IO操作（包括数据准备、数据复制）完成后，通知用户程序，用户执行后续的业务操作。

kernel的数据准备是将数据从网络物理设备（网卡）读取到内核缓冲区；kernel的数据复制是将数据从内核缓冲区拷贝到用户程序空间的缓冲区。

![img](https://raw.githubusercontent.com/MrSunflowers/images/main/note/images/202406161707336.jpeg)

（1）当用户线程调用了read系统调用，立刻就可以开始去做其它的事，用户线程不阻塞。

（2）内核（kernel）就开始了IO的第一个阶段：准备数据。当kernel一直等到数据准备好了，它就会将数据从kernel内核缓冲区，拷贝到用户缓冲区（用户内存）。

（3）kernel会给用户线程发送一个信号（signal），或者回调用户线程注册的回调接口，告诉用户线程read操作完成了。

（4）用户线程读取用户缓冲区的数据，完成后续的业务操作。

异步IO模型的特点：

在内核kernel的等待数据和复制数据的两个阶段，用户线程都不是block(阻塞)的。用户线程需要接受kernel的IO操作完成的事件，或者说注册IO操作完成的回调函数，到操作系统的内核。所以说，异步IO有的时候，也叫做信号驱动 IO 。

异步IO模型缺点：

需要完成事件的注册与传递，这里边需要底层操作系统提供大量的支持，去做大量的工作。

目前来说， Windows 系统下通过 IOCP 实现了真正的异步 I/O。但是，就目前的业界形式来说，Windows 系统，很少作为百万级以上或者说高并发应用的服务器操作系统来使用。

而在 Linux 系统下，异步IO模型在2.6版本才引入，目前并不完善。所以，这也是在 Linux 下，实现高并发网络编程时都是以 IO 复用模型模式为主。

四种IO模型，理论上越往后，阻塞越少，效率也是最优。在这四种 I/O 模型中，前三种属于同步 I/O，因为其中真正的 I/O 操作将阻塞线程。只有最后一种，才是真正的异步 I/O 模型，可惜目前Linux 操作系统尚欠完善。

## java BIO，NIO，AIO 的区别与实际应用场景分析

[JAVA中BIO、NIO、AIO的分析理解-阿里云开发者社区 (aliyun.com)](https://developer.aliyun.com/article/726698)

[Java编程中的IO模型详解：BIO，NIO，AIO的区别与实际应用场景分析\_java nio bio aio-CSDN博客](https://blog.csdn.net/oWuChenHua/article/details/135394686)

[从理论到实践：深度解读BIO、NIO、AIO的优缺点及使用场景-腾讯云开发者社区-腾讯云 (tencent.com)](https://cloud.tencent.com/developer/article/2337352)

Java中的BIO、NIO和AIO是三种不同的I/O模型，它们在处理网络通信和文件I/O时有着不同的特点和适用场景。

**BIO (Blocking I/O)**

BIO是传统的同步阻塞I/O模型。在这种模型中，当一个客户端连接请求到来时，服务器会为每个客户端创建一个新的线程来处理请求。如果客户端数量很多，服务器将需要大量的线程来处理这些请求，这会导致资源消耗过大，特别是在高并发场景下，服务器的性能会急剧下降。

**应用场景**：

*   适用于连接数不多的场景。
*   适用于简单的客户端-服务器模型，如简单的聊天服务器。

**NIO (Non-blocking I/O)**

NIO是Java 1.4引入的新的I/O模型，它基于事件驱动，使用选择器（Selector）来实现非阻塞I/O。NIO允许一个线程管理多个网络连接，提高了线程的使用效率。NIO适用于需要处理大量连接的场景，如Web服务器、文件服务器等。

**应用场景**：

*   适用于高并发的网络应用，如Web服务器、文件服务器等。
*   适用于需要同时处理多个客户端请求的场景。

**AIO (Asynchronous I/O)**

AIO是Java 7引入的异步非阻塞I/O模型。AIO在NIO的基础上进一步发展，实现了真正的异步I/O操作。在AIO中，当一个I/O操作开始后，线程可以继续执行其他任务，I/O操作完成后，操作系统会通知线程处理结果。AIO适用于需要处理大量I/O操作的场景，如大数据处理、高性能服务器等。

**应用场景**：

*   适用于需要处理大量I/O操作的场景，如大数据处理、高性能服务器等。
*   适用于需要高吞吐量和低延迟的应用。

总结

*   **BIO**：适用于连接数不多的场景，简单易用，但不适合高并发。
*   **NIO**：适用于高并发场景，提高了线程的使用效率，但编程模型相对复杂。
*   **AIO**：适用于需要处理大量I/O操作的场景，提供了更高的性能和吞吐量，但支持的平台和库较少。

在实际应用中，选择哪种I/O模型取决于具体的应用场景和性能需求。对于大多数Web应用和网络服务，NIO是一个很好的选择，因为它提供了较好的性能和可扩展性。对于需要处理大量I/O操作的应用，AIO可能是一个更好的选择。而BIO在一些简单的场景下仍然适用，尤其是在连接数不多的情况下。

## 零拷贝技术

零拷贝（Zero-Copy）技术是一种减少数据在用户空间和内核空间之间复制次数的技术，从而提高数据传输效率的方法。在传统的数据传输过程中，数据需要从磁盘读取到内核空间的缓冲区，然后从内核空间复制到用户空间的缓冲区，最后再从用户空间复制到发送缓冲区或从接收缓冲区复制到用户空间。零拷贝技术通过减少这些不必要的数据复制，可以显著提高数据传输的性能。

例如，在应用程序中想要复制一个文件或向外部发送一个文件，一般情况下，应用程序需要首先向操作系统发出读取文件请求，操作系统收到请求后开始准备数据，数据准备好后通知应用程序可以读取，应用程序发起请求，将数据从内核缓冲区读取到用户缓冲区，然后再复制到指定位置或发送给网卡，发送过程仍需要将数据重新写出到内核缓冲区，然后才能真正发送数据，零拷贝（Zero-Copy）技术就是告诉操作系统，直接将数据复制到指定位置或发送给网卡，不需要给应用程序，跳过中间的过程的一种操作系统级别的优化方式。

**原理**

零拷贝技术的核心思想是减少或避免数据在内核空间和用户空间之间的复制，以及减少CPU的参与。以下是几种常见的零拷贝技术：

1.  **直接I/O**：应用程序直接访问存储设备，绕过内核缓冲区，从而减少一次数据复制。

2.  **内存映射（mmap）**：通过将文件映射到用户空间的内存地址，应用程序可以直接读写文件，避免了数据在内核空间和用户空间之间的复制。

3.  **sendfile**：在Linux系统中，sendfile系统调用可以将数据从一个文件描述符直接传输到另一个文件描述符，减少了一次数据复制。

4.  **DMA（Direct Memory Access）**：直接内存访问允许硬件设备直接读写系统内存，而不需要CPU的介入，从而减少了CPU的负担。

5.  **分散/聚集I/O（Scatter/Gather I/O）**：允许数据从多个缓冲区读取或写入到一个连续的缓冲区，减少了数据的复制次数。

**Java 中的实现**

在Java中，零拷贝技术可以通过以下几种方式实现：

1.  **FileChannel.transferTo() 和 transferFrom()**：这两个方法可以将数据从一个Channel传输到另一个Channel，或者从Channel传输到文件。在某些操作系统上，这些方法可以利用零拷贝技术，减少数据复制。

2.  **NIO的ByteBuffer**：使用ByteBuffer的allocateDirect()方法可以创建一个直接缓冲区，直接缓冲区的数据直接位于物理内存中，可以被操作系统直接访问，从而减少数据在用户空间和内核空间之间的复制。

3.  **Java 7引入的FileChannel.map()**：这个方法可以将文件的一部分映射到内存中，实现内存映射文件，从而实现零拷贝。

4.  **Java 9引入的AIO（Asynchronous I/O）**：虽然AIO本身不直接提供零拷贝技术，但其异步特性可以减少线程的阻塞等待，从而提高系统的整体性能。

需要注意的是，零拷贝技术的实现和效果依赖于底层操作系统和硬件的支持。在某些情况下，零拷贝技术可能无法完全避免数据复制，但仍然可以显著减少数据复制的次数和CPU的参与，从而提高数据传输的效率。

## Java NIO

### Channel

首先说一下Channel，国内大多翻译成“通道”。Channel和IO中的Stream（流）是差不多一个等级的。只不过Stream是单向的，譬如：InputStream， OutputStream，而Channel是双向的，既可以用来进行读操作，又可以用来进行写操作。NIO中的Channel的主要实现有：

1.  FileChannel
2.  DatagramChannel
3.  SocketChannel
4.  ServerSocketChannel

这里看名字就可以猜出个所以然来：分别可以对应文件IO、UDP和TCP（Server和Client）。

### Buffer

Buffer，故名思意，缓冲区，实际上是一个容器，是一个连续数组。 Channel 提供从文件、网络读取数据的渠道，但是读取或写入的数据
都必须经由 Buffer

上面的图描述了从一个客户端向服务端发送数据，然后服务端接收数据的过程。客户端发送数据时，必须先将数据存入 Buffer 中，然后将
Buffer 中的内容写入通道。服务端这边接收数据必须通过 Channel 将数据读入到 Buffer 中，然后再从 Buffer 中取出数据来处理。

在 NIO 中， Buffer 是一个顶层父类，它是一个抽象类，常用的 Buffer 的子类有：ByteBuffer、 IntBuffer、 CharBuffer、 LongBuffer、
DoubleBuffer、 FloatBuffer、ShortBuffer 

### Selector

Selector 类是 NIO 的核心类， Selector 能够检测多个注册的通道上是否有事件发生，如果有事件发生，便获取事件然后针对每个事件进行
相应的响应处理。这样一来，只是用一个单线程就可以管理多个通道，也就是管理多个连接。这样使得只有在连接真正有读写事件发生时，
才会调用函数来进行读写，就大大地减少了系统开销，并且不必为每个连接都创建一个线程，不用去维护多个线程，并且避免了多线程之间
的上下文切换导致的开销。

Java NIO（New Input/Output）的`Selector`类是Java NIO中用于实现非阻塞IO的关键组件。它允许单个线程管理多个网络连接。下面是一个简单的使用`Selector`的实例，演示了如何在服务器端使用`Selector`来处理多个客户端的连接。

```java
import java.io.IOException;
import java.net.InetSocketAddress;
import java.nio.ByteBuffer;
import java.nio.channels.SelectionKey;
import java.nio.channels.Selector;
import java.nio.channels.ServerSocketChannel;
import java.nio.channels.SocketChannel;
import java.util.Iterator;

public class NioSelectorServer {

    public static void main(String[] args) throws IOException {
        // 打开服务器套接字通道
        ServerSocketChannel serverSocketChannel = ServerSocketChannel.open();
        // 绑定到指定端口
        serverSocketChannel.bind(new InetSocketAddress(8080));
        // 设置为非阻塞模式
        serverSocketChannel.configureBlocking(false);

        // 打开选择器
        Selector selector = Selector.open();
        // 将服务器套接字通道注册到选择器上，并指定感兴趣的事件为接受连接
        serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT);

        System.out.println("Server is listening on port 8080...");

        while (true) {
            // 选择一组键，其对应的通道已为 I/O 操作准备就绪
            int readyChannels = selector.select();
            if (readyChannels == 0) {
                continue;
            }

            // 获取选择器中所有已选择的键
            Iterator<SelectionKey> selectedKeys = selector.selectedKeys().iterator();

            while (selectedKeys.hasNext()) {
                SelectionKey key = selectedKeys.next();

                // 检查键是否是新的连接
                if (key.isAcceptable()) {
                    ServerSocketChannel server = (ServerSocketChannel) key.channel();
                    // 接受连接
                    SocketChannel client = server.accept();
                    client.configureBlocking(false);
                    // 注册客户端到选择器，并指定感兴趣的事件为读取
                    client.register(selector, SelectionKey.OP_READ);
                    System.out.println("Accepted connection from " + client.getRemoteAddress());
                }

                // 检查键是否是读取事件
                if (key.isReadable()) {
                    SocketChannel client = (SocketChannel) key.channel();
                    ByteBuffer buffer = ByteBuffer.allocate(1024);
                    int bytesRead = client.read(buffer);
                    if (bytesRead > 0) {
                        buffer.flip();
                        // 读取数据
                        System.out.println("Received message: " + new String(buffer.array(), 0, bytesRead));
                        // 回应客户端
                        buffer.clear();
                        buffer.put("Server received message".getBytes());
                        buffer.flip();
                        client.write(buffer);
                    } else if (bytesRead == -1) {
                        // 客户端关闭连接
                        client.close();
                    }
                }

                // 移除已处理的键
                selectedKeys.remove();
            }
        }
    }
}
```

这个例子中，我们创建了一个服务器端的程序，它监听8080端口。当有新的连接请求时，它接受连接并注册到`Selector`上。当有数据可读时，它读取数据并回送一条消息给客户端。

注意，这个例子仅用于演示目的，实际应用中可能需要更复杂的错误处理和资源管理。此外，为了保持非阻塞特性，所有的操作都应当是非阻塞的，例如，`read`和`write`操作应当在循环中调用，直到所有数据都被读取或写入。

## DirectByteBuffer

`DirectByteBuffer` 是 Java NIO（New Input/Output）包中的一个类，它用于在Java堆外分配内存，即直接内存（Direct Memory）。直接内存不是由JVM管理的堆内存，而是直接由操作系统管理的内存区域。这种内存分配方式可以提高某些操作的性能，尤其是对于那些需要大量数据传输的场景，如网络通信和文件I/O操作。

使用`DirectByteBuffer`可以减少数据在用户空间和内核空间之间的复制次数，从而提高数据传输的效率。`DirectByteBuffer`是Java NIO（New I/O）包中的一部分，它允许Java程序直接操作堆外内存（即直接内存），而不是堆内存。这种直接内存通常由操作系统管理，可以被内核直接访问。

**DirectByteBuffer的工作原理**

1. **直接内存分配**：`DirectByteBuffer`在创建时会分配一块直接内存，这块内存是操作系统管理的，不与Java堆内存直接关联。

2. **内核空间访问**：由于直接内存是操作系统管理的，内核可以直接访问这块内存，无需通过用户空间的缓冲区。

3. **数据传输**：当进行I/O操作时，如读写文件或网络通信，数据可以直接在内核空间和直接内存之间传输，绕过了用户空间的缓冲区。

**减少数据复制次数的原理**

`DirectByteBuffer`减少数据复制次数的原理与内存映射文件的原理不同。内存映射文件是将文件内容映射到用户空间的虚拟内存地址，使得文件数据看起来像是进程的内存。而`DirectByteBuffer`则是直接操作堆外的内存，这块内存是直接由操作系统管理的，可以被内核直接访问。

在使用`DirectByteBuffer`进行I/O操作时，数据传输的路径通常是：

1. **内核空间到直接内存**：当从磁盘读取数据时，内核直接将数据写入到直接内存中，而不是先写入到用户空间的缓冲区。

2. **直接内存到内核空间**：当向磁盘写入数据时，直接内存中的数据直接被内核读取并写入磁盘，无需先复制到用户空间的缓冲区。

**与内存映射文件的区别**

- **内存映射文件**：通过映射文件到用户空间的虚拟内存，使得文件数据看起来像是进程的内存。数据的读写操作仍然需要通过用户空间的内存地址，但操作系统会负责在内核空间和用户空间之间同步数据。

- **DirectByteBuffer**：直接操作堆外的内存，绕过了用户空间的缓冲区。数据的读写操作直接在内核空间和直接内存之间进行，减少了数据复制的次数。

**注意事项**

使用`DirectByteBuffer`时需要注意：

- **内存管理**：直接内存需要手动管理，使用完毕后需要通过`DirectByteBuffer`的`cleaner`机制或`System.gc()`来释放内存。

- **内存泄漏**：如果忘记释放直接内存，可能会导致内存泄漏。

- **性能开销**：虽然减少了数据复制，但直接内存的分配和管理可能会有额外的性能开销。

`DirectByteBuffer`提供了一种高效的数据传输方式，特别适合于需要大量数据传输和高性能I/O操作的应用场景。然而，它也要求开发者对内存管理有更深入的理解和控制。

# 并发

参考 <a href = "../Server/java/java 多线程/多线程基础.md"> 多线程基础.md </a>

# JVM

参考 <a href = "../Server/java/java 虚拟机/深入理解java虚拟机.md"> 深入理解java虚拟机.md </a>
