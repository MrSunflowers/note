[TOC]

# java 基础

## Java的数据结构有那些？

Java语言提供了丰富的数据结构，这些数据结构主要包含在`java.util`包中。以下是一些常用的Java数据结构：

1.  **集合框架（Collection Framework）**：
    *   **List**：有序集合，允许重复元素。
        *   `ArrayList`：基于数组实现，随机访问速度快，增删操作慢。
        *   `LinkedList`：基于链表实现，增删操作速度快，随机访问速度慢。
        *   `Vector`：类似于ArrayList，但它是线程安全的。
        *   `Stack`：继承自Vector，实现了一个后进先出（LIFO）的栈。
    *   **Set**：不允许重复元素的集合。
        *   `HashSet`：基于哈希表实现，无序，允许null值。
        *   `LinkedHashSet`：基于HashSet，维护元素插入顺序。
        *   `TreeSet`：基于红黑树实现，元素自动排序。
    *   **Queue**：队列，先进先出（FIFO）的数据结构。
        *   `LinkedList`：实现了Queue接口，可以作为队列使用。
        *   `PriorityQueue`：基于优先级堆的无界队列，元素按照自然顺序或自定义比较器排序。
        *   `ArrayDeque`：基于数组实现的双端队列，可以作为栈或队列使用。

2.  **映射（Map）**：
    *   `HashMap`：基于哈希表实现，允许null键和null值，无序。
    *   `LinkedHashMap`：继承自HashMap，维护元素的插入顺序或访问顺序。
    *   `TreeMap`：基于红黑树实现，元素自动排序。
    *   `Hashtable`：类似于HashMap，但它是线程安全的，不允许null键和null值。
    *   `Properties`：继承自Hashtable，用于处理属性文件。

3.  **其他数据结构**：
    *   `BitSet`：表示一个位向量，可以进行位操作。
    *   `EnumSet`：用于枚举类型的集合，内部实现为位向量。
    *   `Stack`：继承自Vector，实现了一个后进先出（LIFO）的栈。
    *   `PriorityQueue`：实现了一个优先队列，可以按照元素的自然顺序或自定义比较器进行排序。

Java的集合框架提供了强大的数据结构支持，使得开发者可以根据不同的需求选择合适的数据结构来实现算法和应用。此外，Java 8及以后的版本还引入了流（Stream）API，可以对集合进行函数式编程风格的操作。

## instanceof 关键字的作用

`instanceof` 关键字在Java中用于在运行时检查对象是否是特定类的实例。它通常用于类型检查，以确保在进行类型转换之前对象确实是期望的类型。

**`instanceof` 的作用：**

1.  **类型检查**：`instanceof` 可以用来判断一个对象是否是某个类的实例，或者是否实现了某个接口。
2.  **安全的类型转换**：在进行类型转换之前，使用 `instanceof` 可以确保转换是安全的，避免抛出 `ClassCastException`。
3.  **多态性**：在多态的场景中，`instanceof` 可以帮助确定对象的实际类型，从而执行特定类型的方法。

示例代码：

```java
Object obj = new Integer(10);
if (obj instanceof Integer) {
    Integer i = (Integer) obj;
    System.out.println("obj is an Integer: " + i);
} else {
    System.out.println("obj is not an Integer");
}
```

**`instanceof` 的禁忌：**

1.  **过度使用**：过度使用 `instanceof` 可能意味着设计上的问题。如果需要频繁地检查对象类型，可能需要重新考虑设计，使用多态和接口来减少类型检查的需求。
2.  **隐藏的类型转换**：在 `instanceof` 检查之后，如果总是进行类型转换，可能会隐藏潜在的 `ClassCastException`。应该确保类型转换是安全的，并且在转换后进行适当的错误处理。
3.  **滥用多态**：虽然 `instanceof` 可以帮助处理多态，但滥用多态可能会导致代码难以理解和维护。应该在必要时使用，而不是在所有可能的情况下都使用。
4.  **避免在继承层次结构中使用**：在继承层次结构中，如果需要判断一个对象是否是某个特定子类的实例，这可能表明设计上的问题。应该考虑使用接口或抽象类来定义共同的行为。

**最佳实践：**

*   **使用接口和抽象类**：尽量使用接口和抽象类来定义行为，而不是依赖于具体的类。
*   **利用多态**：在可能的情况下，使用多态来减少类型检查的需求。
*   **重构代码**：如果发现代码中频繁使用 `instanceof`，考虑重构代码，以减少类型检查的需要。
*   **异常处理**：在进行类型转换后，应该处理可能抛出的 `ClassCastException`。

instanceof 严格来说是 Java 中的一个双目运算符，用于在运行时判断对象是否为特定类的实例，或者是否实现了特定接口。它通常用于类型检查，以确保在进行类型转换之前对象确实是期望的类型。

**`instanceof` 运算符的语法：**

```java
(对象) instanceof (类或接口)
```

**`instanceof` 的注意事项：**

1.  **左侧必须是对象引用**：`instanceof` 运算符的左侧必须是一个对象引用，不能是基本数据类型。
2.  **右侧必须是类或接口**：`instanceof` 运算符的右侧必须是一个类或接口的名称。
3.  **返回值类型**：`instanceof` 运算符的返回值是一个布尔值（`true` 或 `false`），表示左侧的对象是否是右侧类或接口的实例。
4.  **可以用于多态**：`instanceof` 可以用于多态场景，判断对象是否是某个类的实例，或者是否实现了某个接口。

**`instanceof` 的限制：**

*   **不能用于基本数据类型**：`instanceof` 不能用于基本数据类型，如 `int`、`double` 等。
*   **不能用于检查数组类型**：虽然数组在 Java 中是对象，但 `instanceof` 不能用于检查数组类型。应该使用 `array.getClass().isArray()` 或 `array instanceof Object[]` 等方法来检查数组类型。
*   **不能用于检查是否为 null**：`instanceof` 运算符不能用于检查对象是否为 `null`。如果左侧的对象是 `null`，`instanceof` 运算的结果将总是 `false`。

总之，`instanceof` 是Java中一个有用的工具，但应该谨慎使用，避免过度依赖它来处理类型检查和转换。在设计时，应该优先考虑使用多态和接口来减少对 `instanceof` 的依赖。

## 什么是拆装箱？

在Java中，拆箱（Unboxing）和装箱（Boxing）是自动类型转换的过程，它们涉及到基本数据类型（如int, double等）和它们对应的包装类（如Integer, Double等）之间的转换。

装箱（Boxing）

装箱是指将基本数据类型转换为对应的包装类的过程。Java提供了自动装箱机制，允许在需要时自动将基本数据类型转换为包装类。例如，将一个int类型的值赋给一个Integer类型的变量时，Java会自动进行装箱操作。

```java
int i = 10;
Integer integer = i; // 自动装箱
```

拆箱（Unboxing）

拆箱是指将包装类转换回基本数据类型的过程。同样，Java也提供了自动拆箱机制，允许在需要时自动将包装类转换为基本数据类型。例如，将一个Integer类型的对象赋值给一个int类型的变量时，Java会自动进行拆箱操作。

```java
Integer integer = 10; // 自动装箱
int i = integer; // 自动拆箱
```

使用场景

装箱和拆箱在Java中非常常见，特别是在集合框架（如List, Set, Map等）中使用包装类作为元素类型时。例如，当你将一个Integer对象添加到一个List\<Integer>中时，实际上是在使用自动装箱。

```java
List<Integer> list = new ArrayList<>();
list.add(10); // 自动装箱
```

注意事项

*   **性能影响**：虽然自动装箱和拆箱为编程带来了便利，但它们在性能上是有开销的。在大量数据处理或性能敏感的场景中，应尽量避免不必要的装箱和拆箱操作。
*   **空指针异常**：在拆箱操作中，如果包装类对象为null，尝试拆箱会抛出`NullPointerException`。

```java
Integer integer = null;
int i = integer; // 这里会抛出NullPointerException
```

*   **类型安全**：自动装箱和拆箱可能会导致类型不安全的问题，特别是在使用泛型时。例如，`List<Integer>`和`List<Double>`在泛型上是不兼容的，尽管它们都是`Number`的子类。

\*\*在Java中，如果尝试对一个`null`值进行拆箱操作，将会抛出`NullPointerException`。\*\*拆箱操作是指将包装类（如`Integer`、`Double`等）转换回基本数据类型（如`int`、`double`等）。由于包装类可以持有`null`值，而基本数据类型不能为`null`，因此在尝试将`null`的包装类转换为基本数据类型时，Java运行时会抛出异常。

例如：

```java
Integer nullInteger = null;
int i = nullInteger; // 这里会抛出NullPointerException
```

在上面的代码中，`nullInteger`被赋值为`null`，然后尝试将其拆箱为基本数据类型`int`。由于`nullInteger`是`null`，所以尝试访问其值时会抛出`NullPointerException`。

为了避免在拆箱时出现`NullPointerException`，在进行拆箱操作之前，应该检查包装类对象是否为`null`。例如：

```java
Integer nullInteger = null;
if (nullInteger != null) {
    int i = nullInteger; // 这里不会抛出异常，因为已经检查了nullInteger不为null
} else {
    // 处理null的情况
}
```

在实际编程中，特别是在使用集合或进行泛型编程时，应该特别注意避免对可能为`null`的包装类进行拆箱操作，以防止程序抛出`NullPointerException`。

## Java中的包装类的缓存机制

Java中的包装类（如`Integer`、`Long`、`Short`、`Byte`、`Character`）提供了缓存机制，以提高性能和减少内存使用。这些缓存机制主要针对小范围的整数值，因为这些值在程序中非常常见，如循环计数、数组索引等。

Integer缓存机制

`Integer`类的缓存机制是通过`IntegerCache`类实现的。从Java 5开始，`Integer`类默认缓存了-128到127之间的所有`Integer`对象。这意味着当你创建一个`Integer`对象时，如果它的值在-128到127之间，Java会返回缓存中的同一个对象，而不是创建一个新的对象。

```java
Integer i1 = 127;
Integer i2 = 127;
System.out.println(i1 == i2); // 输出 true，因为它们指向同一个对象

Integer i3 = 128;
Integer i4 = 128;
System.out.println(i3 == i4); // 输出 false，因为它们是不同的对象
```

Long缓存机制

`Long`类也有类似的缓存机制，它默认缓存了-128到127之间的所有`Long`对象。这个范围可以通过`LongCache.low`和`LongCache.high`属性来调整。

Byte和Short缓存机制

`Byte`和`Short`类也有类似的缓存机制，它们默认缓存了-128到127之间的所有对象。

Character缓存机制

`Character`类缓存了0到127之间的所有`Character`对象。这个范围是固定的，不能调整。

缓存机制的注意事项

*   **缓存范围**：缓存的范围是固定的，对于`Integer`和`Long`，这个范围可以通过JVM参数`-XX:AutoBoxCacheMax`来调整，但通常不推荐这样做，因为这可能会导致性能问题。
*   **不可变性**：由于包装类是不可变的，所以缓存的对象可以安全地被多个变量共享。
*   **性能优化**：缓存机制减少了对象的创建和垃圾回收的开销，从而提高了性能。
*   **使用场景**：缓存机制主要适用于那些频繁使用小整数值的场景，如循环计数、数组索引等。

通过这些缓存机制，Java包装类在处理常见数值时能够提供更好的性能和更少的内存占用。

## 缓存机制在并发环境下安全吗？

Java中的包装类（如`Integer`、`Long`、`Short`、`Byte`、`Character`）的缓存机制在设计上考虑了线程安全。这些缓存机制是通过静态初始化实现的，这意味着缓存的实例在类加载时就已经创建，并且是不可变的。因此，这些缓存实例在并发环境下是安全的。

缓存实例的创建和使用

*   **缓存实例的创建**：缓存实例在类加载时创建，这个过程是线程安全的，因为类加载是由类加载器以线程安全的方式执行的。
*   **缓存实例的使用**：一旦缓存实例被创建，它们就成为不可变的，这意味着它们的状态不会改变。由于不可变对象的线程安全特性，这些缓存实例可以被多个线程安全地共享和访问。

缓存机制的线程安全特性

*   **不可变性**：由于缓存实例是不可变的，它们的状态在创建后不会改变，因此不存在线程安全问题。
*   **线程安全的初始化**：缓存实例的创建是线程安全的，因为它们是在类加载时创建的，而**类加载是由类加载器以线程安全的方式执行的。**

注意事项

尽管缓存实例本身是线程安全的，但在使用这些缓存实例时，仍然需要注意以下几点：

*   **避免共享可变状态**：如果在使用缓存实例时，你创建了可变对象并共享它们，那么需要确保这些可变对象的访问是线程安全的。
*   **避免使用缓存实例作为锁**：虽然缓存实例是线程安全的，但它们不应该被用作同步块或方法的锁对象，因为这可能会导致死锁或其他并发问题。

总的来说，Java包装类的缓存机制在设计上是线程安全的，可以被多个线程安全地共享和访问。然而，开发者在使用这些缓存实例时，仍需注意避免共享可变状态和正确使用同步机制。

## 包装类和基本数据类型性能比较如何？

在Java中，基本数据类型（如int, double, char等）和它们对应的包装类（如Integer, Double, Character等）在性能上存在显著差异。这些差异主要体现在以下几个方面：

内存占用

*   **基本数据类型**：占用固定大小的内存空间，例如`int`占用4字节，`double`占用8字节。
*   **包装类**：除了存储基本数据类型值外，还需要额外的内存来存储对象的引用和对象头信息。因此，包装类的内存占用通常比基本数据类型大。

性能

*   **基本数据类型**：由于直接操作内存中的值，基本数据类型的性能通常比包装类要高。基本数据类型的操作（如算术运算、比较等）不需要进行额外的装箱和拆箱操作，因此执行速度更快。
*   **包装类**：包装类的操作涉及到装箱和拆箱，这会增加额外的性能开销。特别是在频繁进行装箱和拆箱操作时，性能影响会更加明显。

使用场景

*   **基本数据类型**：适用于需要高性能和内存效率的场景，如循环计数、数组索引、数学计算等。
*   **包装类**：适用于需要使用对象而非基本数据类型的场景，如泛型集合（如`List<Integer>`）、方法参数传递、反射等。

总结

在性能敏感的应用中，特别是在循环和大量数据处理的情况下，推荐使用基本数据类型以获得更好的性能。然而，在需要使用对象的场景中，如泛型集合或需要使用`null`值时，包装类是必要的选择。

在Java 5及以后的版本中，引入了自动装箱和自动拆箱机制，这使得在使用包装类时更加方便，但同时也增加了性能开销。因此，在性能要求较高的代码中，应尽量避免不必要的自动装箱和拆箱操作。

总之，选择使用基本数据类型还是包装类，应根据具体的应用场景和性能需求来决定。在性能要求较高的场景中，优先考虑使用基本数据类型。

## 针对浮点型数据运算出现的误差的问题，应该怎么解决？

在Java中，浮点数运算可能会出现精度误差，这是由于浮点数的表示方式和计算机的二进制系统所决定的。浮点数通常使用IEEE 754标准表示，该标准定义了浮点数的存储格式，包括符号位、指数位和尾数位。由于浮点数的表示是近似的，因此在进行浮点数运算时可能会出现舍入误差。

以下是一些处理浮点数运算误差的策略：

1.  使用`BigDecimal`类

`BigDecimal`类提供了高精度的浮点数运算，可以避免由于浮点数表示的近似性带来的误差。`BigDecimal`可以精确地表示任意大小和精度的十进制数。

```java
import java.math.BigDecimal;

public class Main {
    public static void main(String[] args) {
        BigDecimal a = new BigDecimal("1.1");
        BigDecimal b = new BigDecimal("1.2");
        BigDecimal c = a.add(b); // 使用add方法进行加法运算
        System.out.println(c); // 输出结果
    }
}
```

1.  设置精度

在使用`BigDecimal`时，可以设置运算的精度，以控制舍入行为。

```java
BigDecimal a = new BigDecimal("1.1");
BigDecimal b = new BigDecimal("1.2");
BigDecimal c = a.add(b).setScale(2, RoundingMode.HALF_UP); // 设置精度为两位小数
System.out.println(c); // 输出结果
```

1.  使用`Math.round`方法

对于简单的四舍五入需求，可以使用`Math.round`方法，它将浮点数四舍五入到最接近的整数。

```java
double a = 1.1;
double b = 1.2;
double c = Math.round(a + b); // 结果为2
```

1.  使用`DecimalFormat`类

`DecimalFormat`类可以格式化浮点数，以显示特定的小数位数，这有助于控制输出的精度。

```java
import java.text.DecimalFormat;

public class Main {
    public static void main(String[] args) {
        double a = 1.1;
        double b = 1.2;
        DecimalFormat df = new DecimalFormat("#.##"); // 设置两位小数
        System.out.println(df.format(a + b)); // 输出结果
    }
}
```

1.  了解浮点数的限制

了解浮点数的表示限制和可能的误差范围，有助于在设计算法和处理数据时做出合理的决策。

1.  避免不必要的浮点数比较

由于浮点数的精度问题，直接比较两个浮点数是否相等可能会得到错误的结果。通常，应该比较它们的差值是否小于一个很小的阈值。

```java
double a = 1.1;
double b = 1.2;
if (Math.abs(a - b) < 1e-10) {
    // a和b足够接近，可以认为它们相等
}
```

通过上述方法，可以有效地处理和减少浮点数运算中的误差问题。在实际应用中，选择合适的方法取决于具体的应用场景和精度要求。

## short s1 = 1; s1 = s1 + 1;有错吗 ? short s1 = 1; s1 += 1; 有错吗？

在Java中，`short`类型是16位的整数类型，其取值范围是-32768到32767。当你尝试执行以下操作时：

```java
short s1 = 1;
s1 = s1 + 1;
```

这里存在一个问题：`s1 + 1`的结果是一个`int`类型，因为Java在执行算术运算时会将操作数提升为`int`类型。因此，你需要显式地将结果转换回`short`类型，否则编译器会报错，提示类型不匹配。

正确的做法是：

```java
short s1 = 1;
s1 = (short)(s1 + 1); // 显式转换回short类型
```

或者使用Java的自动装箱和拆箱机制，将`short`类型自动提升为`int`类型，然后赋值回`short`类型：

```java
short s1 = 1;
s1 += 1; // 自动拆箱和装箱
```

在上面的代码中，`+=`操作符会自动将`s1`的值提升为`int`类型，执行加法操作，然后将结果转换回`short`类型并赋值给`s1`。这种做法是合法的，因为Java会自动处理类型转换，确保类型安全。

总结来说，`short s1 = 1; s1 += 1;`是合法的，而`short s1 = 1; s1 = s1 + 1;`需要显式类型转换。在实际编程中，推荐使用`+=`操作符，因为它简洁且自动处理了类型转换，避免了显式类型转换的需要。

## equals与==的区别

在Java中，`equals`方法和`==`运算符都是用来比较两个对象是否相等的，但它们的比较方式和用途有所不同。

`==`运算符

`==`运算符用于比较两个对象的引用（内存地址）是否相同，即它们是否指向同一个对象实例。对于基本数据类型（如`int`、`double`等），`==`比较的是它们的值是否相等。

```java
int a = 5;
int b = 5;
int c = 10;

System.out.println(a == b); // 输出 true，因为a和b的值相等
System.out.println(a == c); // 输出 false，因为a和c的值不相等

Integer x = 5;
Integer y = 5;
Integer z = 10;

System.out.println(x == y); // 输出 true，因为x和y指向同一个Integer对象
System.out.println(x == z); // 输出 false，因为x和z指向不同的Integer对象
```

`equals`方法

`equals`方法是`Object`类的一个方法，它被所有Java类继承。`equals`方法用于比较两个对象的内容是否相等。对于自定义类，通常需要重写`equals`方法以定义对象相等的逻辑。

```java
String str1 = new String("Hello");
String str2 = new String("Hello");

System.out.println(str1 == str2); // 输出 false，因为str1和str2指向不同的String对象
System.out.println(str1.equals(str2)); // 输出 true，因为equals方法比较的是内容
```

重写`equals`方法

对于自定义类，如果需要根据对象的内容来判断两个对象是否相等，应该重写`equals`方法。例如：

```java
public class Person {
    private String name;
    private int age;

    // 构造方法、getter和setter省略

    @Override
    public boolean equals(Object obj) {
        if (this == obj) return true;
        if (obj == null || getClass() != obj.getClass()) return false;
        Person person = (Person) obj;
        return age == person.age && Objects.equals(name, person.name);
    }
}
```

在上面的`Person`类中，`equals`方法首先检查两个对象是否是同一个对象的引用，然后检查是否为`null`，最后比较两个对象的`name`和`age`字段是否相等。

总结来说，`==`用于比较两个对象的引用是否相同，而`equals`方法用于比较两个对象的内容是否相等。对于自定义类，通常需要重写`equals`方法来定义对象相等的逻辑。

## ++i与i++的区别

在Java中，`++i` 和 `i++` 都是递增运算符，用于将变量的值增加1。然而，它们在使用时有重要的区别，主要体现在它们的返回值和执行时间点上。

`++i`（前缀递增）

*   **返回值**：`++i` 会先将变量的值增加1，然后返回增加后的值。
*   **执行时间点**：`++i` 在表达式求值之前执行，因此它会立即影响变量的值。

`i++`（后缀递增）

*   **返回值**：`i++` 会返回变量增加前的原始值，然后将变量的值增加1。
*   **执行时间点**：`i++` 在表达式求值之后执行，因此它不会立即影响变量的值。

示例

```java
int i = 5;
int j = ++i; // i 现在是 6，j 也是 6
System.out.println("i = " + i); // 输出 i = 6
System.out.println("j = " + j); // 输出 j = 6

int k = 5;
int l = k++; // k 现在是 6，l 是 5
System.out.println("k = " + k); // 输出 k = 6
System.out.println("l = " + l); // 输出 l = 5
```

## Java中各种数据默认值

在Java中，不同的数据类型有不同的默认值。这些默认值在声明变量但未显式初始化时自动赋予。以下是Java中各种数据类型的默认值：

基本数据类型

*   **整数类型** (`byte`, `short`, `int`, `long`):
    *   默认值为 `0`。

*   **浮点类型** (`float`, `double`):
    *   默认值为 `0.0`。

*   **字符类型** (`char`):
    *   默认值为 `'\u0000'`，即空字符。

*   **布尔类型** (`boolean`):
    *   默认值为 `false`。

引用数据类型

*   **类类型** (`Object`, `String`, 自定义类等):
    *   默认值为 `null`。

*   **数组**:
    *   数组的默认值取决于数组的元素类型。对于基本数据类型的数组，每个元素的默认值与单独的变量相同。对于对象类型的数组，每个元素的默认值为 `null`。

示例

```java
int i; // 默认值为 0
long l; // 默认值为 0L
float f; // 默认值为 0.0f
double d; // 默认值为 0.0d
char c; // 默认值为 '\u0000'
boolean b; // 默认值为 false

String str; // 默认值为 null
MyClass obj; // 自定义类，MyClass是任意类名，obj的默认值为 null

int[] intArray; // 默认值为 null
int[] intArray2 = new int[5]; // 数组中的每个元素默认值为 0
```

注意事项

*   **局部变量**：局部变量（在方法内部声明的变量）没有默认值，必须在使用前显式初始化。
*   **静态变量**：静态变量（类变量）在类加载时初始化，如果没有显式初始化，则会根据类型赋予默认值。

## java中是值传递引用传递？

在Java中，参数传递的方式是值传递（pass-by-value）。这意味着当一个方法被调用时，方法参数的值被复制到方法的局部变量中。对于基本数据类型（如int, double, char等），传递的是实际的值。对于对象引用类型（如String, Integer, ArrayList等），传递的是引用的副本，即引用的值（内存地址）。

基本数据类型传递

对于基本数据类型，传递的是实际的值的副本：

```java
public class PassByValueExample {
    public static void main(String[] args) {
        int number = 10;
        System.out.println("Before method call: " + number); // 输出 10
        modify(number);
        System.out.println("After method call: " + number); // 输出 10
    }

    public static void modify(int number) {
        number = 20;
    }
}
```

在上面的例子中，`modify`方法接收一个`int`类型的参数`number`。当`modify`方法被调用时，`number`的值被复制到方法的局部变量中。在`modify`方法内部对`number`的修改不会影响到`main`方法中的`number`变量。

引用类型传递

对于对象引用类型，传递的是引用的副本：

```java
public class PassByValueExample {
    public static void main(String[] args) {
        Integer number = 10;
        System.out.println("Before method call: " + number); // 输出 10
        modify(number);
        System.out.println("After method call: " + number); // 输出 10
    }

    public static void modify(Integer number) {
        number = 20;
    }
}
```

在这个例子中，`modify`方法接收一个`Integer`类型的参数`number`。当`modify`方法被调用时，`number`的引用（内存地址）被复制到方法的局部变量中。在`modify`方法内部对`number`的修改不会影响到`main`方法中的`number`变量，因为它们指向的是不同的对象。

总结

在Java中，无论是基本数据类型还是对象引用类型，传递的都是值的副本。对于基本数据类型，传递的是实际的值；对于对象引用类型，传递的是引用的副本。理解这一点对于编写正确和高效的Java代码非常重要。

## 内部类与静态内部类的区别

在Java中，内部类（Inner Class）是指定义在另一个类的内部的类。内部类可以访问外部类的所有成员（包括私有成员）。根据内部类是否需要外部类的实例来创建，内部类可以分为非静态内部类（Inner Class）和静态内部类（Static Inner Class）。

非静态内部类（Inner Class）

*   **非静态内部类**不能有静态成员（字段、方法、内部类等），因为非静态内部类依赖于外部类的实例。
*   **非静态内部类**可以访问外部类的所有成员，包括私有成员。
*   **非静态内部类**的实例必须与外部类的实例关联。创建非静态内部类的实例时，必须先创建外部类的实例。
*   **非静态内部类**可以访问外部类的实例变量和方法，就像它们是自己的成员一样。

静态内部类（Static Inner Class）

*   **静态内部类**可以有静态成员（字段、方法、内部类等），因为静态内部类不依赖于外部类的实例。
*   **静态内部类**可以访问外部类的静态成员，但不能直接访问外部类的非静态成员，除非通过外部类的实例。
*   **静态内部类**的实例不需要外部类的实例即可创建。
*   **静态内部类**可以被外部类的静态方法直接访问，不需要外部类的实例。

区别总结

1.  **静态与非静态**：静态内部类是通过`static`关键字定义的，而非静态内部类则没有这个关键字。这决定了它们是否可以拥有静态成员以及它们与外部类实例的关系。

2.  **实例化方式**：非静态内部类的实例化需要外部类的实例，而静态内部类的实例化不需要。

3.  **访问权限**：非静态内部类可以访问外部类的所有成员，包括私有成员；静态内部类只能访问外部类的静态成员。

4.  **使用场景**：如果内部类不需要访问外部类的非静态成员，或者你希望内部类可以独立于外部类的实例存在，那么使用静态内部类。如果内部类需要访问外部类的非静态成员，或者需要与外部类的实例紧密相关联，那么使用非静态内部类。

5.  **内存占用**：由于非静态内部类需要外部类的实例，因此在创建非静态内部类的实例时，会同时创建外部类的实例，这可能会增加内存的使用。

## String str=”aaa” , 与String str=new String(“aaa”) 一样吗

在Java中，`String str = "aaa"` 和 `String str = new String("aaa")` 这两种方式创建字符串对象是不同的，主要体现在它们在内存中的存储方式和性能上。

1.  **字符串字面量（String Literal）**:
    *   当使用 `String str = "aaa"` 这种方式时，Java虚拟机会首先检查字符串字面量 `"aaa"` 是否已经存在于字符串常量池（String Pool）中。
    *   如果存在，那么 `str` 将直接指向常量池中的这个字符串对象，不会创建新的对象。
    *   如果不存在，Java虚拟机会在字符串常量池中创建一个新的字符串对象 `"aaa"`，然后 `str` 指向这个对象。

2.  **使用 `new` 关键字创建字符串对象**:
    *   当使用 `String str = new String("aaa")` 这种方式时，不管字符串常量池中是否已经存在 `"aaa"`，都会在堆内存中创建一个新的字符串对象。
    *   这个新创建的对象是 `new String("aaa")` 的结果，而 `"aaa"` 字符串字面量仍然存在于字符串常量池中。
    *   因此，使用 `new` 关键字创建字符串对象会创建两个对象：一个在字符串常量池中，另一个在堆内存中。

性能影响

*   使用字符串字面量的方式创建字符串对象通常更高效，因为它避免了不必要的对象创建，减少了内存的使用。
*   使用 `new` 关键字创建字符串对象则会增加内存的使用，因为它总是创建一个新的对象。

示例

```java
String str1 = "aaa"; // 字符串字面量，可能指向常量池中的对象
String str2 = "aaa"; // 同样指向常量池中的对象，因为字符串字面量是共享的
String str3 = new String("aaa"); // 在堆内存中创建新的字符串对象
```

在上述代码中，`str1` 和 `str2` 指向同一个字符串对象，而 `str3` 指向堆内存中的另一个字符串对象。如果执行 `str1 == str2`，结果将是 `true`，因为它们指向同一个对象。而 `str1 == str3` 或 `str2 == str3` 的结果将是 `false`，因为它们指向不同的对象。

## Hashcode 的作用

在Java中，`hashCode()` 方法是`Object`类的一个方法，它返回一个整数，这个整数是对象的哈希码（hash code）。哈希码是对象的一个标识符，用于在哈希表（如`HashMap`、`HashSet`等）中快速定位对象。`hashCode()`方法在Java集合框架中扮演着非常重要的角色，特别是在实现`equals()`方法的对象中。

以下是`hashCode()`方法的一些关键作用：

1.  **哈希表的性能**：在哈希表中，对象的存储位置是通过对象的哈希码来计算的。当向哈希表中添加、查找或删除元素时，首先计算元素的哈希码，然后根据哈希码来确定元素在哈希表中的位置。这样可以快速定位元素，提高操作的效率。

2.  **对象的唯一性**：虽然`hashCode()`方法返回的哈希码并不保证是唯一的，但通常情况下，不同的对象应该返回不同的哈希码。这样可以减少哈希冲突，提高哈希表的性能。

3.  **`equals()`方法的辅助**：在Java中，如果两个对象通过`equals()`方法比较是相等的，那么它们的`hashCode()`方法返回的哈希码也必须相同。这是为了保证在哈希表中，相等的对象能够被正确地识别和处理。

4.  **缓存**：在某些情况下，对象的哈希码计算可能比较耗时，因此对象可以缓存其哈希码。一旦计算出哈希码，就可以在后续的调用中直接返回，避免重复计算。

5.  **一致性**：当对象的状态发生变化时，其哈希码应该保持不变，除非对象的`equals()`方法定义为在状态变化后返回`false`。这保证了对象在哈希表中的位置不会因为状态的变化而改变。

在实现自定义类时，通常需要重写`hashCode()`方法，以确保当两个对象通过`equals()`方法判断为相等时，它们的`hashCode()`方法返回相同的值。这有助于保持哈希表的正确性和性能。

下面是一个简单的`hashCode()`方法的实现示例：

```java
@Override
public int hashCode() {
    final int prime = 31;
    int result = 1;
    result = prime * result + ((name == null) ? 0 : name.hashCode());
    result = prime * result + age;
    return result;
}
```

在这个例子中，`hashCode()`方法考虑了对象的两个字段：`name`和`age`。它首先初始化一个结果变量，然后根据每个字段的哈希码来计算最终的哈希码。**注意，这里使用了31作为乘数，因为它是奇素数，可以提供更好的哈希分布。**

在Java中，使用31作为乘数来计算哈希码基于以下几点考虑：

1.  **奇数乘法**：使用奇数作为乘数可以避免哈希码的低位和高位发生冲突。如果使用偶数乘以一个整数，那么结果的最低位（即偶数位）将总是0，这会降低哈希码的随机性和分布性。使用奇数可以确保结果的每一位都可能发生变化。

2.  **31的特殊性**：选择31作为乘数是因为它是一个奇素数，而且在乘法运算中，31可以被优化为 `(i << 5) - i`，其中`i`是当前字段的哈希码。这种优化可以提高计算效率，因为位移和减法比直接乘法更快。

3.  **乘法的性能**：乘法运算通常比除法运算快，尤其是在现代处理器上。使用31作为乘数，可以利用处理器的优化来提高性能。

4.  **哈希码的分布**：使用31作为乘数可以产生一个较好的哈希码分布，这有助于减少哈希冲突，提高哈希表的性能。

5.  **可读性和一致性**：使用31作为乘数在Java社区中已经形成了一种约定，这有助于保持代码的可读性和一致性。

下面是一个简单的例子，展示如何使用31来计算哈希码：

```java
int hash = 1;
hash = 31 * hash + field1.hashCode();
hash = 31 * hash + field2.hashCode();
// ... 对其他字段进行同样的操作
```

在这个例子中，`field1.hashCode()`和`field2.hashCode()`是对象中各个字段的哈希码。通过将它们与31相乘并累加到`hash`变量中，我们得到了一个基于这些字段的哈希码。

需要注意的是，虽然31是一个常用的乘数，但并不是唯一的选择。在某些情况下，根据具体的应用场景和性能要求，开发者可能会选择其他数值作为乘数。重要的是选择一个奇数乘数，并且确保它能够提供良好的哈希码分布。

## Java的四种引用，强弱软虚

在Java中，引用类型分为四种：强引用（Strong Reference）、软引用（Soft Reference）、弱引用（Weak Reference）和虚引用（Phantom Reference）。每种引用类型都有其特定的用途和行为。

强引用（Strong Reference）

强引用是最常见的引用类型。当一个对象通过强引用被引用时，它不会被垃圾回收器回收，即使内存不足。只有当没有任何强引用指向该对象时，它才会被垃圾回收器回收。

```java
Object strongRef = new Object();
```

软引用（Soft Reference）

软引用是一种比强引用弱的引用。当一个对象只有软引用指向它时，它只有在内存不足的情况下才会被垃圾回收器回收。软引用通常用于实现内存敏感的缓存。

```java
SoftReference<Object> softRef = new SoftReference<>(new Object());
```

弱引用（Weak Reference）

弱引用比软引用更弱。当一个对象只有弱引用指向它时，它随时都可能被垃圾回收器回收，即使在内存充足的情况下。弱引用通常用于实现映射表，如`WeakHashMap`。

```java
WeakReference<Object> weakRef = new WeakReference<>(new Object());
```

虚引用（Phantom Reference）

虚引用是最弱的引用类型。它不会影响对象的生命周期，即使有虚引用指向对象，该对象也可能被垃圾回收器回收。虚引用主要用于跟踪对象被垃圾回收器回收的活动。虚引用必须与引用队列（ReferenceQueue）一起使用，以便在对象被回收时得到通知。

```java
ReferenceQueue<Object> queue = new ReferenceQueue<>();
PhantomReference<Object> phantomRef = new PhantomReference<>(new Object(), queue);
```

虚引用的主要用途是实现更精细的控制，比如在对象被回收后执行一些清理工作。

每种引用类型都有其特定的使用场景，开发者可以根据需要选择合适的引用类型来管理对象的生命周期。在实际应用中，软引用和弱引用常用于缓存和映射表，而虚引用则用于更高级的内存管理。

在实际开发中，软引用（Soft Reference）和弱引用（Weak Reference）的选择取决于你希望如何管理对象的生命周期以及你对内存使用的敏感程度。

软引用（Soft Reference）

软引用用于实现内存敏感的缓存。当内存不足时，JVM会回收这些对象，以避免`OutOfMemoryError`。因此，软引用适合于那些可以被回收但又希望尽可能长时间保留的对象。

**使用场景**：

*   缓存：当你需要缓存一些数据，但又不想因为缓存而耗尽内存导致应用崩溃时，可以使用软引用。
*   图像处理：在图像处理应用中，可以使用软引用缓存图像，当内存不足时，这些图像可以被回收。

**示例**：

```java
SoftReference<byte[]> softRef = new SoftReference<>(new byte[1024 * 1024]);
```

弱引用（Weak Reference）

弱引用用于那些即使被引用也随时可能被垃圾回收器回收的对象。弱引用不会阻止对象被回收，因此适合于那些生命周期短暂的对象。

**使用场景**：

*   映射表：在`WeakHashMap`中，键是弱引用，这样当键不再被其他地方引用时，整个键值对可以被回收。
*   临时对象：当你需要创建一些临时对象，但又不希望这些对象影响垃圾回收时，可以使用弱引用。

**示例**：

```java
WeakReference<String> weakRef = new WeakReference<>(new String("临时字符串"));
```

如何选择

选择软引用还是弱引用，主要取决于你对对象生命周期的控制需求：

*   如果你希望对象在内存不足时被回收，但又希望尽可能长时间地保留它们，那么应该使用软引用。
*   如果你希望对象在没有其他强引用时被回收，那么应该使用弱引用。

在实际应用中，软引用和弱引用的使用需要谨慎，因为它们可能会导致对象的生命周期变得难以预测。在使用这些引用时，应该确保你的应用逻辑能够处理对象可能随时被回收的情况。

## finalize() 方法

`finalize()` 方法是Java中一个特殊的方法，它属于`Object`类，因此所有Java对象都继承了这个方法。`finalize()`方法的目的是在垃圾收集器执行时，为对象提供一个执行清理工作的机会。当一个对象不再被任何引用所指向时，垃圾收集器可能会在回收该对象之前调用它的`finalize()`方法。

`finalize()`方法的声明如下：

```java
protected void finalize() throws Throwable {
    // 清理代码
}
```

需要注意的是，`finalize()`方法的使用存在一些限制和问题：

1.  **不确定性**：垃圾收集器何时调用`finalize()`方法是不确定的。它可能在对象被回收之前、之后，或者根本不调用。因此，不应该依赖`finalize()`方法来执行关键的清理工作。

2.  **性能影响**：`finalize()`方法的执行会增加垃圾收集的开销，因为它需要额外的处理来调用对象的`finalize()`方法。

3.  **资源释放**：如果对象持有外部资源（如文件、数据库连接等），应该使用`try-finally`块或`try-with-resources`语句来确保这些资源被正确释放，而不是依赖`finalize()`方法。

4.  **异常处理**：`finalize()`方法可以抛出任何异常，但这些异常会被垃圾收集器忽略。因此，不应该在`finalize()`方法中抛出异常。

5.  **不推荐使用**：由于上述原因，Java官方文档明确指出，`finalize()`方法不应该被使用。在Java 9及以后的版本中，`finalize()`方法被标记为`@Deprecated`，并推荐使用其他方式来管理资源。

由于`finalize()`方法的这些限制和问题，现代Java开发中通常不推荐使用它。相反，应该使用`try-finally`块、`try-with-resources`语句或`AutoCloseable`接口来确保资源的正确释放。这些方法提供了更明确、更可靠的方式来管理资源，避免了`finalize()`方法的不确定性。

## 排序都有哪几种方法？请列举

排序算法是计算机科学中一个非常重要的主题，用于将一系列元素按照一定的顺序排列。排序算法的种类繁多，每种算法都有其特定的使用场景和性能特点。以下是一些常见的排序算法：

1.  **冒泡排序（Bubble Sort）**
    *   简单直观，通过重复遍历待排序的数列，比较相邻元素，如果顺序错误就交换它们。
    *   时间复杂度：平均和最坏情况为O(n^2)，最好情况为O(n)。

冒泡排序的基本步骤：

1.  **比较相邻元素**：从数列的第一个元素开始，比较相邻的两个元素。如果第一个比第二个大，就交换它们两个。
2.  **每一轮遍历**：对每一对相邻元素做同样的工作，从开始第一对到结尾的最后一对。这步做完后，最后的元素会是最大的数。
3.  **重复步骤**：针对所有的元素重复以上的步骤，除了最后一个。
4.  **持续减少未排序数列的长度**：每次遍历后，未排序的数列长度减1，直到所有元素都已排序。

示例：

```java
public class BubbleSortExample {

    public static void bubbleSort(int[] arr) {
        // 获取数组的长度
        int n = arr.length;
        // 外层循环控制排序的轮数
        for (int i = 0; i < n - 1; i++) {
            // 内层循环负责每轮的比较和交换
            for (int j = 0; j < n - 1 - i; j++) {
                // 如果当前元素大于下一个元素，则交换它们
                if (arr[j] > arr[j + 1]) {
                    // 交换arr[j]和arr[j+1]
                    int temp = arr[j];
                    arr[j] = arr[j + 1];
                    arr[j + 1] = temp;
                }
            }
        }
    }

    public static void main(String[] args) {
        // 待排序的数组
        int[] arr = {64, 34, 25, 12, 22, 11, 90};

        // 打印原始数组
        System.out.println("Original array:");
        printArray(arr);

        // 调用冒泡排序方法
        bubbleSort(arr);

        // 打印排序后的数组
        System.out.println("Sorted array:");
        printArray(arr);
    }

    // 辅助方法，用于打印数组
    private static void printArray(int[] arr) {
        for (int value : arr) {
            System.out.print(value + " ");
        }
        System.out.println();
    }
}
```

冒泡排序虽然简单，但效率较低，特别是对于大数据集来说，它不是一种高效的排序方法。在实际应用中，通常会使用更高效的排序算法，如快速排序、归并排序或堆排序。

1.  **选择排序（Selection Sort）**
    *   每次从待排序的数据元素中选出最小（或最大）的一个元素，存放在序列的起始位置，直到全部待排序的数据元素排完。
    *   时间复杂度：平均和最坏情况为O(n^2)。

选择排序的基本步骤：

1.  **初始化**：将数组的第一个元素视为已排序部分，剩余的视为未排序部分。
2.  **选择最小（或最大）元素**：在未排序部分中找到最小（或最大）的元素。
3.  **交换**：将找到的最小（或最大）元素与未排序部分的第一个元素交换位置。
4.  **重复**：重复步骤2和3，直到未排序部分为空。

示例：

```java
public class SelectionSortExample {

    public static void selectionSort(int[] arr) {
        // 遍历数组中的每个元素
        for (int i = 0; i < arr.length - 1; i++) {
            // 假设当前索引处的元素是最小的
            int minIndex = i;
            // 遍历未排序部分的元素
            for (int j = i + 1; j < arr.length; j++) {
                // 如果找到更小的元素，则更新最小索引
                if (arr[j] < arr[minIndex]) {
                    minIndex = j;
                }
            }
            // 如果最小元素不是当前索引处的元素，则交换它们
            if (minIndex != i) {
                int temp = arr[i];
                arr[i] = arr[minIndex];
                arr[minIndex] = temp;
            }
        }
    }

    public static void main(String[] args) {
        // 待排序的数组
        int[] arr = {64, 25, 12, 22, 11};

        // 打印原始数组
        System.out.println("Original array:");
        printArray(arr);

        // 调用选择排序方法
        selectionSort(arr);

        // 打印排序后的数组
        System.out.println("Sorted array:");
        printArray(arr);
    }

    // 辅助方法，用于打印数组
    private static void printArray(int[] arr) {
        for (int value : arr) {
            System.out.print(value + " ");
        }
        System.out.println();
    }
}
```

选择排序算法虽然简单，但效率较低，特别是对于大数据集来说，它不是一种高效的排序方法。在实际应用中，通常会使用更高效的排序算法，如快速排序、归并排序或堆排序。

1.  **插入排序（Insertion Sort）**
    *   通过构建有序序列，对于未排序数据，在已排序序列中从后向前扫描，找到相应位置并插入。
    *   时间复杂度：平均和最坏情况为O(n^2)，最好情况为O(n)。

它的工作原理是通过构建有序序列，对于未排序数据，在已排序序列中从后向前扫描，找到相应位置并插入。插入排序在实现上，通常使用in-place排序（即只需用到O(1)的额外空间的排序），因而在从后向前扫描过程中，需要反复把已排序元素逐步向后挪位，为最新元素提供插入空间。

插入排序的基本步骤：

1.  从第一个元素开始，该元素可以认为已经被排序。
2.  取出下一个元素，在已经排序的元素序列中从后向前扫描。
3.  如果该元素（已排序）大于新元素，将该元素移到下一位置。
4.  重复步骤3，直到找到已排序的元素小于或者等于新元素的位置。
5.  将新元素插入到该位置后。
6.  重复步骤2\~5。

示例：

```java
public class InsertionSortExample {

    public static void insertionSort(int[] arr) {
        // 遍历数组中的每个元素
        for (int i = 1; i < arr.length; i++) {
            // 选择当前元素作为要插入的值
            int current = arr[i];
            // j是已排序部分的最后一个元素的索引
            int j = i - 1;

            // 将已排序部分的元素向后移动，直到找到正确的位置插入current
            while (j >= 0 && arr[j] > current) {
                // 将大于current的元素向后移动
                arr[j + 1] = arr[j];
                // 移动到前一个元素
                j--;
            }
            // 将current插入到正确的位置
            arr[j + 1] = current;
        }
    }

    public static void main(String[] args) {
        // 待排序的数组
        int[] arr = {9, 5, 1, 4, 3};

        // 打印原始数组
        System.out.println("Original array:");
        printArray(arr);

        // 调用插入排序方法
        insertionSort(arr);

        // 打印排序后的数组
        System.out.println("Sorted array:");
        printArray(arr);
    }

    // 辅助方法，用于打印数组
    private static void printArray(int[] arr) {
        for (int value : arr) {
            System.out.print(value + " ");
        }
        System.out.println();
    }
}
```

1.  **快速排序（Quick Sort）**
    *   采用分治法策略，通过一个基准元素将数组分为两部分，一边的元素都比基准小，另一边的元素都比基准大，然后递归地对这两部分继续进行排序。
    *   时间复杂度：平均情况为O(n log n)，最坏情况为O(n^2)。

示例

```java
import java.util.Random;

public class QuickSortExample {

    // 快速排序方法，接受数组以及要排序的子数组的起始和结束索引
    public static void quickSort(int[] arr, int low, int high) {
        // 如果子数组的起始索引小于结束索引，说明子数组中至少有两个元素，需要进行排序
        if (low < high) {
            // 调用partition方法进行分区，并获取分区后的基准值索引
            int index = partition(arr, low, high);

            // 递归地对基准值左侧的子数组进行快速排序
            quickSort(arr, low, index - 1);
            // 递归地对基准值右侧的子数组进行快速排序
            quickSort(arr, index + 1, high);
        }
    }

    // 分区方法，用于将数组分为两部分，并返回基准值的最终索引
    private static int partition(int[] arr, int low, int high) {
        // 随机选择一个基准值索引，以避免最坏情况下的性能
        Random random = new Random();
        int pivotIndex = low + random.nextInt(high - low + 1);
        // 将随机选择的基准值与子数组的最后一个元素交换位置
        swap(arr, pivotIndex, high);

        // 选择最后一个元素作为基准值
        int pivot = arr[high];

        // i用于记录小于基准值的元素的最后一个位置
        int i = (low - 1);

        // 遍历子数组，将小于基准值的元素移动到基准值的左侧
        for (int j = low; j < high; j++) {
            // 如果当前元素小于或等于基准值
            if (arr[j] <= pivot) {
                // 将i加1，并交换arr[i]和arr[j]的位置
                i++;
                swap(arr, i, j);
            }
        }

        // 将基准值放到正确的位置（i+1），此时i+1左边的元素都小于基准值
        swap(arr, i + 1, high);

        // 返回基准值的最终索引
        return i + 1;
    }

    // 交换数组中两个元素的位置
    private static void swap(int[] arr, int i, int j) {
        int temp = arr[i];
        arr[i] = arr[j];
        arr[j] = temp;
    }

    // 主方法，用于演示快速排序的过程
    public static void main(String[] args) {
        // 创建一个待排序的数组
        int[] arr = {10, 7, 8, 9, 1, 5};
        // 获取数组的长度
        int n = arr.length;

        // 打印原始数组
        System.out.println("Original array:");
        printArray(arr);

        // 调用快速排序方法对数组进行排序
        quickSort(arr, 0, n - 1);

        // 打印排序后的数组
        System.out.println("Sorted array:");
        printArray(arr);
    }

    // 辅助方法，用于打印数组中的所有元素
    private static void printArray(int[] arr) {
        for (int value : arr) {
            System.out.print(value + " ");
        }
        System.out.println();
    }
}
```

1.  **归并排序（Merge Sort）**
    *   采用分治法策略，将数组分成两半，分别排序，然后合并。
    *   时间复杂度：稳定排序，平均和最坏情况均为O(n log n)。

2.  **堆排序（Heap Sort）**
    *   利用堆这种数据结构所设计的一种排序算法，通过构建一个大顶堆或小顶堆，然后依次取出堆顶元素并重新调整堆结构。
    *   时间复杂度：平均和最坏情况均为O(n log n)。

3.  **计数排序（Counting Sort）**
    *   非比较排序，适用于一定范围内的整数排序。通过统计每个整数出现的次数，然后根据统计结果进行排序。
    *   时间复杂度：O(n + k)，其中k是整数的范围。

4.  **桶排序（Bucket Sort）**
    *   将数组分到有限数量的桶里，每个桶再个别排序（有可能再使用别的排序算法或是以递归方式继续使用桶排序进行排序）。
    *   时间复杂度：平均情况为O(n + k)，其中k是桶的数量。

5.  **基数排序（Radix Sort）**
    *   非比较排序，通过键值的各个位的值，将要排序的元素分配到有限数量的桶里，再从桶中收集元素。
    *   时间复杂度：平均和最坏情况均为O(nk)，其中n是元素数量，k是位数。

每种排序算法都有其适用场景，例如，快速排序在大多数情况下效率较高，但对小规模数据或已排序数据效率不高；归并排序在数据量大时性能稳定，但需要额外的存储空间；计数排序和桶排序适用于特定范围内的整数排序等。在实际应用中，选择合适的排序算法可以显著提高程序的性能。

## 泛型擦除

Java中的泛型是一种在**编译时**提供类型安全的机制，允许在定义类、接口和方法时使用类型参数。泛型的主要目的是允许程序员编写通用的代码，这些代码可以适用于多种数据类型，同时保持类型安全。泛型在Java 5中引入。

泛型的基本概念

泛型允许你定义类、接口和方法时使用类型参数（如`<T>`），这些类型参数在使用时会被具体类型（如`Integer`、`String`等）替换。例如，`List<T>`是一个泛型接口，可以被实例化为`List<Integer>`、`List<String>`等。

泛型的好处

1.  **类型安全**：泛型确保在编译时类型检查，避免了类型转换错误和`ClassCastException`。
2.  **代码重用**：泛型允许编写通用的代码，可以适用于多种数据类型，减少了代码的重复。
3.  **清晰的API**：泛型使得API更加清晰，因为类型参数直接表明了方法或类的预期类型。

泛型擦除

尽管泛型提供了类型安全，但Java的泛型实现采用了类型擦除（Type Erasure）机制。这意味着泛型信息在编译后会被擦除，运行时不会保留泛型类型信息。具体来说，泛型类型参数会被替换为它们的边界类型（如果没有指定边界，则为`Object`），泛型类和接口会被转换为非泛型类和接口。

例如，考虑以下泛型类：

```java
public class Box<T> {
    private T t;

    public void set(T t) {
        this.t = t;
    }

    public T get() {
        return t;
    }
}
```

在编译后，`Box<T>`会被转换为：

```java
public class Box {
    private Object t;

    public void set(Object t) {
        this.t = t;
    }

    public Object get() {
        return t;
    }
}
```

**泛型擦除的主要原因**是为了保持向后兼容性，因为Java泛型是在Java 5中引入的，而在此之前，Java代码已经广泛使用了。泛型擦除确保了泛型代码可以与非泛型代码无缝交互。

泛型擦除的限制

由于泛型擦除，以下限制存在：

1.  **不能创建泛型数组**：因为数组需要在运行时知道其确切类型，而泛型信息在运行时被擦除了。
2.  **不能使用基本类型作为泛型类型参数**：因为基本类型不能作为对象使用，而泛型擦除后，类型参数会被替换为`Object`类型。
3.  **不能使用instanceof检查泛型类型**：因为泛型信息在运行时被擦除，所以无法使用`instanceof`来检查泛型类型。

尽管存在这些限制，泛型仍然是Java中非常强大的特性，它极大地提高了代码的类型安全性和可读性。

## try catch finally return 的执行顺序

在Java中，`try-catch-finally`语句块用于处理异常。`finally`块无论是否发生异常都会执行，而`return`语句则用于从方法中返回一个值。当`try`块或`catch`块中包含`return`语句时，`finally`块的执行顺序可能会引起一些混淆。以下是`try-catch-finally`块中`return`语句的执行顺序：

1.  **执行`try`块**：首先执行`try`块中的代码。
2.  **异常发生**：如果在`try`块中发生异常，控制流会跳转到与之匹配的`catch`块。
3.  **执行`catch`块**：如果存在匹配的`catch`块，执行`catch`块中的代码。如果`catch`块中包含`return`语句，那么`finally`块会在`return`语句执行之前执行。
4.  **执行`finally`块**：无论是否发生异常，`finally`块都会执行。如果`try`块或`catch`块中包含`return`语句，`finally`块会在`return`语句执行之前执行，但`finally`块中的`return`语句会覆盖`try`或`catch`块中的`return`语句。
5.  **返回值**：`finally`块执行完毕后，方法返回`finally`块中`return`的值，或者如果`finally`块中没有`return`语句，则返回`try`或`catch`块中`return`的值。

下面是一个简单的例子来说明这个执行顺序：

```java
public class TryCatchFinallyExample {
    public static int exampleMethod() {
        try {
            System.out.println("Try block");
            return 1; // ①
        } catch (Exception e) {
            System.out.println("Catch block");
            return 2; // ②
        } finally {
            System.out.println("Finally block");
            return 3; // ③
        }
    }

    public static void main(String[] args) {
        int result = exampleMethod();
        System.out.println("Returned value: " + result);
    }
}
```

输出将会是：

    Try block
    Finally block
    Returned value: 3

在这个例子中，尽管`try`块中有一个`return`语句，`finally`块中的`return`语句仍然会覆盖它，并且方法返回`finally`块中的值。如果`finally`块中没有`return`语句，那么方法将返回`try`块中的值。

# java 集合

## java 中都有哪些常用数据结构

Java 提供了丰富的数据结构，这些数据结构被封装在 `java.util` 包中。以下是一些常用的 Java 数据结构：

1.  **List**：有序集合，可以包含重复元素。
    *   **ArrayList**：基于动态数组实现，允许所有元素，包括null。
    *   **LinkedList**：基于链表实现，允许快速插入和删除操作。
    *   **Vector**：类似于ArrayList，但它是线程安全的。

2.  **Set**：不允许重复元素的集合。
    *   **HashSet**：基于哈希表实现，不保证元素的顺序。底层基于 HashMap 实现。
    *   **LinkedHashSet**：基于哈希表和链表实现，保持插入顺序。
    *   **TreeSet**：基于红黑树实现，保持元素的自然排序或自定义排序。

3.  **Queue**：用于处理先进先出（FIFO）的数据结构。
    *   **LinkedList**：实现了Queue接口，可以作为队列使用。
    *   **PriorityQueue**：基于优先级堆实现的队列，元素按照优先级顺序被移除。

4.  **Deque**：双端队列，允许在两端进行插入和删除操作。
    *   **ArrayDeque**：基于动态数组实现的双端队列。
    *   **LinkedList**：也可以作为双端队列使用。

5.  **Map**：存储键值对的数据结构。
    *   **HashMap**：基于哈希表实现，允许null键和null值。
    *   **LinkedHashMap**：基于哈希表和链表实现，保持插入顺序或访问顺序。
    *   **TreeMap**：基于红黑树实现，保持键的自然排序或自定义排序。
    *   **Hashtable**：类似于HashMap，但它是线程安全的，不允许null键和null值。

6.  **Stack**：基于后进先出（LIFO）原则的栈。
    *   **Stack**：继承自Vector，提供了栈的基本操作。

7.  **BitSet**：用于表示一系列布尔值的集合，每个值只占用一位。

8.  **Properties**：用于处理属性文件的类，它继承自Hashtable，通常用于配置文件。

9.  **EnumSet**：用于枚举类型的Set实现，内部使用位向量实现，效率高。

10. **NavigableMap** 和 **NavigableSet**：提供导航功能的接口，如查找最接近的元素等。

这些数据结构提供了不同的操作和性能特性，适用于不同的应用场景。例如，如果你需要快速查找元素，可以使用HashMap；如果你需要保持元素的插入顺序，可以使用LinkedHashMap；如果你需要一个线程安全的集合，可以使用Collections提供的同步包装器，或者使用Vector、Hashtable等线程安全的集合类。

## List

在Java中，`List` 是一个接口，它继承自 `Collection` 接口。`List` 接口代表了一个有序的集合，其中可以包含重复的元素。`List` 接口定义了多种操作，包括添加、删除、获取元素等。`List` 接口的实现类允许我们以索引的方式访问元素，这使得 `List` 成为处理有序数据集合的首选。

### List 接口的主要特点：

*   **有序**：`List` 中的元素是有序的，这意味着元素的顺序是按照它们被添加到列表中的顺序排列的。
*   **可重复**：`List` 允许包含重复的元素。
*   **索引访问**：可以通过元素的索引来访问列表中的元素，索引从0开始。
*   **动态数组**：`List` 的实现通常基于动态数组，这意味着列表的大小可以根据需要自动调整。

### List 接口的主要实现类：

1.  **ArrayList**：
    *   基于动态数组实现，允许所有元素，包括null。
    *   随机访问元素非常快，但插入和删除操作相对较慢，尤其是当操作位于列表的开头或中间时。
    *   非线程安全。

2.  **LinkedList**：
    *   基于双向链表实现，允许快速的插入和删除操作，尤其是在列表的开头和结尾。
    *   随机访问元素相对较慢，因为需要遍历链表。
    *   非线程安全。

3.  **Vector**：
    *   类似于 `ArrayList`，但它是线程安全的。
    *   所有方法都是同步的，这使得它在多线程环境中更加安全，但性能较低。
    *   由于线程安全的开销，`Vector` 在单线程环境中通常不推荐使用。

### List 接口的常用方法：

*   `add(E element)`：在列表末尾添加一个元素。
*   `add(int index, E element)`：在指定位置插入一个元素。
*   `remove(int index)`：移除指定位置的元素。
*   `remove(Object o)`：移除列表中第一个匹配指定元素的元素。
*   `get(int index)`：返回指定位置的元素。
*   `set(int index, E element)`：用指定元素替换列表中指定位置的元素。
*   `size()`：返回列表中的元素数量。
*   `contains(Object o)`：判断列表中是否包含指定的元素。
*   `indexOf(Object o)`：返回指定元素在列表中首次出现的索引，如果不存在则返回-1。

`List` 接口是Java集合框架中的核心接口之一，它提供了丰富的操作集合的方法，使得开发者可以根据具体需求选择合适的实现类。

### ArrayList 添加元素源码分析

首先，我们来看 `ArrayList` 类中添加元素的主要方法 `add(E e)` 的实现。这个方法是 `ArrayList` 类中定义的，用于向列表的末尾添加一个元素。

```java
public boolean add(E e) {
    // 确保数组容量足够，如果不够则进行扩容
    ensureCapacityInternal(size + 1);  // Increments modCount!!
    // 将元素添加到数组的size位置，并将size加1
    elementData[size++] = e;
    return true;
}
```

接下来，我们详细解释一下 `ensureCapacityInternal(int minCapacity)` 方法，这个方法用于确保 `ArrayList` 的内部数组有足够的空间来容纳新的元素。

```java
private void ensureCapacityInternal(int minCapacity) {
    // 如果是第一次添加元素，minCapacity为1，否则为当前size加1
    if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) {
        minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity);
    }
    // 确保数组容量足够
    ensureExplicitCapacity(minCapacity);
}

private void ensureExplicitCapacity(int minCapacity) {
    // 修改次数加1，用于检测并发修改异常
    modCount++;

    // 如果当前容量小于所需的最小容量，则进行扩容
    if (minCapacity - elementData.length > 0)
        grow(minCapacity);
}
```

`grow(int minCapacity)` 方法是 `ArrayList` 扩容的核心方法，它会创建一个新的数组，并将旧数组中的元素复制到新数组中。

```java
private void grow(int minCapacity) {
    // 计算新数组的容量
    int oldCapacity = elementData.length;
    int newCapacity = oldCapacity + (oldCapacity >> 1); // 新容量为旧容量的1.5倍
    if (newCapacity - minCapacity < 0)
        newCapacity = minCapacity;
    if (newCapacity - MAX_ARRAY_SIZE > 0)
        newCapacity = hugeCapacity(minCapacity);
    // 创建新数组，并将旧数组中的元素复制到新数组中
    elementData = Arrays.copyOf(elementData, newCapacity);
}
```

`hugeCapacity(int minCapacity)` 方法用于处理当新容量超过 `Integer.MAX_VALUE` 时的情况。

```java
private static int hugeCapacity(int minCapacity) {
    if (minCapacity < 0) // 如果minCapacity小于0，抛出异常
        throw new OutOfMemoryError();
    // 返回Integer.MAX_VALUE或minCapacity中的较大值
    return (minCapacity > MAX_ARRAY_SIZE) ?
        Integer.MAX_VALUE :
        MAX_ARRAY_SIZE;
}
```

以上就是 `ArrayList` 添加元素的主要步骤和相关方法的解释。在实际使用中，我们通常不需要直接操作这些底层方法，而是直接调用 `add(E e)` 方法来添加元素。`ArrayList` 会自动处理扩容和元素的添加。

### ArrayList 的扩容机制

`ArrayList` 的扩容机制是自动的，当添加元素到 `ArrayList` 时，如果当前数组的容量不足以容纳新元素，`ArrayList` 会自动进行扩容。扩容机制是 `ArrayList` 实现动态数组的关键部分。

`ArrayList` 在使用没有参数的构造方法时，新建的列表为空数组，size 为 0，在第一次添加元素时进行容量初始化，默认的容量为 10。

扩容机制的步骤：

1.  **检查容量**：当调用 `add` 方法添加元素时，`ArrayList` 首先检查当前数组的容量是否足够。如果当前容量足够，直接将元素添加到数组的末尾。

2.  **自动扩容**：如果当前容量不足，`ArrayList` 会进行扩容。扩容的大小是基于当前容量的，而不是基于添加的元素数量。默认情况下，`ArrayList` 的扩容策略是将容量增加到原来的1.5倍。

3.  **创建新数组**：扩容时，`ArrayList` 会创建一个新的数组，其容量是原数组容量的1.5倍（或指定的其他大小，如果在构造 `ArrayList` 时指定了初始容量）。然后，将原数组中的所有元素复制到新数组中。

4.  **添加新元素**：复制完成后，新元素被添加到新数组的末尾。

5.  **引用更新**：最后，`ArrayList` 将内部数组的引用更新为新数组的引用，以便后续的访问和操作。

扩容的性能影响：

*   **增加内存使用**：每次扩容都会创建一个新的数组，这会消耗额外的内存空间。
*   **复制元素**：扩容时需要将原数组中的所有元素复制到新数组中，这会增加操作的时间复杂度。因此，频繁的扩容操作可能会导致性能下降。

`ArrayList` 的扩容机制是其核心特性之一，它允许 `ArrayList` 在添加元素时动态地增加其内部数组的大小。当 `ArrayList` 的容量不足以容纳新元素时，它会自动扩容。下面是 `ArrayList` 源码中关于扩容机制的实现，以及扩容时机的描述。

扩容时机

`ArrayList` 在添加元素时会检查当前容量是否足够。如果当前容量不足以容纳新元素，它会进行扩容。具体来说，当执行 `add` 方法时，会调用 `ensureCapacityInternal` 方法来检查容量。

扩容机制

`ArrayList` 的扩容机制是通过 `grow` 方法实现的。当需要扩容时，`grow` 方法会计算新的容量，然后使用 `Arrays.copyOf` 方法创建一个新的数组，并将旧数组中的元素复制到新数组中。

源码示例

以下是 `ArrayList` 源码中关于扩容机制的简化示例：

```java
import java.util.Arrays;
import java.util.Objects;

public class ArrayList<E> extends AbstractList<E>
        implements List<E>, RandomAccess, Cloneable, java.io.Serializable {

    // ... 其他成员变量和方法 ...

    // 添加元素到列表末尾
    public boolean add(E e) {
        // 确保容量足够
        ensureCapacityInternal(size + 1);  // Increments modCount!!
        elementData[size++] = e;
        return true;
    }

    // 确保容量足够
    private void ensureCapacityInternal(int minCapacity) {
        // 如果当前容量为默认空数组，则使用默认容量
        if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) {
            minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity);
        }
        ensureExplicitCapacity(minCapacity);
    }

    // 确保容量足够，如果不够则扩容
    private void ensureExplicitCapacity(int minCapacity) {
        modCount++; // 修改次数，用于快速失败机制

        // 如果当前容量小于所需最小容量，则扩容
        if (minCapacity - elementData.length > 0)
            grow(minCapacity);
    }

    // 扩容方法
    private void grow(int minCapacity) {
        // 旧容量
        int oldCapacity = elementData.length;
        // 新容量为旧容量的1.5倍
        int newCapacity = oldCapacity + (oldCapacity >> 1);
        // 如果新容量小于所需最小容量，则使用所需最小容量
        if (newCapacity - minCapacity < 0)
            newCapacity = minCapacity;
        // 如果新容量大于最大容量，则使用最大容量
        if (newCapacity - MAX_ARRAY_SIZE > 0)
            newCapacity = hugeCapacity(minCapacity);
        // 使用新容量创建新数组，并复制旧数组中的元素
        elementData = Arrays.copyOf(elementData, newCapacity);
    }

    // ... 其他成员变量和方法 ...
}
```

在上述代码中，`ensureCapacityInternal` 方法首先检查 `elementData` 是否为默认空数组，如果是，则使用默认容量 `DEFAULT_CAPACITY`（通常是10）。然后，`ensureExplicitCapacity` 方法会检查当前容量是否足够，如果不够，则调用 `grow` 方法进行扩容。

`grow` 方法首先计算新容量，新容量是旧容量的1.5倍（通过位运算实现），然后检查新容量是否满足最小容量要求。如果新容量小于最小容量，则使用最小容量。如果新容量大于最大容量（`MAX_ARRAY_SIZE`），则调用 `hugeCapacity` 方法来处理。最后，使用 `Arrays.copyOf` 方法创建一个新数组，并将旧数组中的元素复制到新数组中。

## Map

### HashMap

#### HashMap 中数据的存储结构

JDK1.7前 : 数组+链表

JDK1.8+ : 数组+链表+红黑树

每个哈希桶位中可以存在多个node节点，其中node节点为key+value+hashCode+next 组成，其中k,v存储了存放的数据信息，next存储当哈希冲突时指向下个node的信息。

![](https://raw.githubusercontent.com/MrSunflowers/images/main/note/images/202205141420146.png)

#### HashMap 中链表转为红黑树的条件

**链表长度大于8且数组长度大于等于64(不满足则会发生扩容代替升级)，当删除小于6时重新变为链表**，根据**泊松分布**，在负载因子默认为0.75的时候，单个hash槽内元素个数为8的概率小于百万分之一，所以将7作为一个分水岭，等于7的时候不转换，大于等于8的时候才进行转换，**小于等于6的时候就转化回链表结构**。

#### HashMap 扰动算法计算 hashCode

HashMap 中每个 node 节点中存储的 hashCode 并不是直接调用 Object::hashCode() 方法得出的哈希值，而是经过一种叫做扰动算法处理过的哈希值，具体的处理逻辑是使用 key 的 hash 值经过无符号右移 16 位，再与 key 原来的 hash 值进行进行与异或运算（如果a、b两个值不相同，则异或结果为1。如果a、b两个值相同，异或结果为0），在源码中的体现如下：

```java
static final int hash(Object key) {
   int h;
   return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
}
```

采用这种算法其实是对虚拟机哈希算法的补充，目的是使散列更加均匀。因为 table 当前的长度是不固定的，在进行存放和寻址时肯定要尽可能多的让表的长度和 key 的 hash 值产生联系，最简单的联系就是使用 key 的 hash 值对表的长度取余。

当表的长度为 2 的 n 次幂时，`hashCode % table.length = hashCode & (table.length-1)` ，由于 table.length 为 2 的次方数，转换为 2 进制是：1 0000（16） 这种形式，也就是高位为 1 ，其余全部为 0，其进行减一操作后变为 1111（15）也就是高位为 0 ，其余全部为 1，且 java 中 hashCode 为 32 位，此时如果仅仅使用 `hashCode & (table.length-1)` 操作，则算出来的值只保留了 hash 值低四位的特征，前面还有28位的特征全部丢失了：

假设 key 调用 hashCode() 方法后的值不做右移 16 和按位异或运算，直接和 (n-1) 做与运算

    1111 1111 1111 1111 1111 0000 1100 0001
    0000 0000 0000 0000 0000 0000 0000 1111 ----> n-1
    0000 0000 0000 0000 0000 0000 0000 0001 ----> 结果是1

结果是1

假设这时再来一个key2值，它调用hashCode()方法后的值为:

    1100 1001 1101 1101 0011 0000 1100 0001
    0000 0000 0000 0000 0000 0000 0000 1111 ---->n-1
    0000 0000 0000 0000 0000 0000 0000 0001 ----> 结果是1

结果仍然是1

再把上面的key2值的hash值做右移16和按位异或运算，再和(n-1)做与运算

    1100 1001 1101 1101 0011 0000 1100 0001
    0000 0000 0000 0000 1100 1001 1101 0011 ----> 右移16位后的值（h >>> 16）
    1100 1001 1101 1101 1111 1001 0001 0010 ----> 异或运算
    0000 0000 0000 0000 0000 0000 0000 1111 ----> n-1
    0000 0000 0000 0000 0000 0000 0000 0010 ----> 结果是2

结果是2

key的hash值经过无符号右移16位，再与key原来的hash值进行 ^ 运算，就能很好的保留hash值的所有特征，这种离散效果才是我们最想要的

![](https://raw.githubusercontent.com/MrSunflowers/images/main/note/images/202205112221896.png)

#### HashMap 寻址算法

由于散列表的长度是2的次方数，比如16,32,64等，寻址算法为 哈希码按位与散列表的长度减一 ：hashCode&(table.length-1) ，其实就等于取余 hashCode%table.length，**注意：只有散列表的长度是2的次方数时两个才相等**

总结：哈希码的高16位与低16位进行异或扰动，然后对链表长度取余计算出地址。

#### HashMap 中的散列表是什么时候创建的

HashMap 中的散列表使用懒加载的方式创建，**在第一次 put 数据的时候创建**，默认初始化容量为16，如果传入17则会寻找2的倍数最小值，应该找到的是32

```java
static final int tableSizeFor(int cap) {
    int n = cap - 1;
    n |= n >>> 1;
    n |= n >>> 2;
    n |= n >>> 4;
    n |= n >>> 8;
    n |= n >>> 16;
    return (n < 0) ? 1 : (n >= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;
}
```

向右移位1、2、4、8、16，这主要是为了把二进制的各个位置都填上1，当二进制的各个位置都是1以后，就是一个标准的2的倍数减1了，最后把结果加1再返回即可。

![](https://raw.githubusercontent.com/MrSunflowers/images/main/note/images/202205112235605.png)

#### HashMap put 的流程

1.  通过扰动算法计算 key 的哈希码
2.  判断当前散列表是否为空，是空则创建散列表，默认长度为 16
3.  计算需要插入到桶数组的位置下标，这里会有四种情况
    1.  如果下标位置没有元素，直接新建节点插入
    2.  如果下标位置不为空，且此位置还没有形成链表，则判断当前节点与目标节点的key是否相同，相同则用新value替换旧value，否则新建节点插入1.7为头插法，1.8为尾插法
    3.  此位置已经形成链表，迭代查找node，是否有重复的，与5相同，插入后检查是否需要树化，判断链表长度是否大于8，且桶数组长度大于64，满足条件则转换为红黑树存储，否则进行扩容处理
    4.  如果已经树化，则新建节点插入树中
4.  判断元素个数是否到达扩容临界点（数组容量\*负载因子），到达则扩容

#### HashMap get的流程

1.  通过扰动算法计算 key 的哈希码
2.  计算需要插入到桶数组的位置下标，这里也会有四种情况
    1.  如果下标位置为空，则返回空，说明没有查找到
    2.  如果下标位置不为空，且此位置还没有形成链表，则判断当前节点与目标节点的key是否相同，相同则返回value
    3.  如果已经树化，则从树中查找
    4.  如果已经形成链表，则遍历链表查找元素

#### HashMap 的负载因子为什么是 0.75

负载因子是和扩容机制有关的，如果当前容器的容量，达到了我们设定的最大值，就要开始执行扩容操作。举个例子：

比如说当前的容器容量是16，负载因子是0.75,16\*0.75=12，也就是说，**默认情况下当容量达到了12的时候就会进行扩容操作。**

当负载因子是1.0的时候，也就意味着，只有当数组的8个值（这个图表示了8个）全部填充了，才会发生扩容。这就带来了很大的问题，因为Hash冲突时避免不了的。当负载因子是1.0的时候，意味着会出现大量的Hash的冲突，底层的红黑树变得异常复杂。对于查询效率极其不利。这种情况就是牺牲了时间来保证空间的利用率。

负载因子过大，虽然空间利用率上去了，但是时间效率降低了

负载因子是0.5的时候，这也就意味着，当数组中的元素达到了一半就开始扩容，既然填充的元素少了，Hash冲突也会减少，那么底层的链表长度或者是红黑树的高度就会降低。查询效率就会增加。

**负载因子0.75**

这是时间和空间的权衡，大致意思就是说负载因子是0.75的时候，空间利用率比较高，而且避免了相当多的Hash冲突，使得底层的链表或者是红黑树的高度比较低，提升了空间效率。

#### HashMap 扩容过程

1.  **判断旧的表是已经否达到了最大扩容容量**，也就是 1<<30 ，（由于 java 中 int 类型最大为 32 位，而最高位为符号位，所以 hashMap 数组的最大值等于 int 的最大值，为 2 的 31 次幂减一），达到最大扩容容量后将临界值变为 `Integer.MAX_VALUE` 并返回旧表。
2.  否则进行扩容，扩容将旧表容量和扩容临界值都左移一位，即乘以 2
3.  遍历旧表的每个桶位，分为以下情况：
    1.  如果当前位置没有链化，则直接使用 node 中存储的 hash 值与\*\*新表长度 -1 \*\* `(e.hash & (newCap - 1))` 进行与运算得到新表中的位置
    2.  如果已经链化，则遍历链中的每个元素，根据 node 中存储的 hash 值与**旧表长度**进行与运算是否为 0  `((e.hash & oldCap) == 0)` 来分为两种情况，为 0 则说明该元素到新表中位置相同，否则使用该元素在旧表的位置加上旧表的长度作为新表中的位置，原因是新表的长度是旧表长度左移一位得到的，所以只需要关注最高位是否变化就可以知道新表的位置

#### ArrayList、Hashtable、HashMap初始化大小

*   ArrayList初始化n=10个空间扩容(n3)/2 + 1,如果不够设置传入的值

*   HashMap初始化n=16空间扩容2n,在并发环境下，1.7 可能会形成环状链表（扩容时可能造成）

*   Hashtable初始化n=11空间扩容2n+1

*   jdk1.6ConcurrentHashMap初始化segments=16个空间每个segments是初始化一个HashEntry 扩容segments=n2

*   jdk1.7ConcurrentHashMap初始化segments=16个空间每个segments是初始化两个HashEntry 扩容segments=n\*2

### HashMap 源码实现

HashMap是应用更广泛的`哈希表`实现，而且大部分情况下，都能在常数时间性能的情况下进行put和get操作。要掌握HashMap，主要从如下几点来把握：

*   jdk1.7中底层是由**数组（也有叫做“位桶”的）+链表**实现；jdk1.8中底层是由**数组+链表/红黑树**实现
*   可以存储null键和null值，线程不安全。在HashMap中，null可以作为键，这样的键只有一个，但可以有一个或多个键所对应的值为null。`当get()方法返回null值时，即可以表示HashMap中没有该key，也可以表示该key所对应的value为null`。因此，在HashMap中不能由get()方法来判断HashMap中是否存在某个key，应该用`containsKey()`方法来判断。而在Hashtable中，无论是key还是value都不能为null。
*   初始size为**16**，扩容：newsize = oldsize\*2，`size一定为2的n次幂`
*   扩容针对整个Map，每次扩容时，原来数组中的元素依次重新计算存放位置，并重新插入
*   插入元素后才判断该不该扩容，有可能无效扩容（插入后如果扩容，如果没有再次插入，就会产生无效扩容）
*   当Map中元素总数超过Entry数组的75%，触发扩容操作，为了减少链表长度，元素分配更均匀
*   1.7中是**先扩容后插入**新值的，1.8中是**先插值再扩容**

`为什么说HashMap是线程不安全的？`在接近临界点时，若此时两个或者多个线程进行put操作，都会进行resize（扩容）和reHash（为key重新计算所在位置），而reHash在并发的情况下可能会形成`链表环`。总结来说就是在多线程环境下，使用HashMap进行put操作会引起死循环，导致CPU利用率接近100%，所以在并发情况下不能使用HashMap。为什么在并发执行put操作会引起死循环？是因为多线程会导致HashMap的Entry链表形成环形数据结构，一旦形成环形数据结构，Entry的next节点永远不为空，就会产生死循环获取Entry。jdk1.7的情况下，并发扩容时容易形成链表环，此情况在1.8时就好太多太多了。因为在1.8中当链表长度大于阈值（默认长度为8）时，链表会被改成树形（红黑树）结构。

#### jdk1.7中HashMap的实现

##### 初始容量及存储形式

HashMap底层维护的是数组+链表，我们可以通过一小段源码来看看：

```java
 /**
  * The default initial capacity - MUST be a power of two.
  *  即 默认初始大小，值为16
  */
 static final int DEFAULT_INITIAL_CAPACITY = 1 << 4; // aka 16

 /**
  * The maximum capacity, used if a higher value is implicitly specified
  * by either of the constructors with arguments.
  * MUST be a power of two <= 1<<30.
  *  即 最大容量，必须为2^30
  */
 static final int MAXIMUM_CAPACITY = 1 << 30;

 /**
  * The load factor used when none specified in constructor.
  * 负载因子为0.75
  */
 static final float DEFAULT_LOAD_FACTOR = 0.75f;

 /**
  * The bin count threshold for using a tree rather than list for a
  * bin.  Bins are converted to trees when adding an element to a
  * bin with at least this many nodes. The value must be greater
  * than 2 and should be at least 8 to mesh with assumptions in
  * tree removal about conversion back to plain bins upon
  * shrinkage.
  * 大致意思就是说hash冲突默认采用单链表存储，当单链表节点个数大于8时，会转化为红黑树存储
  */
 static final int TREEIFY_THRESHOLD = 8;

 /**
  * The bin count threshold for untreeifying a (split) bin during a
  * resize operation. Should be less than TREEIFY_THRESHOLD, and at
  * most 6 to mesh with shrinkage detection under removal.
  * hash冲突默认采用单链表存储，当单链表节点个数大于8时，会转化 
     为红黑树存储。
* 当红黑树中节点少于6时，则转化为单链表存储
  */
 static final int UNTREEIFY_THRESHOLD = 6;

 /**
  * The smallest table capacity for which bins may be treeified.
  * (Otherwise the table is resized if too many nodes in a bin.)
  * Should be at least 4 * TREEIFY_THRESHOLD to avoid conflicts
  * between resizing and treeification thresholds.
  * hash冲突默认采用单链表存储，当单链表节点个数大于8时，会转化为红黑树存储。
  * 但是有一个前提：要求数组长度大于64，否则不会进行转化
  */
 static final int MIN_TREEIFY_CAPACITY = 64;
```

通过以上代码可以看出初始容量（16）、负载因子以及对数组的说明。数组中的每一个元素其实就是Entry\<K,V>\[] table，Map中的key和value就是以Entry的形式存储的。Entry包含四个属性：key、value、hash值和用于单向链表的next。关于Entry\<K,V>的具体定义参看如下源码：

```java
static class Entry<K,V> implements Map.Entry<K,V> {
    final K key;
    V value;
    Entry<K,V> next;
    int hash;
 
    Entry(int h, K k, V v, Entry<K,V> n) {
        value = v;
        next = n;
        key = k;
        hash = h;
    }
 
    public final K getKey() {
        return key;
    }
 
    public final V getValue() {
        return value;
    }
 
    public final V setValue(V newValue) {
        V oldValue = value;
        value = newValue;
        return oldValue;
    }
 
    public final boolean equals(Object o) {
        if (!(o instanceof Map.Entry))
            return false;
        Map.Entry e = (Map.Entry)o;
        Object k1 = getKey();
        Object k2 = e.getKey();
        if (k1 == k2 || (k1 != null && k1.equals(k2))) {
            Object v1 = getValue();
            Object v2 = e.getValue();
            if (v1 == v2 || (v1 != null && v1.equals(v2)))
                return true;
        }
        return false;
    }
 
    public final int hashCode() {
        return Objects.hashCode(getKey()) ^ Objects.hashCode(getValue());
    }
 
    public final String toString() {
        return getKey() + "=" + getValue();
    }
 
    /**
     * This method is invoked whenever the value in an entry is
     * overwritten by an invocation of put(k,v) for a key k that's already
     * in the HashMap.
     */
    void recordAccess(HashMap<K,V> m) {
    }
 
    /**
     * This method is invoked whenever the entry is
     * removed from the table.
     */
    void recordRemoval(HashMap<K,V> m) {
    }
}
```

##### 负载因子

HashMap的初始值要考虑加载因子:

*   哈希冲突：若干Key的哈希值按数组大小取模后，如果落在同一个数组下标上，将组成一条Entry链，对Key的查找需要遍历Entry链上的每个元素执行equals()比较。
*   加载因子：为了降低哈希冲突的概率，默认当HashMap中的键值对达到数组大小的75%时，即会触发扩容。因此，如果预估容量是100，即需要设定100/0.75＝134的数组大小。
*   空间换时间：如果希望加快Key查找的时间，还可以进一步降低加载因子，加大初始大小，以降低哈希冲突的概率。

HashMap和Hashtable都是用hash算法来决定其元素的存储，因此HashMap和Hashtable的hash表包含如下属性：

*   容量（capacity）：hash表中桶的数量
*   初始化容量（initial capacity）：创建hash表时桶的数量，HashMap允许在构造器中指定初始化容量
*   尺寸（size）：当前hash表中记录的数量
*   负载因子（load factor）：负载因子等于“size/capacity”。负载因子为0，表示空的hash表，0.5表示半满的散列表，依此类推。轻负载的散列表具有冲突少、适宜插入与查询的特点（但是使用Iterator迭代元素时比较慢）

除此之外，hash表里还有一个“负载极限”，“负载极限”是一个0～1的数值，“负载极限”决定了hash表的最大填满程度。当hash表中的负载因子达到指定的“负载极限”时，hash表会自动成倍地增加容量（桶的数量），并将原有的对象重新分配，放入新的桶内，这称为rehashing。

HashMap和Hashtable的构造器允许指定一个负载极限，HashMap和Hashtable默认的“负载极限”为0.75，这表明当该hash表的3/4已经被填满时，hash表会发生rehashing。

“负载极限”的默认值（0.75）是时间和空间成本上的一种折中：

*   `较高`的“负载极限”可以降低hash表所占用的内存空间，但会增加查询数据的时间开销，而查询是最频繁的操作（HashMap的get()与put()方法都要用到查询）
*   `较低`的“负载极限”会提高查询数据的性能，但会增加hash表所占用的内存开销

程序猿可以根据实际情况来调整“负载极限”值。

##### put 流程

当向 HashMap 中 `put`一对键值时，它会根据 key的 hashCode 值计算出一个位置， 该位置就是此对象准备往数组中存放的位置。 该计算过程参看如下代码：

```java
transient int hashSeed = 0;
final int hash(Object k) {
     int h = hashSeed;
     if (0 != h && k instanceof String) {
         return sun.misc.Hashing.stringHash32((String) k);
     }
 
     h ^= k.hashCode();
 
     // This function ensures that hashCodes that differ only by
     // constant multiples at each bit position have a bounded
     // number of collisions (approximately 8 at default load factor).
     h ^= (h >>> 20) ^ (h >>> 12);
     return h ^ (h >>> 7) ^ (h >>> 4);
 }
 
 /**
  * Returns index for hash code h.
  */
 static int indexFor(int h, int length) {
     // assert Integer.bitCount(length) == 1 : "length must be a non-zero power of 2";
     return h & (length-1);
 }
```

通过hash计算出来的值将会使用**indexFor**方法找到它应该所在的table下标。当两个key通过hashCode计算相同时，则发生了hash冲突(碰撞)，HashMap解决hash冲突的方式是用链表(**拉链法**)。当发生hash冲突时，则将存放在数组中的Entry设置为新值的next（这里要注意的是，比如A和B都hash后都映射到下标i中，之前已经有A了，当map.put(B)时，将B放到下标i中，A则为B的next，所以新值存放在数组中，旧值在新值的链表上）。`即将新值作为此链表的头节点`，为什么要这样操作？据说后插入的Entry被查找的可能性更大（因为get查询的时候会遍历整个链表），此处有待考究，如果有哪位大神知道，请留言告知。有一种说法就是链表查找复杂度高，可插入和删除性能高，如果将新值插在末尾，就需要先经过一轮遍历，这个时间复杂度高，开销大，如果是插在头结点，省去了遍历的开销，还发挥了链表插入性能高的优势。

**如果该位置没有对象存在，就将此对象直接放进数组当中；如果该位置已经有对象存在了，则顺着此存在的对象的链开始寻找(为了判断是否值相同，map不允许\<key,value>键值对重复)， 如果此链上有对象的话，再去使用 equals方法进行比较，如果对此链上的每个对象的 equals 方法比较都为 false，则将该对象放到数组当中，然后将数组中该位置以前存在的那个对象链接到此对象的后面。**

`添加节点到链表中`：找到数组下标后，会先进行key判重，如果没有重复，就准备将新值放入到链表的表头。

```java
void addEntry(int hash, K key, V value, int bucketIndex) {
    // 如果当前 HashMap 大小已经达到了阈值，并且新值要插入的数组位置已经有元素了，那么要扩容
    if ((size >= threshold) && (null != table[bucketIndex])) {
        // 扩容
        resize(2 * table.length);
        // 扩容以后，重新计算 hash 值
        hash = (null != key) ? hash(key) : 0;
        // 重新计算扩容后的新的下标
        bucketIndex = indexFor(hash, table.length);
    }
    // 往下看
    createEntry(hash, key, value, bucketIndex);
}
// 这个很简单，其实就是将新值放到链表的表头，然后 size++
void createEntry(int hash, K key, V value, int bucketIndex) {
    Entry<K,V> e = table[bucketIndex];
    table[bucketIndex] = new Entry<>(hash, key, value, e);
    size++;
}
```

这个方法的主要逻辑就是先判断是否需要扩容，需要带的话先扩容，然后再将这个新的数据插入到扩容后的数组的相应位置处的链表的表头。

##### 扩容

扩容就是用一个新的大数组替换原来的小数组，并将原来数组中的值迁移到新的数组中。由于是双倍扩容，迁移过程中，会将原来table\[i]中的链表的所有节点，分拆到新的数组的newTable\[i]和newTable\[i+oldLength]位置上。如原来数组长度是16，那么扩容后，原来table\[0]处的链表中的所有元素会被分配到新数组中newTable\[0]和newTable\[16]这两个位置。扩容期间，由于会新建一个新的空数组，并且用旧的项填充到这个新的数组中去。所以，在这个填充的过程中，如果有线程获取值，很可能会取到 null 值，而不是我们所希望的、原来添加的值。

哈希数组（默认数组大小是16，每对key-value键值对其实是存在map的内部类entry里的），数组的每个元素都是一个单链表的头节点，跟着的蓝色链表是用来解决冲突的，如果不同的key映射到了数组的同一位置处，就将其放入单链表中。

前面说过HashMap的key是允许为null的，当出现这种情况时，会放到table\[0]中。

```java
private V putForNullKey(V value) {
    for (Entry<K,V> e = table[0]; e != null; e = e.next) {
        if (e.key == null) {
            V oldValue = e.value;
            e.value = value;
            e.recordAccess(this);
            return oldValue;
        }
    }
    modCount++;
    addEntry(0, null, value, 0);
    return null;
}
```

当size>=threshold（ threshold等于“容量\*负载因子”）时，会发生`扩容`。

```java
void addEntry(int hash, K key, V value, int bucketIndex) {
    if ((size >= threshold) && (null != table[bucketIndex])) {
        resize(2 * table.length);
        hash = (null != key) ? hash(key) : 0;
        bucketIndex = indexFor(hash, table.length);
    }
 
    createEntry(hash, key, value, bucketIndex);
}
```

`特别提示：jdk1.7中resize，只有当 size>=threshold并且 table中的那个槽中已经有Entry时，才会发生resize`。即有可能虽然size>=threshold，但是必须等到相应的槽至少有一个Entry时，才会扩容,可以通过上面的代码看到每次resize都会扩大一倍容量（2 \* table.length）。

#### jdk1.8中HashMap的实现

在jdk1.8中HashMap的内部结构可以看作是数组(Node\<K,V>\[] table)和链表的复合结构，数组被分为一个个桶（bucket），通过哈希值决定了键值对在这个数组中的寻址（哈希值相同的键值对，则以链表形式存储。有一点需要注意，如果链表大小超过阈值（TREEIFY\_THRESHOLD,8），图中的链表就会被改造为树形（红黑树）结构。

```java
transient Node<K,V>[] table;
```

Entry的名字变成了Node，原因是和红黑树的实现TreeNode相关联。**1.8与1.7最大的不同就是利用了红黑树，即由数组+链表（或红黑树）组成。**

在分析jdk1.7中HashMap的hash冲突时，不知大家是否有个疑问就是万一发生碰撞的节点非常多怎么办？如果说成百上千个节点在hash时发生碰撞，存储一个链表中，那么如果要查找其中一个节点，那就不可避免的花费O(N)的查找时间，这将是多么大的性能损失。这个问题终于在JDK1.8中得到了解决，在最坏的情况下，链表查找的时间复杂度为`O(n)`,而红黑树一直是`O(logn)`,这样会提高HashMap的效率。

jdk1.7中HashMap采用的是位桶+链表的方式，即我们常说的**散列链表**的方式，而jdk1.8中采用的是位桶+链表/红黑树的方式，也是非线程安全的。当某个位桶的链表的长度达到某个阀值的时候，这个链表就将转换成红黑树。

jdk1.8中，当同一个hash值的节点数不小于8时，将不再以单链表的形式存储了，会被调整成一颗红黑树（上图中null节点没画）。这就是jdk1.7与jdk1.8中HashMap实现的最大区别。

HashMap根据链地址法（`拉链法`）来解决冲突，**在jdk1.8中，如果`链表长度大于8且节点数组长度大于64的时候`，就把链表下所有的节点转为红黑树**。

##### put 流程

通过分析put方法的源码，可以让这种区别更直观：

```java
static final int TREEIFY_THRESHOLD = 8;
 
public V put(K key, V value) {
        return putVal(hash(key), key, value, false, true);
 }
  
  
final V putVal(int hash, K key, V value, boolean onlyIfAbsent,
                   boolean evict) {
        Node<K,V>[] tab;
    Node<K,V> p;
    int n, i;
    //如果当前map中无数据，执行resize方法。并且返回n
        if ((tab = table) == null || (n = tab.length) == 0)
            n = (tab = resize()).length;
     //如果要插入的键值对要存放的这个位置刚好没有元素，那么把他封装成Node对象，放在这个位置上即可
        if ((p = tab[i = (n - 1) & hash]) == null)
            tab[i] = newNode(hash, key, value, null);
    //否则的话，说明这上面有元素
        else {
            Node<K,V> e; K k;
        //如果这个元素的key与要插入的一样，那么就替换一下。
            if (p.hash == hash &&
                ((k = p.key) == key || (key != null && key.equals(k))))
                e = p;
        //1.如果当前节点是TreeNode类型的数据，执行putTreeVal方法
            else if (p instanceof TreeNode)
                e = ((TreeNode<K,V>)p).putTreeVal(this, tab, hash, key, value);
            else {
        //还是遍历这条链子上的数据，跟jdk7没什么区别
                for (int binCount = 0; ; ++binCount) {
                    if ((e = p.next) == null) {
                        p.next = newNode(hash, key, value, null);
            //2.完成了操作后多做了一件事情，判断，并且可能执行treeifyBin方法
                        if (binCount >= TREEIFY_THRESHOLD - 1) // -1 for 1st
                            treeifyBin(tab, hash);
                        break;
                    }
                    if (e.hash == hash &&
                        ((k = e.key) == key || (key != null && key.equals(k))))
                        break;
                    p = e;
                }
            }
            if (e != null) { // existing mapping for key
                V oldValue = e.value;
                if (!onlyIfAbsent || oldValue == null) //true || --
                    e.value = value;
           //3.
                afterNodeAccess(e);
                return oldValue;
            }
        }
        ++modCount;
    //判断阈值，决定是否扩容
        if (++size > threshold)
            resize();
        //4.
        afterNodeInsertion(evict);
        return null;
    }
```

以上代码中的特别之处如下：

```java
if (binCount >= TREEIFY_THRESHOLD - 1) // -1 for 1st
       treeifyBin(tab, hash);
```

`treeifyBin()`就是将链表转换成红黑树。

##### 树化操作

树化操作的过程有点复杂，可以结合源码来看看。将原本的单链表转化为双向链表，再遍历这个双向链表转化为红黑树。

```java
final void treeifyBin(Node<K,V>[] tab, int hash) {
     int n, index; Node<K,V> e;
     //树形化还有一个要求就是数组长度必须大于等于64，否则继续采用扩容策略
     if (tab == null || (n = tab.length) < MIN_TREEIFY_CAPACITY)
         resize();
     else if ((e = tab[index = (n - 1) & hash]) != null) {
         TreeNode<K,V> hd = null, tl = null;//hd指向首节点，tl指向尾节点
         do {
             TreeNode<K,V> p = replacementTreeNode(e, null);//将链表节点转化为红黑树节点
            if (tl == null) // 如果尾节点为空，说明还没有首节点
                hd = p;  // 当前节点作为首节点
            else { // 尾节点不为空，构造一个双向链表结构，将当前节点追加到双向链表的末尾
                p.prev = tl; // 当前树节点的前一个节点指向尾节点
                tl.next = p; // 尾节点的后一个节点指向当前节点
            }
            tl = p; // 把当前节点设为尾节点
        } while ((e = e.next) != null); // 继续遍历单链表
        //将原本的单链表转化为一个节点类型为TreeNode的双向链表
        if ((tab[index] = hd) != null) // 把转换后的双向链表，替换数组原来位置上的单向链表
            hd.treeify(tab); // 将当前双向链表树形化
    }
}
```

> 大家要特别注意一点，树化有个要求就是数组长度必须大于等于MIN\_TREEIFY\_CAPACITY（64），否则继续采用扩容策略。

总的来说，HashMap默认采用数组+单链表方式存储元素，当元素出现哈希冲突时，会存储到该位置的单链表中。但是单链表不会一直增加元素，当元素个数超过8个时，会尝试将单链表转化为红黑树存储。但是在转化前，会再判断一次当前数组的长度，只有数组长度大于`64`才处理。否则，进行扩容操作。

将双向链表转化为红黑树的实现：

```java
 final void treeify(Node<K,V>[] tab) {
     TreeNode<K,V> root = null;  // 定义红黑树的根节点
     for (TreeNode<K,V> x = this, next; x != null; x = next) { // 从TreeNode双向链表的头节点开始逐个遍历
         next = (TreeNode<K,V>)x.next; // 头节点的后继节点
         x.left = x.right = null;
         if (root == null) {
             x.parent = null;
             x.red = false;
             root = x; // 头节点作为红黑树的根，设置为黑色
        }
        else { // 红黑树存在根节点
            K k = x.key; 
            int h = x.hash;
            Class<?> kc = null;
            for (TreeNode<K,V> p = root;;) { // 从根开始遍历整个红黑树
                int dir, ph;
                K pk = p.key;
                if ((ph = p.hash) > h) // 当前红黑树节点p的hash值大于双向链表节点x的哈希值
                    dir = -1;
                else if (ph < h) // 当前红黑树节点的hash值小于双向链表节点x的哈希值
                    dir = 1;
                else if ((kc == null &&
                          (kc = comparableClassFor(k)) == null) ||
                         (dir = compareComparables(kc, k, pk)) == 0) // 当前红黑树节点的hash值等于双向链表节点x的哈希值，则如果key值采用比较器一致则比较key值
                    dir = tieBreakOrder(k, pk); //如果key值也一致则比较className和identityHashCode

                TreeNode<K,V> xp = p; 
                if ((p = (dir <= 0) ? p.left : p.right) == null) { // 如果当前红黑树节点p是叶子节点，那么双向链表节点x就找到了插入的位置
                    x.parent = xp;
                    if (dir <= 0) //根据dir的值，插入到p的左孩子或者右孩子
                        xp.left = x;
                    else
                        xp.right = x;
                    root = balanceInsertion(root, x); //红黑树中插入元素，需要进行平衡调整(过程和TreeMap调整逻辑一模一样)
                    break;
                }
            }
        }
    }
    //将TreeNode双向链表转化为红黑树结构之后，由于红黑树是基于根节点进行查找，所以必须将红黑树的根节点作为数组当前位置的元素
    moveRootToFront(tab, root);
}
```

然后将红黑树的根节点移动端数组的索引所在位置上：

```java
static <K,V> void moveRootToFront(Node<K,V>[] tab, TreeNode<K,V> root) {
     int n;
     if (root != null && tab != null && (n = tab.length) > 0) {
         int index = (n - 1) & root.hash; //找到红黑树根节点在数组中的位置
         TreeNode<K,V> first = (TreeNode<K,V>)tab[index]; //获取当前数组中该位置的元素
         if (root != first) { //红黑树根节点不是数组当前位置的元素
             Node<K,V> rn;
             tab[index] = root;
             TreeNode<K,V> rp = root.prev;
            if ((rn = root.next) != null) //将红黑树根节点前后节点相连
                ((TreeNode<K,V>)rn).prev = rp;
            if (rp != null)
                rp.next = rn;
            if (first != null) //将数组当前位置的元素，作为红黑树根节点的后继节点
                first.prev = root;
            root.next = first;
            root.prev = null;
        }
        assert checkInvariants(root);
    }
}
```

`putVal`方法处理的逻辑比较多，包括初始化、扩容、树化，近乎在这个方法中都能体现，针对源码简单讲解下几个关键点：

*   如果Node\<K,V>\[] table是null，resize方法会负责初始化，即如下代码：

```java
if ((tab = table) == null || (n = tab.length) == 0)
    n = (tab = resize()).length;
```

*   resize方法兼顾两个职责，创建初始存储表格，或者在容量不满足需求的时候，进行扩容（resize）。在放置新的键值对的过程中，如果发生下面条件，就会发生扩容。

```java
if (++size > threshold)
    resize();
```

*   具体键值对在哈希表中的位置（数组index）取决于下面的位运算：

```java
i = (n - 1) & hash
```

仔细观察哈希值的源头，会发现它并不是key本身的hashCode，而是来自于HashMap内部的另一个hash方法。**为什么这里需要将高位数据移位到低位进行异或运算呢**？这是因为有些数据计算出的哈希值差异主要在高位，而HashMap里的哈希寻址是忽略容量以上的高位的，那么这种处理就可以有效避免类似情况下的哈希碰撞。

在jdk1.8中取消了indefFor()方法，直接用(tab.length-1)\&hash，所以看到这个，代表的就是数组的下角标。

```java
static final int hash(Object key) {
    int h;
    return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
}
```

为什么HashMap为什么要树化？

之前在极客时间的专栏里看到过一个解释。本质上这是个安全问题。因为在元素放置过程中，如果一个对象哈希冲突，都被放置到同一个桶里，则会形成一个链表，我们知道链表查询是线性的，会严重影响存取的性能。而在现实世界，构造哈希冲突的数据并不是非常复杂的事情，恶意代码就可以利用这些数据大量与服务器端交互，导致服务器端CPU大量占用，这就构成了哈希碰撞拒绝服务攻击，国内一线互联网公司就发生过类似攻击事件。

> 用哈希碰撞发起拒绝服务攻击(DOS，Denial-Of-Service attack),常见的场景是攻击者可以事先构造大量相同哈希值的数据，然后以JSON数据的形式发送给服务器，服务器端在将其构建成为Java对象过程中，通常以Hashtable或HashMap等形式存储，哈希碰撞将导致哈希表发生严重退化，算法复杂度可能上升一个数据级，进而耗费大量CPU资源。

##### 为什么要将链表中转红黑树的阈值设为 8

我们可以这么来看，`当链表长度大于或等于阈值（默认为 8）的时候，如果同时还满足容量大于或等于 MIN_TREEIFY_CAPACITY（默认为 64）的要求，就会把链表转换为红黑树`。同样，后续如果由于删除或者其他原因调整了大小，当红黑树的节点小于或等于 6 个以后，又会恢复为链表形态。

每次遍历一个链表，平均查找的时间复杂度是 O(n)，n 是链表的长度。红黑树有和链表不一样的查找性能，由于红黑树有自平衡的特点，可以防止不平衡情况的发生，所以可以始终将查找的时间复杂度控制在 O(log(n))。最初链表还不是很长，所以可能 O(n) 和 O(log(n)) 的区别不大，但是如果链表越来越长，那么这种区别便会有所体现。所以为了提升查找性能，需要把链表转化为红黑树的形式。

还要注意很重要的一点，单个 TreeNode 需要占用的空间大约是普通 Node 的两倍，所以只有当包含足够多的 Nodes 时才会转成 TreeNodes，而是否足够多就是由 TREEIFY\_THRESHOLD 的值决定的。而当桶中节点数由于移除或者 resize 变少后，又会变回普通的链表的形式，以便节省空间。

默认是链表长度达到 8 就转成红黑树，而当长度降到 6 就转换回去，这体现了`时间和空间平衡的思想`，最开始使用链表的时候，空间占用是比较少的，而且由于链表短，所以查询时间也没有太大的问题。可是当链表越来越长，需要用红黑树的形式来保证查询的效率。

在理想情况下，链表长度符合`泊松分布`，各个长度的命中概率依次递减，当长度为 8 的时候，是最理想的值。

事实上，链表长度超过 8 就转为红黑树的设计，更多的是为了防止用户自己实现了不好的哈希算法时导致链表过长，从而导致查询效率低，而此时转为红黑树更多的是一种保底策略，用来保证极端情况下查询的效率。

通常如果 hash 算法正常的话，那么链表的长度也不会很长，那么红黑树也不会带来明显的查询时间上的优势，反而会增加空间负担。所以通常情况下，并没有必要转为红黑树，所以就选择了概率非常小，小于千万分之一概率，也就是长度为 8 的概率，把长度 8 作为转化的默认阈值。

如果开发中发现 HashMap 内部出现了红黑树的结构，那可能是我们的哈希算法出了问题，所以需要选用合适的hashCode方法，以便减少冲突。

### ConcurrentHashMap

`ConcurrentHashMap` 是 Java 中的一个线程安全的哈希表实现，它属于 `java.util.concurrent` 包。它在多线程环境下提供了比 `HashMap` 更好的性能和并发控制。`ConcurrentHashMap` 的设计目标是提供一个线程安全的哈希表，同时尽量减少锁的使用，以提高并发性能。

以下是 `ConcurrentHashMap` 的一些关键特性：

1.  **线程安全**：底层采用分段的数组+链表实现，`ConcurrentHashMap` 通过使用分段锁（Segmented Locking）来实现线程安全。在早期版本中，它使用了多个锁来保护不同的哈希桶（bucket），这样可以允许多个线程同时访问不同的桶，从而提高并发性能。在 Java 8 及以后的版本中，`ConcurrentHashMap` 采用了更细粒度的锁机制，即使用了 `volatile` 关键字和 CAS（Compare-And-Swap）操作来减少锁的使用，进一步提高了性能。

2.  **分段锁**：在 Java 8 之前，`ConcurrentHashMap` 使用了分段锁技术，将哈希表分成多个段（segment），每个段都有自己的锁。这样，当多个线程需要访问不同的段时，它们可以同时进行，而不会相互阻塞。这种设计允许在多线程环境下进行读写操作，而不会影响到其他线程的操作。但是效率提升N倍，默认提升16倍。(读操作不加锁，由于HashEntry的value变量是 volatile的，也能保证读取到最新的值。)，有些方法需要跨段，比如size()和containsValue()，它们可能需要锁定整个表而而不仅仅是某个段，这需要按顺序锁定所有段，操作完毕后，又按顺序释放所有段的锁

3.  **无锁操作**：在 Java 8 及以后的版本中，`ConcurrentHashMap` 通过使用 `volatile` 关键字和 CAS 操作来实现无锁的读写操作。这使得在没有竞争的情况下，读写操作可以不加锁地进行，从而提高了性能。

4.  **延迟初始化**：`ConcurrentHashMap` 的桶数组（bucket array）是延迟初始化的，这意味着只有在第一次插入元素时，才会创建桶数组。这种设计可以减少不必要的内存分配，尤其是在哈希表初始化后没有立即使用的情况下。

5.  **扩容机制**：`ConcurrentHashMap` 的扩容机制与 `HashMap` 类似，但它是分段进行的。在扩容时，每个段可以独立地进行扩容操作，这样可以减少扩容对性能的影响。段内扩容（段内元素超过该段对应Entry数组长度的75%触发扩容，不会对整个Map进行扩容），插入前检测需不需要扩容，有效避免无效扩容

6.  **迭代器**：`ConcurrentHashMap` 提供了弱一致性的迭代器（Weakly Consistent Iterator）。这意味着迭代器可能不会反映最新的更新，但不会抛出 `ConcurrentModificationException` 异常。这种迭代器适用于不需要实时反映最新状态的场景。

`ConcurrentHashMap` 是一个非常强大的并发数据结构，适用于需要在多线程环境下进行高效读写操作的场景。它在 Java 8 中的实现进行了优化，进一步提高了性能和并发能力。

#### Java 8 中的实现进行了哪些优化

Java 8 对 `ConcurrentHashMap` 的实现进行了显著的优化，这些优化主要集中在提高并发性能和减少内存占用上。以下是 Java 8 中 `ConcurrentHashMap` 实现的一些关键优化：

1.  **无锁化**：Java 8 中的 `ConcurrentHashMap` 引入了无锁（lock-free）和无阻塞（wait-free）的编程技术，特别是在读取操作中。通过使用 `volatile` 关键字和 CAS（Compare-And-Swap）操作，`ConcurrentHashMap` 能够在没有锁的情况下进行读取操作，从而减少了锁的开销和提高了并发性能。

2.  **分段锁的取消**：在 Java 8 之前，`ConcurrentHashMap` 使用了分段锁（segment）来减少锁的粒度，从而提高并发性能。然而，这种设计在某些情况下仍然会导致锁竞争。Java 8 中，`ConcurrentHashMap` 取消了分段锁的概念，转而使用了更细粒度的锁机制，即每个数组元素（桶）都可能有一个锁。这种设计使得在没有竞争的情况下，读写操作可以不加锁地进行，进一步提高了性能。

3.  **数组的延迟初始化**：Java 8 中的 `ConcurrentHashMap` 实现了延迟初始化数组，这意味着只有在第一次插入元素时，才会创建数组。这种设计减少了不必要的内存分配，特别是在哈希表初始化后没有立即使用的情况下。

4.  **扩容机制的优化**：Java 8 中的 `ConcurrentHashMap` 在扩容时采用了更高效的策略。扩容操作现在是分段进行的，每个桶可以独立地进行扩容，这减少了扩容对性能的影响。

5.  **更高效的哈希算法**：Java 8 中的 `ConcurrentHashMap` 使用了更高效的哈希算法，这有助于减少哈希冲突，从而提高性能。

6.  **更简洁的代码**：由于去除了分段锁的概念，Java 8 中的 `ConcurrentHashMap` 代码更加简洁，易于理解和维护。

7.  **更好的迭代器**：Java 8 中的 `ConcurrentHashMap` 提供了更强的迭代器，这些迭代器能够反映最新的更新，同时仍然保持了弱一致性，即在迭代过程中，如果哈希表被修改，迭代器不会抛出 `ConcurrentModificationException` 异常。

这些优化使得 Java 8 中的 `ConcurrentHashMap` 在多线程环境下提供了更好的性能和更灵活的并发控制。

#### ConcurrentHashMap的分段锁是如何实现的

在Java 8中，`ConcurrentHashMap` 的实现已经不再使用分段锁（segment）的概念，而是采用了更细粒度的锁机制。在Java 8之前，`ConcurrentHashMap` 通过分段锁来实现线程安全，每个段（segment）都是一个独立的锁，可以独立地进行读写操作。但在Java 8中，`ConcurrentHashMap` 采用了`Node`数组和`CAS`操作来实现线程安全，同时引入了`TreeNode`和`TreeBin`来处理红黑树结构，以优化性能。

下面，我将结合Java 8中`ConcurrentHashMap`的部分源码来解释其线程安全的实现方式。请注意，由于`ConcurrentHashMap`的实现较为复杂，这里仅提供一个高层次的概述。

```java
// Node是ConcurrentHashMap中的内部类，用于存储键值对
static class Node<K,V> implements Map.Entry<K,V> {
    final int hash;
    final K key;
    volatile V val;
    volatile Node<K,V> next;
    // ... 其他成员和方法 ...
}

// ConcurrentHashMap的主类
public class ConcurrentHashMap<K,V> extends AbstractMap<K,V>
    implements ConcurrentMap<K,V>, Serializable {
    // ... 其他成员和方法 ...

    // Node数组，用于存储键值对
    transient volatile Node<K,V>[] table;

    // 初始化或扩容时的辅助变量
    private transient volatile Node<K,V>[] nextTable;

    // ... 其他成员和方法 ...
}
```

在Java 8中，`ConcurrentHashMap` 使用了`Node`数组来存储键值对。每个`Node`对象代表一个键值对，并且可能指向链表中的下一个节点。当发生哈希冲突时，这些节点会形成链表。如果链表长度超过阈值（默认为8），链表会转换为红黑树以优化性能。

在`ConcurrentHashMap`中，对数组的访问和修改是通过`volatile`关键字来保证内存可见性的，这样可以避免在多线程环境下出现数据不一致的问题。同时，`ConcurrentHashMap`使用了`CAS`操作来实现无锁的并发更新。例如，在`put`方法中，如果发现某个位置的节点为空，会尝试使用`CAS`操作来设置新节点，如果成功则表示更新成功，否则会进行重试。

```java
final V putVal(K key, V value, boolean onlyIfAbsent) {
    // ... 省略部分代码 ...
    for (Node<K,V>[] tab = table;;) {
        Node<K,V> f; int n, i, fh;
        // ... 省略部分代码 ...
        else if ((f = tabAt(tab, i = (n - 1) & hash)) == null) {
            // 如果该位置为空，使用CAS操作设置新节点
            if (casTabAt(tab, i, null,
                         new Node<K,V>(hash, key, value, null)))
                break;                   // no lock when adding to empty bin
        }
        // ... 省略部分代码 ...
    }
    // ... 省略部分代码 ...
}
```

在上述代码中，`tabAt`方法用于获取数组中指定位置的节点，`casTabAt`方法用于使用`CAS`操作设置新节点。如果`CAS`操作成功，则表示成功添加了新节点，否则会进行重试。

`ConcurrentHashMap`的这种设计使得它在多线程环境下能够提供良好的性能和线程安全。它避免了分段锁带来的复杂性和性能开销，同时通过`volatile`和`CAS`操作保证了数据的一致性和线程安全。

### 分析Hashtable、HashMap、TreeMap的区别

*   `HashMap`是继承自`AbstractMap`类，而`HashTable`是继承自`Dictionary`类。不过它们都同时实现了map、Cloneable（可复制）、Serializable（可序列化）这三个接口。存储的内容是基于key-value的键值对映射，不能有重复的key，而且一个key只能映射一个value。HashSet底层就是基于HashMap实现的。
*   Hashtable的key、value都不能为null；HashMap的key、value可以为null，不过只能有一个key为null，但可以有多个null的value；TreeMap键、值都不能为null。
*   Hashtable、HashMap具有**无序**特性。TreeMap是利用`红黑树`实现的（树中的每个节点的值都会大于或等于它的左子树中的所有节点的值，并且小于或等于它的右子树中的所有节点的值），实现了SortMap接口，能够对保存的记录根据键进行排序。所以一般需求排序的情况下首选TreeMap，`默认按键的升序排序`（深度优先搜索），也可以自定义实现Comparator接口实现排序方式。

一般情况下我们选用HashMap，因为HashMap的键值对在取出时是随机的，其依据键的hashCode和键的equals方法存取数据，具有很快的访问速度，所以在Map中插入、删除及索引元素时其是效率最高的实现。而TreeMap的键值对在取出时是排过序的，所以效率会低点。

`TreeMap`是基于红黑树的一种提供顺序访问的Map，与HashMap不同的是它的get、put、remove之类操作都是o(log(n))的时间复杂度，具体顺序可以由指定的Comparator来决定，或者根据键的自然顺序来判断。

**对HashMap做下总结**：
HashMap基于哈希散列表实现 ，可以实现对数据的读写。**将键值对传递给put方法时，它调用键对象的hashCode()方法来计算hashCode，然后找到相应的bucket位置（即数组）来储存值对象。当获取对象时，通过键对象的equals()方法找到正确的键值对，然后返回值对象**。HashMap使用链表来解决hash冲突问题，当发生冲突了，对象将会储存在链表的头节点中。HashMap在每个链表节点中储存键值对对象，当两个不同的键对象的hashCode相同时，它们会储存在同一个bucket位置的链表中，如果链表大小超过阈值（TREEIFY\_THRESHOLD,8），链表就会被改造为树形结构。

**有个问题要特别声明下**：

*   HashMap在jdk1.7中采用**表头插入法**，在扩容时会**改变**链表中元素原本的顺序，以至于在并发场景下导致链表成环的问题。
*   在jdk1.8中采用的是**尾部插入法**，在扩容时会保持链表元素原本的顺序，就不会出现链表成环的问题了。

**我们可以简单列下HashMap在1.7和1.8之间的变化：**

*   1.7中采用数组+链表，1.8采用的是数组+链表/红黑树，即在1.7中链表长度超过一定长度后就改成红黑树存储。
*   1.7扩容时需要重新计算哈希值和索引位置，1.8并不重新计算哈希值，巧妙地采用和扩容后容量进行&操作来计算新的索引位置。
*   1.7是采用表头插入法插入链表，1.8采用的是尾部插入法。
*   在1.7中采用表头插入法，在扩容时会改变链表中元素原本的顺序，以至于在并发场景下导致链表成环的问题；在1.8中采用尾部插入法，在扩容时会保持链表元素原本的顺序，就不会出现链表成环的问题了。

### HashMap和HashTable和ConcurrentHashMap的区别

`HashMap`、`HashTable` 和 `ConcurrentHashMap` 都是 Java 中用于存储键值对的集合类，它们都实现了 `Map` 接口。但它们在实现细节、线程安全性和性能方面存在显著差异。下面是它们之间的一些主要区别：

1.  **线程安全**：
    *   `HashMap` 是非线程安全的，不保证在多线程环境下的操作是安全的。
    *   `HashTable` 是线程安全的，其所有方法都通过同步机制（synchronized）来保证线程安全。这意味着在多线程环境下，每次只有一个线程可以访问 `HashTable`，这会降低并发性能。
    *   `ConcurrentHashMap` 是线程安全的，但它的实现方式比 `HashTable` 更为精细。它使用了分段锁（Segmented Locking）技术，允许多个读操作同时进行，以及对不同段的写操作同时进行，从而提高了并发性能。

2.  **性能**：
    *   `HashMap` 在单线程环境下性能最好，因为它没有同步开销。
    *   `HashTable` 由于同步机制，性能较差，尤其是在多线程环境下。
    *   `ConcurrentHashMap` 在多线程环境下性能最好，因为它使用了分段锁，减少了锁的粒度，提高了并发性能。

3.  **null 值**：
    *   `HashMap` 允许键和值为 `null`。
    *   `HashTable` 不允许键或值为 `null`，尝试插入 `null` 值会抛出 `NullPointerException`。
    *   `ConcurrentHashMap` 也允许键和值为 `null`，但不建议使用 `null` 值，因为这可能会导致混淆。

4.  **迭代器**：
    *   `HashMap` 的迭代器是快速失败的（fail-fast），如果在迭代过程中集合被修改，迭代器会抛出 `ConcurrentModificationException`。
    *   `HashTable` 的迭代器不是快速失败的，但它的 `entrySet().iterator()` 返回的迭代器是快速失败的。
    *   `ConcurrentHashMap` 的迭代器也是快速失败的。

5.  **初始容量和负载因子**：
    *   `HashMap`、`HashTable` 和 `ConcurrentHashMap` 都允许在构造时指定初始容量和负载因子，但它们的默认值可能不同。例如，`HashMap` 的默认初始容量是 16，负载因子是 0.75，而 `ConcurrentHashMap` 的默认初始容量是 16，负载因子是 0.75，但 `HashTable` 的默认初始容量是 11，负载因子也是 0.75。

6.  **计算index的方法**：
    *   `HashTable`:index = (hash & 0x7FFFFFFF) % tab.length
    *   `HashMap`:index = hash & (tab.length – 1)

### 为什么 ConcurrentHashMap 和 HashMap 的初始容量为 16 但 HashTable 的默认初始容量却是 11

`HashMap` 和 `ConcurrentHashMap` 的默认初始容量为 16，而 `HashTable` 的默认初始容量为 11，这主要是因为它们在设计时采用了不同的哈希策略和冲突解决机制。

1.  **HashMap 和 ConcurrentHashMap**:
    *   **容量为2的幂次**：`HashMap` 和 `ConcurrentHashMap` 的默认容量设置为 16，且总是2的幂次，这是为了优化哈希表的性能。当容量为2的幂次时，可以利用位运算来计算哈希值对应的数组索引，这样可以提高效率。例如，通过 `(n - 1) & hash` 来计算索引，其中 `n` 是数组的长度，`hash` 是元素的哈希值。当 `n` 是2的幂次时，`(n - 1)` 是一个全1的二进制数，这样可以确保哈希值的低位与 `(n - 1)` 进行位与操作时，能够均匀地分布到数组的不同位置，从而减少哈希冲突。
    *   **负载因子**：`HashMap` 和 `ConcurrentHashMap` 的默认负载因子都是 0.75，这意味着当哈希表中的元素数量达到容量的75%时，会进行扩容操作，以保持哈希表的性能。

2.  **HashTable**:
    *   **容量为质数**：`HashTable` 的默认容量为 11，且总是质数。这是因为质数的特性使得它们在哈希函数中可以提供更好的分布效果，从而减少哈希冲突。在早期的 `HashTable` 实现中，使用质数作为容量可以提高哈希表的性能，尤其是在处理大量数据时。
    *   **负载因子**：`HashTable` 的默认负载因子也是 0.75，与 `HashMap` 和 `ConcurrentHashMap` 相同。

总结来说，`HashMap` 和 `ConcurrentHashMap` 选择2的幂次作为默认容量，主要是为了利用位运算来优化哈希计算和索引计算的效率。而 `HashTable` 选择质数作为默认容量，是为了利用质数在哈希函数中的分布特性来减少冲突。尽管 `HashTable` 的设计在某些方面与 `HashMap` 和 `ConcurrentHashMap` 不同，但它们都是为了实现高效、安全的哈希表数据结构。随着Java版本的更新，`HashTable` 的使用已经不如 `HashMap` 和 `ConcurrentHashMap` 那么广泛，因为后者提供了更好的并发性能和更灵活的配置选项。

## set

### TreeSet

`TreeSet` 是 Java 集合框架中的一个类，它实现了 `Set` 接口，基于红黑树的数据结构来存储元素。`TreeSet` 提供了元素的自动排序功能，这意味着当你向 `TreeSet` 添加元素时，这些元素会根据它们的自然顺序（如果元素实现了 `Comparable` 接口）或者根据提供的 `Comparator`（如果元素没有实现 `Comparable` 接口）进行排序。

`TreeSet` 的特点包括：

1.  **自动排序**：`TreeSet` 会自动根据元素的自然顺序或提供的 `Comparator` 对元素进行排序。这意味着当你遍历 `TreeSet` 时，元素会按照排序后的顺序出现。

2.  **不允许重复元素**：`TreeSet` 是一个不允许重复元素的集合，如果尝试添加一个已经存在于集合中的元素，该操作将不会有任何效果。

3.  **基于红黑树**：`TreeSet` 内部使用红黑树来存储元素。红黑树是一种自平衡的二叉查找树，它保证了最坏情况下的时间复杂度为 O(log n)，这使得 `TreeSet` 在添加、删除和查找元素时都具有较高的效率。

4.  **线程不安全**：`TreeSet` 不是线程安全的，如果需要在多线程环境中使用，需要额外的同步机制。

5.  **无序迭代**：虽然 `TreeSet` 会根据元素的自然顺序或 `Comparator` 对元素进行排序，但迭代器返回的元素顺序是固定的，即按照排序后的顺序。

下面是一个简单的 `TreeSet` 使用示例：

```java
import java.util.TreeSet;
import java.util.Comparator;

public class TreeSetExample {
    public static void main(String[] args) {
        // 使用自然顺序
        TreeSet<Integer> naturalOrderSet = new TreeSet<>();
        naturalOrderSet.add(5);
        naturalOrderSet.add(3);
        naturalOrderSet.add(9);
        System.out.println("Natural order set: " + naturalOrderSet);

        // 使用自定义比较器
        TreeSet<Integer> customComparatorSet = new TreeSet<>(new Comparator<Integer>() {
            @Override
            public int compare(Integer o1, Integer o2) {
                return o2.compareTo(o1); // 降序排序
            }
        });
        customComparatorSet.add(5);
        customComparatorSet.add(3);
        customComparatorSet.add(9);
        System.out.println("Custom comparator set: " + customComparatorSet);
    }
}
```

在上述代码中，我们创建了两个 `TreeSet` 实例，一个使用自然顺序，另一个使用自定义的比较器来实现降序排序。`TreeSet` 的使用非常简单，只需要添加元素即可，它会自动处理排序和去重。

# 数据结构

参考 <a href = "数据结构.md"> 数据结构.md </a>

# java IO

## IO 原理

在传统的I/O操作中，数据传输通常涉及用户空间和内核空间之间的数据复制。为了理解这一过程，我们需要先了解操作系统中用户空间和内核空间的概念。

**用户空间与内核空间**

在现代操作系统中，内存空间被分为两个主要部分：

1. **用户空间（User Space）**：这是应用程序运行的地方。用户空间中的代码不能直接访问硬件资源，也不能执行特权操作。用户空间的程序通过系统调用（System Calls）请求操作系统内核来执行这些操作。

2. **内核空间（Kernel Space）**：这是操作系统内核运行的地方。内核空间拥有对硬件资源的直接访问权限，并负责管理系统的资源，如CPU、内存、磁盘等。内核空间可以执行特权操作，如管理文件系统、网络通信、进程调度等。

**数据复制过程**

在传统的I/O操作中，数据从一个设备（如磁盘、网络接口等）传输到用户空间的过程通常涉及以下步骤：

1. **应用程序发起I/O请求**：应用程序通过系统调用请求操作系统内核读取数据。

2. **数据从设备传输到内核空间**：内核空间负责从设备读取数据。数据首先被读入内核空间的缓冲区。

3. **数据从内核空间复制到用户空间**：内核将数据从其缓冲区复制到应用程序在用户空间分配的缓冲区中。

4. **应用程序处理数据**：应用程序现在可以处理这些数据。

5. **数据写回操作**：如果应用程序需要将数据写回磁盘或发送到网络，这个过程会重复，数据首先从用户空间复制到内核空间的缓冲区，然后由内核负责将数据写入设备。

**为什么需要复制数据？**

数据在用户空间和内核空间之间复制的原因是出于安全和隔离的考虑。操作系统通过这种方式确保用户空间的程序不能直接访问或修改内核空间的数据，从而保护系统的稳定性和安全性。此外，这种隔离也使得操作系统可以更有效地管理资源和执行任务。

**性能影响**

尽管这种数据复制机制提供了必要的安全性和隔离性，但它也带来了性能开销。每次数据从内核空间复制到用户空间，或者从用户空间复制到内核空间，都会消耗CPU资源和时间。在处理大量数据或进行高吞吐量的I/O操作时，这种开销可能会成为性能瓶颈。

为了解决这个问题，现代操作系统和编程语言提供了多种优化技术，例如：

- **零拷贝（Zero-Copy）技术**：通过减少数据在用户空间和内核空间之间的复制次数来提高性能。例如，直接从内核空间的缓冲区将数据发送到网络接口，而不需要先复制到用户空间。

- **内存映射（Memory-Mapped Files）**：允许文件数据直接映射到用户空间的内存地址，应用程序可以直接读写这些内存地址，从而避免了数据在用户空间和内核空间之间的复制。

- **异步I/O（Asynchronous I/O）**：允许应用程序在I/O操作进行时继续执行其他任务，而不是等待I/O操作完成。这样可以提高应用程序的响应性和吞吐量。

通过这些技术，现代系统能够更有效地处理I/O操作，减少不必要的数据复制，从而提高整体性能。

## 内存映射文件

内存映射文件（Memory-Mapped Files）是一种允许文件数据直接映射到用户空间内存的技术。这种技术通过操作系统内核将文件的一部分或全部映射到进程的虚拟地址空间中，使得文件数据看起来像是进程内存的一部分。当应用程序访问这些内存地址时，实际上是在访问文件数据，而不需要进行数据在用户空间和内核空间之间的显式复制。

**内存映射文件的工作原理**

1. **映射文件到内存**：操作系统内核将文件的特定区域映射到进程的虚拟地址空间。这通常通过`mmap`系统调用实现。

2. **访问映射区域**：应用程序通过普通的内存访问指令（如读取或写入操作）来访问映射区域。这些操作实际上是对文件数据的访问。

3. **内核处理访问**：当应用程序访问映射区域时，如果数据不在物理内存中（即发生了页面错误），内核会从磁盘读取相应的数据到物理内存，并更新页表，使得虚拟地址映射到正确的物理地址。

4. **数据修改**：如果应用程序修改了映射区域的数据，这些修改会直接反映到物理内存中。当数据被修改后，内核会标记这些页面为“脏”（dirty），表示它们需要被写回到磁盘。

5. **同步到磁盘**：当需要将脏页面写回到磁盘时，内核会负责将这些数据写回文件。这个过程是异步的，应用程序可以继续执行其他任务。

**为什么内存映射文件能避免数据复制**

内存映射文件之所以能避免数据在用户空间和内核空间之间的复制，是因为它利用了虚拟内存管理机制。当应用程序访问映射区域时，实际上是在访问内核管理的物理内存，而不是直接访问磁盘上的文件。这样，数据的读取和写入操作都是在内核空间内部完成的，不需要将数据从内核空间复制到用户空间，或者反过来。

**优点**

- **性能提升**：由于避免了数据在用户空间和内核空间之间的复制，内存映射文件可以显著提高文件I/O操作的性能。

- **简化编程**：应用程序可以像操作普通内存一样操作文件数据，简化了文件I/O的编程模型。

- **共享内存**：多个进程可以映射同一个文件，实现进程间的共享内存通信。

**注意事项**

- **内存管理**：虽然内存映射文件可以提高性能，但需要谨慎管理内存使用，因为映射的文件会占用进程的虚拟地址空间。

- **同步问题**：由于数据修改是异步写回磁盘的，需要确保数据的一致性和完整性，可能需要使用同步机制（如`msync`系统调用）。

- **文件大小限制**：映射的文件大小受到系统可用内存和虚拟地址空间大小的限制。

内存映射文件是现代操作系统中一种高效的文件I/O技术，它通过减少数据复制和利用虚拟内存管理机制来提高性能。然而，它也要求开发者了解其工作原理和限制，以确保正确和高效地使用。

## java 中 io 底层的执行流程

[深入理解javaio读写原理及底层流程 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/442239987)

**Java IO读写原理**

无论是Socket的读写还是文件的读写，在Java层面的应用开发或者是linux系统底层开发，都属于输入input和输出output的处理，简称为IO读写。在原理上和处理流程上，都是一致的。区别在于参数的不同。

用户程序进行IO的读写，基本上会用到read\&write两大系统调用。可能不同操作系统，名称不完全一样，但是功能是一样的。

先强调一个基础知识：read系统调用，并不是把数据直接从物理设备，读数据到内存。write系统调用，也不是直接把数据，写入到物理设备。

read系统调用，是把数据从内核缓冲区复制到进程缓冲区；而write系统调用，是把数据从进程缓冲区复制到内核缓冲区。这个两个系统调用，都不负责数据在内核缓冲区和磁盘之间的交换。底层的读写交换，是由操作系统kernel内核完成的。

**内核态（Kernel Mode）和用户态（User Mode）**

在现代操作系统中，为了保护系统资源和提高安全性，通常会将CPU的运行模式分为内核态和用户态。

1.  **用户态（User Mode）**：这是应用程序运行的模式，它限制了应用程序可以执行的指令和访问的内存区域。在用户态下，应用程序不能直接执行某些特权指令，比如直接访问硬件设备、修改系统数据结构等。这样可以防止应用程序错误或恶意行为对系统造成损害。

2.  **内核态（Kernel Mode）**：这是操作系统内核运行的模式，拥有对硬件资源的完全访问权限。当应用程序需要执行一些需要特权的操作时，比如文件读写、网络通信、设备驱动操作等，它必须通过系统调用（System Call）来请求操作系统内核的帮助。系统调用是操作系统提供的接口，允许用户态程序请求内核态服务。

当系统调用发生时，操作系统会执行以下步骤：

*   **保存当前进程的状态**：操作系统会保存当前用户态程序的寄存器状态、程序计数器等信息，以便在系统调用完成后能够恢复到之前的状态继续执行。
*   **切换到内核态**：CPU模式切换到内核态，以便执行系统调用请求的操作。
*   **执行系统调用**：操作系统内核执行请求的操作，比如读取文件、分配内存等。
*   **恢复用户态程序的状态**：系统调用完成后，操作系统会恢复之前保存的用户态程序的状态信息，包括寄存器、程序计数器等。
*   **返回用户态**：CPU模式切换回用户态，用户态程序继续执行。

这个过程确保了系统资源的安全性和程序的正确执行。通过这种方式，操作系统能够有效地管理资源，同时为应用程序提供必要的服务。

**内核缓冲与进程缓冲区**

缓冲区的目的，是为了减少频繁的系统IO调用。大家都知道，系统调用需要保存之前的进程数据和状态等信息，而结束调用之后回来还需要恢复之前的信息，即操作系统中的内核态（Kernel Mode）和用户态（User Mode）之间的转换，为了减少这种损耗时间、也损耗性能的系统调用，于是出现了缓冲区。

有了缓冲区，操作系统使用read函数把数据从内核缓冲区复制到进程缓冲区，write把数据从进程缓冲区复制到内核缓冲区中。等待缓冲区达到一定数量的时候，再进行IO的调用，提升性能。至于什么时候读取和存储则由内核来决定，用户程序不需要关心。

在linux系统中，系统内核也有个缓冲区叫做内核缓冲区。每个进程有自己独立的缓冲区，叫做进程缓冲区。

所以，用户程序的IO读写程序，大多数情况下，并没有进行实际的IO操作，而是在读写自己的进程缓冲区。

**java IO读写的底层流程**

用户程序进行IO的读写，基本上会用到系统调用read\&write，read把数据从内核缓冲区复制到进程缓冲区，write把数据从进程缓冲区复制到内核缓冲区，它们不等价于数据在内核缓冲区和磁盘之间的交换。

![v2-2d43966234dc1bedb3dee6cd94f7cbba\_r](https://raw.githubusercontent.com/MrSunflowers/images/main/note/images/202406161703450.jpg)

首先看看一个典型Java 服务端处理网络请求的典型过程：

（1）客户端请求

Linux通过网卡，读取客户断的请求数据，将数据读取到内核缓冲区。

（2）获取请求数据

服务器从内核缓冲区读取数据到Java进程缓冲区。

（1）服务器端业务处理

Java服务端在自己的用户空间中，处理客户端的请求。

（2）服务器端返回数据

Java服务端已构建好的响应，从用户缓冲区写入系统缓冲区。

（3）发送给客户端

Linux内核通过网络 I/O ，将内核缓冲区中的数据，写入网卡，网卡通过底层的通讯协议，会将数据发送给目标客户端。

**四种主要的IO模型**

服务器端编程经常需要构造高性能的IO模型，常见的IO模型有四种：

（1）同步阻塞IO（Blocking IO）

首先，解释一下这里的阻塞与非阻塞：

阻塞IO，指的是需要内核IO操作彻底完成后，才返回到用户空间，执行用户的操作。阻塞指的是用户空间程序的执行状态，用户空间程序需等到IO操作彻底完成。传统的IO模型都是同步阻塞IO。在java中，默认创建的socket都是阻塞的。

其次，解释一下同步与异步：

同步IO，是一种用户空间与内核空间的调用发起方式。同步IO是指用户空间线程是主动发起IO请求的一方，内核空间是被动接受方。异步IO则反过来，是指内核kernel是主动发起IO请求的一方，用户线程是被动接受方。

（4）同步非阻塞IO（Non-blocking IO）

非阻塞IO，指的是用户程序不需要等待内核IO操作完成后，内核立即返回给用户一个状态值，用户空间无需等到内核的IO操作彻底完成，可以立即返回用户空间，执行用户的操作，处于非阻塞的状态。

简单的说：阻塞是指用户空间（调用线程）一直在等待，而且别的事情什么都不做；非阻塞是指用户空间（调用线程）拿到状态就返回，IO操作可以干就干，不可以干，就去干的事情。

非阻塞IO要求socket被设置为NONBLOCK。

强调一下，这里所说的NIO（同步非阻塞IO）模型，并非Java的NIO（New IO）库。

（3）IO多路复用（IO Multiplexing）

即经典的Reactor设计模式，有时也称为异步阻塞IO，Java中的Selector和Linux中的epoll都是这种模型。

（5）异步IO（Asynchronous IO）

异步IO，指的是用户空间与内核空间的调用方式反过来。用户空间线程是变成被动接受的，内核空间是主动调用者。

这一点，有点类似于Java中比较典型的模式是回调模式，用户空间线程向内核空间注册各种IO事件的回调函数，由内核去主动调用。

**同步阻塞IO（Blocking IO）**

在linux中的Java进程中，默认情况下所有的socket都是blocking IO。在阻塞式 I/O 模型中，应用程序在从IO系统调用开始，一直到到系统调用返回，这段时间是阻塞的。返回成功后，应用进程开始处理用户空间的缓存数据。

![img](https://raw.githubusercontent.com/MrSunflowers/images/main/note/images/202406161705643.jpeg)

举个栗子，发起一个blocking socket的read读操作系统调用，流程大概是这样：

（1）当用户线程调用了read系统调用，内核（kernel）就开始了IO的第一个阶段：准备数据。很多时候，数据在一开始还没有到达（比如，还没有收到一个完整的Socket数据包），这个时候kernel就要等待足够的数据到来。

（2）当kernel一直等到数据准备好了，它就会将数据从kernel内核缓冲区，拷贝到用户缓冲区（用户内存），然后kernel返回结果。

（3）从开始IO读的read系统调用开始，用户线程就进入阻塞状态。一直到kernel返回结果后，用户线程才解除block的状态，重新运行起来。

所以，blocking IO的特点就是在内核进行IO执行的两个阶段，用户线程都被block了。

BIO的优点：

程序简单，在阻塞等待数据期间，用户线程挂起。用户线程基本不会占用 CPU 资源。

BIO的缺点：

一般情况下，会为每个连接配套一条独立的线程，或者说一条线程维护一个连接成功的IO流的读写。在并发量小的情况下，这个没有什么问题。但是，当在高并发的场景下，需要大量的线程来维护大量的网络连接，内存、线程切换开销会非常巨大。因此，基本上，BIO模型在高并发场景下是不可用的。

**同步非阻塞NIO（None Blocking IO）**

在linux系统下，可以通过设置socket使其变为non-blocking。NIO 模型中应用程序在一旦开始IO系统调用，会出现以下两种情况：

（1）在内核缓冲区没有数据的情况下，系统调用会立即返回，返回一个调用失败的信息。

（2）在内核缓冲区有数据的情况下，是阻塞的，直到数据从内核缓冲复制到用户进程缓冲。复制完成后，系统调用返回成功，应用进程开始处理用户空间的缓存数据。

![img](https://raw.githubusercontent.com/MrSunflowers/images/main/note/images/202406161706092.jpeg)

举个栗子。发起一个non-blocking socket的read读操作系统调用，流程是这个样子：

（1）在内核数据没有准备好的阶段，用户线程发起IO请求时，立即返回。用户线程需要不断地发起IO系统调用。

（2）内核数据到达后，用户线程发起系统调用，用户线程阻塞。内核开始复制数据。它就会将数据从kernel内核缓冲区，拷贝到用户缓冲区（用户内存），然后kernel返回结果。

（3）用户线程才解除block的状态，重新运行起来。经过多次的尝试，用户线程终于真正读取到数据，继续执行。

NIO的特点：

应用程序的线程需要不断的进行 I/O 系统调用，轮询数据是否已经准备好，如果没有准备好，继续轮询，直到完成系统调用为止。

NIO的优点：每次发起的 IO 系统调用，在内核的等待数据过程中可以立即返回。用户线程不会阻塞，实时性较好。

NIO的缺点：需要不断的重复发起IO系统调用，这种不断的轮询，将会不断地询问内核，这将占用大量的 CPU 时间，系统资源利用率较低。

总之，NIO模型在高并发场景下，也是不可用的。一般 Web 服务器不使用这种 IO 模型。一般很少直接使用这种模型，而是在其他IO模型中使用非阻塞IO这一特性。java的实际开发中，也不会涉及这种IO模型。

再次说明，Java NIO（New IO） 不是IO模型中的NIO模型，而是另外的一种模型，叫做IO多路复用模型（ IO multiplexing ）。

**IO多路复用模型(I/O multiplexing）**

如何避免同步非阻塞NIO模型中轮询等待的问题呢？这就是IO多路复用模型。

IO多路复用模型，就是通过一种新的系统调用，一个进程可以监视多个文件描述符，一旦某个描述符就绪（一般是内核缓冲区可读/可写），内核kernel能够通知程序进行相应的IO系统调用。

目前支持IO多路复用的系统调用，有 select，epoll等等。select系统调用，是目前几乎在所有的操作系统上都有支持，具有良好跨平台特性。epoll是在linux 2.6内核中提出的，是select系统调用的linux增强版本。

IO多路复用模型的基本原理就是select/epoll系统调用，单个线程不断的轮询select/epoll系统调用所负责的成百上千的socket连接，当某个或者某些socket网络连接有数据到达了，就返回这些可以读写的连接。因此，好处也就显而易见了——通过一次select/epoll系统调用，就查询到到可以读写的一个甚至是成百上千的网络连接。

IO多路复用模型是一种高效的网络编程技术，它允许单个线程或进程同时管理多个网络连接。这种模型的核心思想是**利用操作系统的内核机制**来监视多个socket连接的状态，当这些连接中有数据可读或可写时，操作系统会通知应用程序，从而避免了应用程序对每个socket进行轮询检查的低效做法。

select和epoll是两种常见的IO多路复用技术，它们在不同的操作系统中实现略有不同，但基本原理相似。

1.  **select系统调用**：
    *   select系统调用是较早的IO多路复用技术，它允许应用程序监视一组文件描述符（包括socket）的状态。
    *   应用程序调用select时，需要提供一个文件描述符集合，内核会检查这些文件描述符是否有事件发生（比如可读、可写或异常）。
    *   如果没有事件发生，select调用会阻塞，直到至少有一个文件描述符满足条件。
    *   当有事件发生时，select返回，应用程序可以遍历文件描述符集合，找出哪些描述符有事件发生，然后进行相应的处理。

2.  **epoll系统调用**：
    *   epoll是Linux特有的IO多路复用技术，相比select，它在处理大量文件描述符时更加高效。
    *   epoll使用一个事件表来管理所有被监视的文件描述符，应用程序可以添加、删除或修改事件表中的文件描述符。
    *   epoll有两种工作模式：水平触发（LT）和边缘触发（ET）。水平触发是默认模式，类似于select，只要有数据可读或可写，就会通知应用程序；边缘触发则只有在状态改变时才会通知。
    *   epoll通过内核事件通知机制，减少了不必要的系统调用和上下文切换，提高了性能。

**IO多路复用模型的好处**：

*   **提高效率**：通过单个线程或进程管理多个socket连接，减少了线程或进程的创建和上下文切换的开销。
*   **资源节省**：不需要为每个socket分配一个线程或进程，节省了系统资源。
*   **易于编程**：相比于多线程或多进程模型，IO多路复用模型的编程模型更加简单，易于理解和维护。

综上所述，IO多路复用模型通过select/epoll这样的系统调用，使得单个线程能够高效地管理多个网络连接，从而提高了网络服务的性能和可扩展性。

因此，IO多路复用模型是一种操作系统层面的优化。它利用了操作系统的内核提供的机制来提高网络编程的效率和性能

举个栗子。发起一个多路复用IO的的read读操作系统调用，流程是这个样子：

![img](https://raw.githubusercontent.com/MrSunflowers/images/main/note/images/202406161706487.jpeg)

在这种模式中，首先不是进行read系统调动，而是进行select/epoll系统调用。当然，这里有一个前提，需要将目标网络连接，提前注册到select/epoll的可查询socket列表中。然后，才可以开启整个的IO多路复用模型的读流程。

（1）进行select/epoll系统调用，查询可以读的连接。kernel会查询所有select的可查询socket列表，当任何一个socket中的数据准备好了，select就会返回。

当用户进程调用了select，那么整个线程会被block（阻塞掉）。

（2）用户线程获得了目标连接后，发起read系统调用，用户线程阻塞。内核开始复制数据。它就会将数据从kernel内核缓冲区，拷贝到用户缓冲区（用户内存），然后kernel返回结果。

（3）用户线程才解除block的状态，用户线程终于真正读取到数据，继续执行。

多路复用IO的特点：

IO多路复用模型，建立在操作系统kernel内核能够提供的多路分离系统调用select/epoll基础之上的。多路复用IO需要用到两个系统调用（system call）， 一个select/epoll查询调用，一个是IO的读取调用。

和NIO模型相似，多路复用IO需要轮询。负责select/epoll查询调用的线程，需要不断的进行select/epoll轮询，查找出可以进行IO操作的连接。

另外，多路复用IO模型与前面的NIO模型，是有关系的。对于每一个可以查询的socket，一般都设置成为non-blocking模型。只是这一点，对于用户程序是透明的（不感知）。

多路复用IO的优点：

用select/epoll的优势在于，它可以同时处理成千上万个连接（connection）。与一条线程只绑定一个连接相比，I/O多路复用技术的最大优势是：系统不必创建线程，也不必维护这些线程，从而大大减小了系统的开销。

Java的NIO（new IO）技术，使用的就是IO多路复用模型。在linux系统上，使用的是epoll系统调用。

多路复用IO的缺点：

本质上，select/epoll系统调用，属于同步IO，也是阻塞IO。都需要在读写事件就绪后，自己负责进行读写，也就是说这个读写过程是阻塞的。

既在同步IO模型中，包括select和epoll在内的IO多路复用技术，虽然可以同时监控多个socket，但当某个socket上的数据就绪时，应用程序仍需要自己负责将数据从内核空间的缓冲区复制到用户空间的缓冲区。这个过程是阻塞的，意味着应用程序在数据复制期间无法执行其他任务。

如何充分的解除线程的阻塞呢？那就是异步IO模型。

**异步IO模型（asynchronous IO）**

如何进一步提升效率，解除最后一点阻塞呢？这就是异步IO模型，全称asynchronous I/O，简称为AIO。

AIO的基本流程是：用户线程通过系统调用，告知kernel内核启动某个IO操作，用户线程返回。kernel内核在整个IO操作（包括数据准备、数据复制）完成后，通知用户程序，用户执行后续的业务操作。

kernel的数据准备是将数据从网络物理设备（网卡）读取到内核缓冲区；kernel的数据复制是将数据从内核缓冲区拷贝到用户程序空间的缓冲区。

![img](https://raw.githubusercontent.com/MrSunflowers/images/main/note/images/202406161707336.jpeg)

（1）当用户线程调用了read系统调用，立刻就可以开始去做其它的事，用户线程不阻塞。

（2）内核（kernel）就开始了IO的第一个阶段：准备数据。当kernel一直等到数据准备好了，它就会将数据从kernel内核缓冲区，拷贝到用户缓冲区（用户内存）。

（3）kernel会给用户线程发送一个信号（signal），或者回调用户线程注册的回调接口，告诉用户线程read操作完成了。

（4）用户线程读取用户缓冲区的数据，完成后续的业务操作。

异步IO模型的特点：

在内核kernel的等待数据和复制数据的两个阶段，用户线程都不是block(阻塞)的。用户线程需要接受kernel的IO操作完成的事件，或者说注册IO操作完成的回调函数，到操作系统的内核。所以说，异步IO有的时候，也叫做信号驱动 IO 。

异步IO模型缺点：

需要完成事件的注册与传递，这里边需要底层操作系统提供大量的支持，去做大量的工作。

目前来说， Windows 系统下通过 IOCP 实现了真正的异步 I/O。但是，就目前的业界形式来说，Windows 系统，很少作为百万级以上或者说高并发应用的服务器操作系统来使用。

而在 Linux 系统下，异步IO模型在2.6版本才引入，目前并不完善。所以，这也是在 Linux 下，实现高并发网络编程时都是以 IO 复用模型模式为主。

四种IO模型，理论上越往后，阻塞越少，效率也是最优。在这四种 I/O 模型中，前三种属于同步 I/O，因为其中真正的 I/O 操作将阻塞线程。只有最后一种，才是真正的异步 I/O 模型，可惜目前Linux 操作系统尚欠完善。

## java BIO，NIO，AIO 的区别与实际应用场景分析

[JAVA中BIO、NIO、AIO的分析理解-阿里云开发者社区 (aliyun.com)](https://developer.aliyun.com/article/726698)

[Java编程中的IO模型详解：BIO，NIO，AIO的区别与实际应用场景分析\_java nio bio aio-CSDN博客](https://blog.csdn.net/oWuChenHua/article/details/135394686)

[从理论到实践：深度解读BIO、NIO、AIO的优缺点及使用场景-腾讯云开发者社区-腾讯云 (tencent.com)](https://cloud.tencent.com/developer/article/2337352)

Java中的BIO、NIO和AIO是三种不同的I/O模型，它们在处理网络通信和文件I/O时有着不同的特点和适用场景。

**BIO (Blocking I/O)**

BIO是传统的同步阻塞I/O模型。在这种模型中，当一个客户端连接请求到来时，服务器会为每个客户端创建一个新的线程来处理请求。如果客户端数量很多，服务器将需要大量的线程来处理这些请求，这会导致资源消耗过大，特别是在高并发场景下，服务器的性能会急剧下降。

**应用场景**：

*   适用于连接数不多的场景。
*   适用于简单的客户端-服务器模型，如简单的聊天服务器。

**NIO (Non-blocking I/O)**

NIO是Java 1.4引入的新的I/O模型，它基于事件驱动，使用选择器（Selector）来实现非阻塞I/O。NIO允许一个线程管理多个网络连接，提高了线程的使用效率。NIO适用于需要处理大量连接的场景，如Web服务器、文件服务器等。

**应用场景**：

*   适用于高并发的网络应用，如Web服务器、文件服务器等。
*   适用于需要同时处理多个客户端请求的场景。

**AIO (Asynchronous I/O)**

AIO是Java 7引入的异步非阻塞I/O模型。AIO在NIO的基础上进一步发展，实现了真正的异步I/O操作。在AIO中，当一个I/O操作开始后，线程可以继续执行其他任务，I/O操作完成后，操作系统会通知线程处理结果。AIO适用于需要处理大量I/O操作的场景，如大数据处理、高性能服务器等。

**应用场景**：

*   适用于需要处理大量I/O操作的场景，如大数据处理、高性能服务器等。
*   适用于需要高吞吐量和低延迟的应用。

总结

*   **BIO**：适用于连接数不多的场景，简单易用，但不适合高并发。
*   **NIO**：适用于高并发场景，提高了线程的使用效率，但编程模型相对复杂。
*   **AIO**：适用于需要处理大量I/O操作的场景，提供了更高的性能和吞吐量，但支持的平台和库较少。

在实际应用中，选择哪种I/O模型取决于具体的应用场景和性能需求。对于大多数Web应用和网络服务，NIO是一个很好的选择，因为它提供了较好的性能和可扩展性。对于需要处理大量I/O操作的应用，AIO可能是一个更好的选择。而BIO在一些简单的场景下仍然适用，尤其是在连接数不多的情况下。

## 零拷贝技术

零拷贝（Zero-Copy）技术是一种减少数据在用户空间和内核空间之间复制次数的技术，从而提高数据传输效率的方法。在传统的数据传输过程中，数据需要从磁盘读取到内核空间的缓冲区，然后从内核空间复制到用户空间的缓冲区，最后再从用户空间复制到发送缓冲区或从接收缓冲区复制到用户空间。零拷贝技术通过减少这些不必要的数据复制，可以显著提高数据传输的性能。

例如，在应用程序中想要复制一个文件或向外部发送一个文件，一般情况下，应用程序需要首先向操作系统发出读取文件请求，操作系统收到请求后开始准备数据，数据准备好后通知应用程序可以读取，应用程序发起请求，将数据从内核缓冲区读取到用户缓冲区，然后再复制到指定位置或发送给网卡，发送过程仍需要将数据重新写出到内核缓冲区，然后才能真正发送数据，零拷贝（Zero-Copy）技术就是告诉操作系统，直接将数据复制到指定位置或发送给网卡，不需要给应用程序，跳过中间的过程的一种操作系统级别的优化方式。

**原理**

零拷贝技术的核心思想是减少或避免数据在内核空间和用户空间之间的复制，以及减少CPU的参与。以下是几种常见的零拷贝技术：

1.  **直接I/O**：应用程序直接访问存储设备，绕过内核缓冲区，从而减少一次数据复制。

2.  **内存映射（mmap）**：通过将文件映射到用户空间的内存地址，应用程序可以直接读写文件，避免了数据在内核空间和用户空间之间的复制。

3.  **sendfile**：在Linux系统中，sendfile系统调用可以将数据从一个文件描述符直接传输到另一个文件描述符，减少了一次数据复制。

4.  **DMA（Direct Memory Access）**：直接内存访问允许硬件设备直接读写系统内存，而不需要CPU的介入，从而减少了CPU的负担。

5.  **分散/聚集I/O（Scatter/Gather I/O）**：允许数据从多个缓冲区读取或写入到一个连续的缓冲区，减少了数据的复制次数。

**Java 中的实现**

在Java中，零拷贝技术可以通过以下几种方式实现：

1.  **FileChannel.transferTo() 和 transferFrom()**：这两个方法可以将数据从一个Channel传输到另一个Channel，或者从Channel传输到文件。在某些操作系统上，这些方法可以利用零拷贝技术，减少数据复制。

2.  **NIO的ByteBuffer**：使用ByteBuffer的allocateDirect()方法可以创建一个直接缓冲区，直接缓冲区的数据直接位于物理内存中，可以被操作系统直接访问，从而减少数据在用户空间和内核空间之间的复制。

3.  **Java 7引入的FileChannel.map()**：这个方法可以将文件的一部分映射到内存中，实现内存映射文件，从而实现零拷贝。

4.  **Java 9引入的AIO（Asynchronous I/O）**：虽然AIO本身不直接提供零拷贝技术，但其异步特性可以减少线程的阻塞等待，从而提高系统的整体性能。

需要注意的是，零拷贝技术的实现和效果依赖于底层操作系统和硬件的支持。在某些情况下，零拷贝技术可能无法完全避免数据复制，但仍然可以显著减少数据复制的次数和CPU的参与，从而提高数据传输的效率。

## Java NIO

### Channel

首先说一下Channel，国内大多翻译成“通道”。Channel和IO中的Stream（流）是差不多一个等级的。只不过Stream是单向的，譬如：InputStream， OutputStream，而Channel是双向的，既可以用来进行读操作，又可以用来进行写操作。NIO中的Channel的主要实现有：

1.  FileChannel
2.  DatagramChannel
3.  SocketChannel
4.  ServerSocketChannel

这里看名字就可以猜出个所以然来：分别可以对应文件IO、UDP和TCP（Server和Client）。

### Buffer

Buffer，故名思意，缓冲区，实际上是一个容器，是一个连续数组。 Channel 提供从文件、网络读取数据的渠道，但是读取或写入的数据
都必须经由 Buffer

上面的图描述了从一个客户端向服务端发送数据，然后服务端接收数据的过程。客户端发送数据时，必须先将数据存入 Buffer 中，然后将
Buffer 中的内容写入通道。服务端这边接收数据必须通过 Channel 将数据读入到 Buffer 中，然后再从 Buffer 中取出数据来处理。

在 NIO 中， Buffer 是一个顶层父类，它是一个抽象类，常用的 Buffer 的子类有：ByteBuffer、 IntBuffer、 CharBuffer、 LongBuffer、
DoubleBuffer、 FloatBuffer、ShortBuffer 

### Selector

Selector 类是 NIO 的核心类， Selector 能够检测多个注册的通道上是否有事件发生，如果有事件发生，便获取事件然后针对每个事件进行
相应的响应处理。这样一来，只是用一个单线程就可以管理多个通道，也就是管理多个连接。这样使得只有在连接真正有读写事件发生时，
才会调用函数来进行读写，就大大地减少了系统开销，并且不必为每个连接都创建一个线程，不用去维护多个线程，并且避免了多线程之间
的上下文切换导致的开销。

Java NIO（New Input/Output）的`Selector`类是Java NIO中用于实现非阻塞IO的关键组件。它允许单个线程管理多个网络连接。下面是一个简单的使用`Selector`的实例，演示了如何在服务器端使用`Selector`来处理多个客户端的连接。

```java
import java.io.IOException;
import java.net.InetSocketAddress;
import java.nio.ByteBuffer;
import java.nio.channels.SelectionKey;
import java.nio.channels.Selector;
import java.nio.channels.ServerSocketChannel;
import java.nio.channels.SocketChannel;
import java.util.Iterator;

public class NioSelectorServer {

    public static void main(String[] args) throws IOException {
        // 打开服务器套接字通道
        ServerSocketChannel serverSocketChannel = ServerSocketChannel.open();
        // 绑定到指定端口
        serverSocketChannel.bind(new InetSocketAddress(8080));
        // 设置为非阻塞模式
        serverSocketChannel.configureBlocking(false);

        // 打开选择器
        Selector selector = Selector.open();
        // 将服务器套接字通道注册到选择器上，并指定感兴趣的事件为接受连接
        serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT);

        System.out.println("Server is listening on port 8080...");

        while (true) {
            // 选择一组键，其对应的通道已为 I/O 操作准备就绪
            int readyChannels = selector.select();
            if (readyChannels == 0) {
                continue;
            }

            // 获取选择器中所有已选择的键
            Iterator<SelectionKey> selectedKeys = selector.selectedKeys().iterator();

            while (selectedKeys.hasNext()) {
                SelectionKey key = selectedKeys.next();

                // 检查键是否是新的连接
                if (key.isAcceptable()) {
                    ServerSocketChannel server = (ServerSocketChannel) key.channel();
                    // 接受连接
                    SocketChannel client = server.accept();
                    client.configureBlocking(false);
                    // 注册客户端到选择器，并指定感兴趣的事件为读取
                    client.register(selector, SelectionKey.OP_READ);
                    System.out.println("Accepted connection from " + client.getRemoteAddress());
                }

                // 检查键是否是读取事件
                if (key.isReadable()) {
                    SocketChannel client = (SocketChannel) key.channel();
                    ByteBuffer buffer = ByteBuffer.allocate(1024);
                    int bytesRead = client.read(buffer);
                    if (bytesRead > 0) {
                        buffer.flip();
                        // 读取数据
                        System.out.println("Received message: " + new String(buffer.array(), 0, bytesRead));
                        // 回应客户端
                        buffer.clear();
                        buffer.put("Server received message".getBytes());
                        buffer.flip();
                        client.write(buffer);
                    } else if (bytesRead == -1) {
                        // 客户端关闭连接
                        client.close();
                    }
                }

                // 移除已处理的键
                selectedKeys.remove();
            }
        }
    }
}
```

这个例子中，我们创建了一个服务器端的程序，它监听8080端口。当有新的连接请求时，它接受连接并注册到`Selector`上。当有数据可读时，它读取数据并回送一条消息给客户端。

注意，这个例子仅用于演示目的，实际应用中可能需要更复杂的错误处理和资源管理。此外，为了保持非阻塞特性，所有的操作都应当是非阻塞的，例如，`read`和`write`操作应当在循环中调用，直到所有数据都被读取或写入。

## DirectByteBuffer

`DirectByteBuffer` 是 Java NIO（New Input/Output）包中的一个类，它用于在Java堆外分配内存，即直接内存（Direct Memory）。直接内存不是由JVM管理的堆内存，而是直接由操作系统管理的内存区域。这种内存分配方式可以提高某些操作的性能，尤其是对于那些需要大量数据传输的场景，如网络通信和文件I/O操作。

使用`DirectByteBuffer`可以减少数据在用户空间和内核空间之间的复制次数，从而提高数据传输的效率。`DirectByteBuffer`是Java NIO（New I/O）包中的一部分，它允许Java程序直接操作堆外内存（即直接内存），而不是堆内存。这种直接内存通常由操作系统管理，可以被内核直接访问。

**DirectByteBuffer的工作原理**

1. **直接内存分配**：`DirectByteBuffer`在创建时会分配一块直接内存，这块内存是操作系统管理的，不与Java堆内存直接关联。

2. **内核空间访问**：由于直接内存是操作系统管理的，内核可以直接访问这块内存，无需通过用户空间的缓冲区。

3. **数据传输**：当进行I/O操作时，如读写文件或网络通信，数据可以直接在内核空间和直接内存之间传输，绕过了用户空间的缓冲区。

**减少数据复制次数的原理**

`DirectByteBuffer`减少数据复制次数的原理与内存映射文件的原理不同。内存映射文件是将文件内容映射到用户空间的虚拟内存地址，使得文件数据看起来像是进程的内存。而`DirectByteBuffer`则是直接操作堆外的内存，这块内存是直接由操作系统管理的，可以被内核直接访问。

在使用`DirectByteBuffer`进行I/O操作时，数据传输的路径通常是：

1. **内核空间到直接内存**：当从磁盘读取数据时，内核直接将数据写入到直接内存中，而不是先写入到用户空间的缓冲区。

2. **直接内存到内核空间**：当向磁盘写入数据时，直接内存中的数据直接被内核读取并写入磁盘，无需先复制到用户空间的缓冲区。

**与内存映射文件的区别**

- **内存映射文件**：通过映射文件到用户空间的虚拟内存，使得文件数据看起来像是进程的内存。数据的读写操作仍然需要通过用户空间的内存地址，但操作系统会负责在内核空间和用户空间之间同步数据。

- **DirectByteBuffer**：直接操作堆外的内存，绕过了用户空间的缓冲区。数据的读写操作直接在内核空间和直接内存之间进行，减少了数据复制的次数。

**注意事项**

使用`DirectByteBuffer`时需要注意：

- **内存管理**：直接内存需要手动管理，使用完毕后需要通过`DirectByteBuffer`的`cleaner`机制或`System.gc()`来释放内存。

- **内存泄漏**：如果忘记释放直接内存，可能会导致内存泄漏。

- **性能开销**：虽然减少了数据复制，但直接内存的分配和管理可能会有额外的性能开销。

`DirectByteBuffer`提供了一种高效的数据传输方式，特别适合于需要大量数据传输和高性能I/O操作的应用场景。然而，它也要求开发者对内存管理有更深入的理解和控制。

# 计算机理论基础

## code cache

JVM 将热点代码通过即时编译器编译为机器码，这些机器码存放在 code cache 内存中，这块内存为堆外内存，如果内存不足，会导致即时编译器停止编译，进而导致程序运行变慢，这也是程序执行效率慢的一个考虑方向。

**1. JVM Code Cache 概述**

**Code Cache** 是 JVM 用于存储由 **JIT（Just-In-Time）编译器** 生成的本地机器码的内存区域。当 JVM 检测到某个方法或代码块被频繁调用时，会将其标记为“热点代码”（Hotspot Code），然后通过 JIT 编译器将其编译成本地机器码，以提高执行效率。这些编译后的代码存储在 Code Cache 中，以便后续快速执行。

**2. Code Cache 内存不足的影响**

当 Code Cache 内存不足时，JVM 会停止 JIT 编译新的热点代码。这会导致以下问题：

- **性能下降**：未编译的热点代码只能通过解释器执行，执行速度显著降低。
- **资源浪费**：JIT 编译器可能反复尝试编译相同的代码，但每次都因内存不足而失败，导致资源浪费。
- **程序变慢**：整体程序执行效率下降，可能导致响应时间增加和吞吐量降低。

**3. 导致 Code Cache 内存不足的原因**

- **JVM 参数配置不当**：
  - **Code Cache 大小设置过小**：默认情况下，Code Cache 的大小可能不足以应对大型应用程序或高负载场景。
  - **未启用分层编译**：分层编译（Tiered Compilation）可以更有效地利用 Code Cache，但需要适当的内存配置。

- **应用程序特性**：
  - **大量热点代码**：如果应用程序中有大量频繁调用的方法或代码块，可能会迅速耗尽 Code Cache。
  - **动态类加载**：频繁加载和卸载类会导致 Code Cache 的频繁分配和释放。

- **内存泄漏或碎片化**：
  - **Code Cache 碎片化**：长时间运行的应用程序可能会导致 Code Cache 内存碎片化，无法有效利用可用空间。
  - **内存泄漏**：某些 JVM 实现或第三方库可能存在内存泄漏问题，导致 Code Cache 无法回收。

**4. 诊断 Code Cache 内存不足的方法**

- **查看 JVM 日志**：
  - 启用详细日志（`-XX:+PrintCompilation`）可以监控 JIT 编译情况。
  - 查看 GC 日志（`-Xlog:gc*`）以了解内存使用情况。

- **使用 JVM 工具**：
  - **JConsole** 或 **VisualVM** 可以实时监控 Code Cache 的使用情况。
  - **jstat** 命令可以查看 Code Cache 的统计信息，例如：
    ```bash
    jstat -printcompilation <pid> <interval> <count>
    ```

- **分析内存转储**：
  - 使用 **jmap** 生成堆转储，并使用 **Eclipse MAT** 等工具进行分析，以检查 Code Cache 的使用情况。

**5. 解决 Code Cache 内存不足的方法**

- **调整 JVM 参数**：
  
  - **增加 Code Cache 大小**：
    
    ```bash
    -XX:ReservedCodeCacheSize=512m
    ```
    根据应用程序需求，适当增加 Code Cache 的大小。
    
  - **启用分层编译**：
    ```bash
    -XX:+TieredCompilation
    ```
    分层编译可以更有效地利用 Code Cache，提高编译效率。
  
  - **调整 Code Cache 初始大小**：
    ```bash
    -XX:InitialCodeCacheSize=128m
    ```
    设置 Code Cache 的初始大小。
  
- **优化应用程序**：
  - **减少热点代码**：通过代码优化，减少频繁调用的方法或代码块。
  - **延迟加载**：避免不必要的类加载，减少 Code Cache 的压力。

- **升级 JVM 版本**：
  - 较新的 JVM 版本可能对 Code Cache 管理进行了优化，提供更好的性能和更有效的内存利用。

- **使用不同的 Code Cache 分区**（适用于 Java 9 及以上版本）：
  - **非方法代码区**（Non-Method Code）：
    ```bash
    -XX:NonMethodCodeHeapSize=128m
    ```
  - **Profiled Code 区**：
    ```bash
    -XX:ProfiledCodeHeapSize=128m
    ```
  - **Non-Profiled Code 区**：
    ```bash
    -XX:NonProfiledCodeHeapSize=256m
    ```
    通过分区管理，可以更精细地控制不同类型代码的内存使用。

## 内存、 CPU 缓存和对象填充

**1. 指令的存储与读取**

**1.1 指令存储在内存中**
在冯·诺伊曼架构的计算机中，**程序指令**和**数据**都存储在主内存（RAM）中。CPU 需要从内存中读取指令并执行。

**1.2 指令寄存器（Instruction Register）**
CPU 内部有一个或多个指令寄存器，用于存储当前正在执行的指令。CPU 从内存中读取指令后，会将其加载到指令寄存器中，然后解码并执行。

**2. 内存读取速度与高速缓存**

**2.1 内存读取速度的限制**
主内存（RAM）的访问速度相对较慢，通常以纳秒（ns）为单位，而 CPU 的执行速度非常快，通常以千兆赫兹（GHz）为单位。为了弥补这种速度差异，CPU 设计了多级高速缓存（Cache）。

**2.2 CPU 高速缓存（Cache）**
高速缓存是位于 CPU 和主内存之间的快速存储器，分为多级（如 L1、L2、L3）。L1 缓存速度最快，但容量最小；L3 缓存速度较慢，但容量较大。高速缓存的作用是存储最近访问的指令和数据，以便 CPU 快速访问。

**3. 预取与缓存行（Cache Line）**

**3.1 预取（Prefetching）**
为了进一步提高效率，CPU 在读取指令时不会只读取一条指令，而是会预取与目标指令相邻的多条指令。这种策略基于程序的局部性原理（Locality of Reference），即程序倾向于在短时间内访问相邻的内存区域。

**3.2 缓存行（Cache Line）**
预取的数据以缓存行（Cache Line）为单位进行存储。缓存行是高速缓存中数据存储的最小单位，通常为 64 字节。现代 CPU 在读取指令时，会将包含目标指令的整个缓存行加载到高速缓存中。

例如，如果目标指令在内存地址 `0x1000`，而缓存行大小为 64 字节，那么缓存行将包含从 `0x1000` 到 `0x103F` 的数据。这意味着 CPU 在读取目标指令时，实际上会同时读取多条指令，从而提高后续指令访问的速度。

**4. 指令流水线与分支预测**

**4.1 指令流水线（Instruction Pipeline）**
现代 CPU 采用指令流水线技术，将指令执行过程分为多个阶段（如取指、解码、执行、访存、写回），并在不同阶段并行处理多条指令。通过预取和缓存，CPU 可以确保指令流水线不断流，提高指令执行效率。

**4.2 分支预测（Branch Prediction）**
程序中的分支指令（如跳转、条件分支）会导致指令流水线的停顿。为了减少这种停顿，CPU 使用分支预测技术，预测分支指令的走向，并预取相应的指令。如果预测正确，可以避免流水线的停顿；如果预测错误，则需要清空流水线并重新预取指令。

缓存行的设计能极大的提升程序的运行效率，但也带来了一些问题，试想当 CPU 读取了一个缓存行的数据，而此时另一个程序修改了缓存行的原始数据，此时整个缓存行都将失效，CPU 不得不重新读取整个缓存行。

在Java中，**对象填充（Object Padding）**与**缓存行（Cache Line）**之间的关系是性能优化的一个重要方面。

**对象填充（Object Padding）**

**什么是对象填充**
对象填充是指在对象中插入无用的字段（通常是空的字节数组或长整型字段），以增加对象的大小。这种做法的主要目的是**控制对象在内存中的布局**，特别是确保关键字段不会跨缓存行存储。

**为什么需要对象填充**
对象填充的主要目的是**避免伪共享（False Sharing）**。伪共享是指多个CPU核心同时访问不同变量，但这些变量恰好位于同一个缓存行中。当一个核心修改了其中一个变量时，整个缓存行会失效，导致其他核心的缓存行也失效，从而引发性能问题。

**对象填充与缓存行的关系**

**避免伪共享**
假设有两个线程分别运行在不同的CPU核心上，每个线程访问不同的变量。如果这两个变量在内存中位于同一个缓存行中，那么当一个线程修改其变量时，整个缓存行会被标记为“脏”，导致其他核心的缓存行失效。这会引发大量的缓存一致性通信（Cache Coherence Traffic），从而降低性能。

通过对象填充，可以确保关键变量位于不同的缓存行中，避免伪共享。例如：

```java
public class PaddingExample {
    public volatile long value = 0L; // 关键变量

    // 填充字段
    public long p1, p2, p3, p4, p5, p6, p7;
}
```

在这个例子中，`value` 变量被多个 `long` 类型的填充字段包围，确保 `value` 位于自己的缓存行中，避免与其他变量共享缓存行。

**内存对齐**
对象填充还可以用于**内存对齐**，确保对象在内存中的起始地址是缓存行大小的倍数。这有助于提高缓存命中率，因为CPU在访问数据时更喜欢对齐的内存地址。

**性能优化**
通过合理使用对象填充，可以显著减少缓存未命中和缓存一致性通信，从而提升多线程程序的性能。例如，在高性能计算、并发数据结构（如队列、哈希表等）中，对象填充被广泛使用。

**示例分析**

**伪共享示例**

```java
public class FalseSharingExample {
    public volatile long value1 = 0L;
    public volatile long value2 = 0L;
}
```

在上述示例中，`value1` 和 `value2` 可能位于同一个缓存行中。如果两个线程分别修改 `value1` 和 `value2`，会导致大量的缓存行失效，从而降低性能。

**使用对象填充避免伪共享**

```java
public class PaddedFalseSharingExample {
    public volatile long value1 = 0L;

    // 填充字段
    public long p1, p2, p3, p4, p5, p6, p7;

    public volatile long value2 = 0L;

    // 填充字段
    public long p8, p9, p10, p11, p12, p13, p14;
}
```

在这个示例中，`value1` 和 `value2` 被填充字段包围，确保它们位于不同的缓存行中，避免了伪共享。

对象填充与缓存行之间的关系主要体现在**避免伪共享**和**提高缓存命中率**。通过合理使用对象填充，可以优化多线程程序的性能。然而，过度填充可能导致内存浪费，因此需要在实际应用中仔细权衡。

## JVM、虚拟内存、内存与 TLB 缓存失效

在计算机中，每启动一个 JVM 都是一个独立的进程，在每个 Java 进程中打印 Obiect 的 hashcode（默认为内存地址），发现它们指向的内存地址都是一样的，说明每个 Java 进程都被分配了自己独立的内存空间。

事实上每个 JVM 进程都会维护一个自己的虚拟内存空间，简化内存管理。每次 JVM 向操作系统申请内存时，都会同时维护虚拟内存空间和真实内存空间，虚拟内存空间可能会超过真实内存，此时会发生数据溢出，会将数据写到磁盘上。页表保存了虚拟内存与真实内存的映射关系，这个映射关系可能是虚拟内存和真实物理内存的，也可能是和磁盘的。页表本身可以存储在主存中，也可以存储在缓存中，将页表存储在高速缓存中可以显著提高地址翻译的速度。

TLB 是 CPU 中的一个高速缓存，用于存储最近访问的虚拟内存到物理内存的映射关系。由于直接从内存中读取页表进行地址翻译非常耗时，TLB 通过缓存频繁访问的映射关系来加速地址翻译过程。

而进程的切换会导致页表缓存失效，降低系统运行速度。

## 进程

进程是操作系统进行资源分配的最小单位。系统需要用一个数据结构来描述它，这个数据结构被称为 PCB，PCB 主要包含三部分信息：进程的描述信息、进程的控制信息，及进程使用的资源信息。

在系统创建一个进程时，首先应创建其 PCB，然后才能根据 PCB 中的信息有效的管理和控制该进程。

### 进程的状态

进程在活动期间可分为五种状态，任一进程在任一时刻只能处于这 5 种状态之一

1. 初始状态：进程刚刚被创建，还处于只有数据结构的状态
2. 就绪状态：表示进程可以被执行，还未占有处理器
3. 执行状态：已经占有处理器，正在执行
4. 等待状态：表示进程由于某种原因不能占有处理器，处于占有处理器的过程中
5. 终止状态：等待释放占有的资源，并等待系统将自己删除。

### 进程的上下文切换

当进程由于某种原因进入等待状态或因某种事件而终止 CPU 的执行时，为了以后该进程能回到终止处恢复执行，就需要保护当前进程的 CPU 执行现场。PCB 中设有专门的 CPU 现场保护区，以存储 CPU 终止执行是的进程现场。

进程的上下文实际上是供进程切换用的，在进程执行过程中，由于中断、出错等原因造成进程被悬挂，此时操作系统需要知道和记忆进程执行到什么地方或新进程将从何处执行，进程在执行过程中调用其他进程的情况也在此列。

已执行的进程指令和数据在寄存器与堆栈中的内容称为上文，正在执行的指令和数据在寄存器与堆栈中的内容称为正文，等待执行的指令和数据在寄存器与堆栈中的内容称为下文。

若在进程中发生内核态与用户态的相互转化，那么也会发生上下文切换。

## 线程与进程的区别

计算机中的线程和进程是操作系统进行**任务调度**和**资源管理**的基本单位

1. **定义和概念**：
   - **进程（Process）**：进程是系统进行资源分配和调度的一个独立单位。每个进程都有自己的地址空间、代码、数据和其他系统资源，如文件句柄和信号处理器等。进程是程序执行的实例，可以理解为一个正在运行的程序。
   - **线程（Thread）**：线程是进程中的一个执行路径，是CPU调度和分派的基本单位。一个进程可以包含多个线程，这些线程共享进程的资源和地址空间，但拥有自己的栈和程序计数器。

2. **资源分配**：
   - 进程拥有独立的资源，包括内存空间、文件描述符等。
   - 线程共享所属进程的资源，但每个线程有自己的执行栈和程序计数器。

3. **通信和同步**：
   - 进程间通信（IPC）通常比线程间通信更复杂，需要使用管道、信号、套接字等机制。
   - 线程间通信（TIPC）相对简单，因为它们共享内存空间，可以直接读写同一进程内的数据。

4. **创建和销毁**：
   - 进程的创建和销毁通常需要更多的系统资源和时间，因为涉及到资源的分配和回收。
   - 线程的创建和销毁相对较快，因为它们共享许多资源。

5. **上下文切换**：
   - 进程间的上下文切换开销较大，因为需要保存和恢复更多的资源状态。
   - 线程间的上下文切换开销较小，因为共享资源较多，切换时需要保存和恢复的状态较少。

6. **独立性**：
   - 进程之间相对独立，一个进程的崩溃通常不会直接影响到其他进程。
   - 线程共享资源，一个线程的错误或崩溃可能会影响到同一进程中的其他线程。

在现代操作系统中，多线程通常用于提高程序的并发性和响应性，而多进程则用于提高系统的稳定性和安全性。多线程编程在需要同时执行多个任务时非常有用，尤其是在多核处理器上，可以实现真正的并行处理。

### 进程的上下文切换

进程间切换（也称为进程切换或上下文切换）是指操作系统中断当前正在执行的进程，并保存其状态（上下文），以便之后能够恢复执行该进程，并开始执行另一个进程的过程。这个过程对于用户来说是透明的，是操作系统实现多任务并发执行的关键机制。下面是进程间切换的一般步骤：

1. 当前进程状态的保存

- **保存上下文**：操作系统会保存当前进程的上下文信息，这通常包括程序计数器（PC）、CPU寄存器、进程状态、内存管理信息（如页表）、文件描述符等。这些信息通常存储在进程控制块（PCB）中。
- **更新进程状态**：操作系统将当前进程的状态更新为“就绪”（如果它还有剩余执行时间）或“阻塞”（如果它正在等待某些资源或事件）。

2. 调度决策

- **选择下一个进程**：操作系统根据调度算法（如轮转调度、优先级调度等）从就绪队列中选择一个进程作为下一个执行的进程。
- **准备执行**：操作系统为选定的进程准备执行环境，这可能包括设置地址空间、加载必要的数据到缓存等。

3. 新进程上下文的恢复

- **恢复上下文**：操作系统从新选定进程的PCB中恢复上下文信息到CPU寄存器和内存中，包括程序计数器、寄存器状态等。
- **更新PCB状态**：将新进程的状态更新为“运行”。

4. 继续执行

- **继续执行**：CPU开始执行新进程的指令，从上次停止的地方继续。

进程间切换的影响

进程间切换对系统性能有一定影响，主要体现在以下几个方面：

- **时间开销**：保存和恢复进程状态需要时间，这会消耗CPU资源。
- **缓存和TLB（转换后援缓冲区）失效**：由于每个进程可能有不同的内存访问模式和地址空间，进程切换可能导致缓存和TLB失效，影响性能。
- **I/O操作和同步**：进程间切换可能发生在进程等待I/O操作完成或进行同步时，这有助于提高CPU利用率。

为了减少进程间切换的开销，操作系统设计者和程序员会采取各种优化措施，如合理设计调度策略、减少不必要的进程创建、使用线程代替进程（在某些情况下）等。

进程间切换是操作系统管理并发执行多个进程的核心机制，它确保了系统的稳定运行和资源的合理分配。

## Java 中虚拟线程与线程的区别

Java 中的虚拟线程（Virtual Thread）与传统线程（也称为平台线程）在多个方面存在显著的区别：

1. **资源占用与创建成本**：
   - **传统线程**：每个传统线程都直接映射到操作系统线程上，因此创建和销毁传统线程的成本较高。它们需要为每个线程分配独立的堆栈和线程上下文，这导致了较高的内存开销。
   - **虚拟线程**：虚拟线程由JVM管理，它们共享同一个操作系统线程的资源，因此虚拟线程的创建和销毁开销极低。这使得可以轻松创建和销毁大量虚拟线程，而不会像传统线程那样耗尽系统资源。

2. **上下文切换开销**：
   - **传统线程**：由于每个传统线程都对应一个操作系统线程，上下文切换开销较大，因为涉及到操作系统级别的调度和同步。
   - **虚拟线程**：虚拟线程在用户空间内被管理，上下文切换开销更低。当一个虚拟线程阻塞时，它可以被挂起，底层的操作系统线程则可以用来运行其他虚拟线程。

3. **并发性与资源利用**：
   - **传统线程**：并发性受限于操作系统线程的数量，资源利用率有限。
   - **虚拟线程**：由于虚拟线程的轻量级特性，可以实现更高的并发性。它们允许在有限资源下创建更多的线程，从而更有效地利用系统资源。

4. **适用场景**：
   - **传统线程**：适用于需要密集计算和精细控制线程行为的场景，以及对延迟敏感的应用程序。
   - **虚拟线程**：特别适合处理I/O密集型任务，如网络请求、文件读写等，因为它们可以高效地处理阻塞操作，提高程序的吞吐量。

5. **编程模型**：
   - **传统线程**：需要开发者关注线程的创建、销毁和调度等细节，编程模型相对复杂。
   - **虚拟线程**：简化了并发编程模型，开发者可以像编写普通顺序代码一样编写并发代码，无需过多考虑线程管理和调度。

6. **线程类型**：
   - **传统线程**：默认创建的是用户线程，可以是守护线程或用户线程。
   - **虚拟线程**：是守护线程，并且其守护线程的属性不能被修改。

7. **JDK版本**：
   - **传统线程**：是Java一直以来支持的线程模型。
   - **虚拟线程**：在Java 21正式发布，之前作为预览特性在Java 19中引入。

综上所述，虚拟线程为Java并发编程带来了新的可能性，特别是在处理高并发I/O密集型任务时，它们能够显著提高程序的性能和资源利用率。然而，虚拟线程并不旨在完全替代传统线程，而是作为补充，针对不同场景选择合适的线程模型仍然很重要。

## 寄存器的作用

计算机中的寄存器是中央处理器（CPU）内部非常快速的小型存储单元，寄存器用于临时存储CPU在执行指令过程中需要频繁访问的数据。由于它们位于CPU内部，访问速度非常快，这大大加快了数据处理的速度。特定的寄存器，如指令寄存器（IR），用于存储当前正在执行或即将执行的指令。这使得CPU可以快速读取和解码指令。程序计数器用于存储下一条要执行指令的地址。它确保CPU知道接下来应该执行哪一条指令。

## CPU 三级缓存结构与其作用

CPU的三级缓存结构通常指的是现代处理器中包含的L1、L2和L3缓存。这些缓存层级的设计旨在优化数据访问速度和减少处理器与主内存之间的延迟。

一级和二级缓存是单个CPU独有的，三级缓存是所有CPU核心公用的，

下面是三级缓存各自的作用和特点：

1. **L1缓存（一级缓存）**：
    - L1缓存是CPU中最快的缓存，通常位于CPU核心内部，访问速度极快。
    - 它的容量相对较小，一般在几十KB到几百KB之间。
    - L1缓存被设计为存储最频繁访问的数据和指令，以减少访问延迟。
    - 由于其高速和核心内部的位置，L1缓存对于提高CPU性能至关重要。

2. **L2缓存（二级缓存）**：
    - L2缓存的容量比L1大，但访问速度稍慢。在多核处理器中，L2缓存可以是每个核心独有，也可以是多个核心共享。
    - 它通常也位于CPU核心内部，但可能与L1缓存共享或独立。
    - L2缓存用于存储次频繁访问的数据和指令，作为L1缓存的补充。
    - L2缓存有助于减少L1缓存未命中的情况，进一步提高性能。

3. **L3缓存（三级缓存）**：
    - L3缓存的容量通常比L1和L2大得多，但访问速度相对较慢。在多核处理器中，L3缓存通常是所有核心共享的。它用于存储那些不经常访问的数据，当L1和L2缓存未命中时，处理器会查询L3缓存。
    - 它通常位于多个CPU核心之间共享，有时也称为共享缓存。
    - L3缓存用于存储多个核心可能需要访问的数据，有助于核心间的数据共享和缓存一致性。
    - 在多核处理器中，L3缓存可以减少核心间通信的延迟，提高整体性能。

**缓存的作用**：
- **减少延迟**：缓存通过存储频繁访问的数据和指令，减少了CPU访问主内存的次数，从而降低了延迟。
- **提高吞吐量**：由于缓存的快速访问能力，CPU可以更快地处理数据和指令，提高了整体的处理吞吐量。
- **减少内存带宽压力**：缓存减少了对主内存的直接访问需求，减轻了内存带宽的压力，允许其他设备更有效地使用内存总线。
- **数据局部性原理**：缓存的设计基于局部性原理，即程序倾向于重复访问最近访问过的数据和指令（时间局部性）和/或访问相邻的数据（空间局部性）。

因为越快的存储越贵，三级缓存结构的设计允许处理器在不同层级上平衡速度、容量和成本，以实现最佳的性能和效率。随着技术的发展，缓存的容量和速度也在不断提升，对现代计算机系统的性能有着显著的影响。

### 在多核处理器中如何保证缓存一致性

在多核处理器中，保证缓存一致性是一个复杂的问题，因为多个核心可能同时读写共享数据，而每个核心都有自己的缓存。为了确保数据的一致性，现代多核处理器采用了多种机制，其中最著名的包括：

1. MESI协议（修改、独占、共享、无效）

MESI是一种广泛使用的缓存一致性协议，它定义了缓存行的四种状态：

- **修改（Modified）**：缓存行中的数据被修改过，与主内存中的数据不一致，且该缓存是唯一拥有该数据的缓存。
- **独占（Exclusive）**：缓存行中的数据与主内存中的数据一致，且没有其他缓存拥有该数据的副本。
- **共享（Shared）**：缓存行中的数据与主内存中的数据一致，且可能有其他缓存拥有该数据的副本。
- **无效（Invalid）**：缓存行中的数据无效。

当一个核心尝试读取或写入缓存行时，MESI协议会确保所有缓存中的数据状态得到更新，以保持一致性。

2. 监听（Snooping）

监听是多核处理器中保证缓存一致性的另一种机制。每个核心的缓存会监听（或监视）总线上的内存访问请求。当一个核心尝试修改缓存行时，其他核心的缓存会检查它们是否拥有该行的副本，并根据需要进行更新或失效处理。

3. 写回（Write-back）和写通（Write-through）

写回和写通是缓存行更新策略，它们影响缓存一致性：

- **写回（Write-back）**：数据首先被写入缓存，只有在特定情况下（如缓存行被替换）才会写回主内存。这需要额外的机制来保证缓存一致性。
- **写通（Write-through）**：数据同时写入缓存和主内存。这种方法简化了一致性问题，但可能降低性能。

4. 目录基协议

在一些大型多处理器系统中，可能会使用目录基协议来管理缓存一致性。在这种设计中，有一个中心化的目录来跟踪每个缓存行的状态和位置。当缓存行被访问或修改时，目录会更新状态信息，并通知需要采取行动的缓存。

5. 缓存一致性与内存模型

缓存一致性还与处理器的内存模型紧密相关，内存模型定义了内存操作的可见性和顺序规则。不同的处理器架构（如x86、ARM）有不同的内存模型和缓存一致性保证。

为了实现缓存一致性，现代多核处理器通常结合使用上述几种机制。这些机制确保了即使在高度并行的环境中，数据的一致性和正确性也能得到维护。然而，这些机制也带来了额外的复杂性和性能开销，设计者需要在性能和一致性之间做出权衡。

### 总线嗅探

总线嗅探（Bus Snooping）是一种在多核处理器和多处理器系统中用于维护缓存一致性的技术。由于每个处理器核心可能拥有自己的缓存，当多个核心试图访问和修改同一数据时，就需要一种机制来确保所有缓存中的数据保持一致。总线嗅探正是为了解决这一问题而设计的。

工作原理

在总线嗅探机制中，每个核心的缓存控制器监视（或“嗅探”）系统总线上的内存访问请求。当一个核心尝试读取或写入缓存行时，该操作会通过系统总线广播给所有其他核心。每个核心的缓存控制器会检查这一操作是否影响到自己缓存中的数据，并根据需要采取相应措施。以下是总线嗅探中可能采取的一些措施：

- **当一个核心写入数据时**：其他核心如果缓存了相同的数据，它们会将这些缓存行标记为无效（Invalid），或者根据具体的缓存一致性协议，可能需要将数据写回主内存。

- **当一个核心读取数据时**：如果其他核心拥有该数据的修改过的副本，它们可能会将修改过的数据写回主内存，并让请求数据的核心从主内存读取数据，或者直接将数据从拥有数据的核心的缓存传输到请求数据的核心的缓存中。

优点

- **简单性**：总线嗅探机制相对简单，易于实现。
- **透明性**：对于软件来说，总线嗅探是透明的，不需要软件层面的干预。

缺点

- **扩展性问题**：随着处理器核心数量的增加，总线上的通信量会显著增加，导致性能瓶颈。
- **总线带宽消耗**：总线嗅探需要占用大量的总线带宽，因为每个缓存操作都需要广播到总线上。

解决方案

为了克服总线嗅探带来的扩展性问题，现代多核处理器和多处理器系统采用了更高级的缓存一致性协议和硬件设计，例如：

- **目录基协议**：使用一个中心化的目录来跟踪缓存行的状态和位置，减少总线上的通信。
- **片上网络（NoC）**：在多核处理器中使用片上网络来代替传统的共享总线，以提高通信效率。

总线嗅探是多核处理器和多处理器系统中保证缓存一致性的重要技术之一，尽管它在扩展性方面存在挑战，但通过不断的技术创新和改进，现代系统已经能够有效地解决这些问题。

## 计算机中的页表是什么

在计算机体系结构中，页表是一种数据结构，用于实现虚拟内存管理中的地址转换。虚拟内存是一种技术，它允许计算机系统运行比实际物理内存更大的程序。页表的主要作用是将程序的虚拟地址（逻辑地址）映射到物理内存地址。

页表的工作原理：

1. **分页机制**：
   - 虚拟内存被分割成固定大小的块，称为“页”（Page），而物理内存被分割成同样大小的块，称为“页框”（Page Frame）。
   - 每个程序都有自己的虚拟地址空间，由这些页组成。物理内存中的页框由操作系统管理。

2. **页表的作用**：
   - 每个运行中的程序都有一个页表，用于记录其虚拟页与物理页框之间的映射关系。
   - 当程序尝试访问一个虚拟地址时，CPU会使用页表来查找相应的物理地址。

页表的关键组成部分：

- **页号（Page Number）**：虚拟地址被分为两部分，页号和页内偏移。页号用于在页表中查找对应的条目。
- **页框号（Frame Number）**：页表中的每个条目包含一个页框号，指示虚拟页对应的物理页框。
- **其他控制位**：除了页框号，页表条目还可能包含其他控制信息，如访问权限、修改位、存在位等。

页表的类型：

- **一级页表**：最简单的页表结构，每个程序有一个页表，页表中的每个条目对应一个虚拟页。
- **多级页表**：为了节省空间，现代操作系统通常使用多级页表结构，如二级页表、三级页表等。这种结构将页表分解成更小的部分，只有当需要时才分配页表空间。
- **反向页表**：在某些系统中，使用反向页表来减少页表占用的空间。它记录了物理页框到虚拟页的映射，而不是传统的一对一映射。

页表的优缺点：

- **优点**：
  - 支持虚拟内存，允许程序使用比实际物理内存更大的地址空间。
  - 提高了内存的利用率和程序的并发运行能力。

- **缺点**：
  - 页表本身需要占用一定的物理内存空间。
  - 地址转换（页表查找）可能引入额外的延迟。

页表是现代操作系统和计算机体系结构中不可或缺的一部分，它使得计算机能够高效地管理内存资源，支持多任务和大型程序的运行。

## 进程的状态有哪些

在操作系统中，进程可以处于多种状态，这些状态反映了进程在执行过程中的不同阶段。进程状态的模型可能因操作系统的设计而略有不同，但通常包括以下几种基本状态：

1. **新建（New）**：
   - 进程刚刚被创建，但尚未被操作系统接受为一个独立的执行实体。此时，进程正在等待分配资源和初始化。

2. **就绪（Ready）**：
   - 进程已经分配到必要的资源，并且已经准备好运行，但当前CPU正在执行其他进程。一旦获得CPU调度，进程就可以立即开始执行。

3. **运行（Running）**：
   - 进程正在CPU上执行。在单核处理器中，一次只有一个进程处于运行状态。在多核处理器中，可以有多个进程同时处于运行状态。

4. **阻塞（Blocked/Waiting）**：
   - 进程正在等待某个事件发生（如I/O操作完成、获取锁等），因此无法继续执行。在等待期间，进程不会占用CPU资源。

5. **终止（Terminated/Exit）**：
   - 进程的执行已经结束，或者由于某种原因被操作系统终止。此时，进程释放所有分配的资源，并从系统中移除。

除了上述基本状态，一些操作系统还可能引入其他状态，例如：

- **挂起（Suspended）**：
   - 进程被暂时停止执行，并从内存中移出，放入到磁盘上。这可以是主动挂起（由进程控制），也可以是被动挂起（由操作系统管理，如内存不足时）。

- **就绪挂起（Ready Suspended）**：
   - 进程处于挂起状态，但已经准备好重新执行，只是暂时被操作系统从内存中移出。

- **阻塞挂起（Blocked Suspended）**：
   - 进程处于挂起状态，并且等待某个事件发生。它在等待期间被移出内存。

进程状态的转换通常由操作系统内核的调度器控制，这些转换是进程管理的重要组成部分。进程状态的管理确保了系统资源的有效分配和使用，同时允许操作系统对进程执行进行适当的控制和调度。

## CPU 调度算法有哪些

CPU调度算法是操作系统用来决定哪个进程或线程获得CPU时间片的机制。这些算法的目标是高效地使用CPU资源，同时尽可能减少进程的等待时间和响应时间。以下是一些常见的CPU调度算法：

1. **先来先服务（FCFS, First-Come, First-Served）**：
   - 最简单的调度算法，按照进程到达的顺序进行调度。容易实现，但可能导致较长的等待时间和较低的CPU利用率。

2. **短作业优先（SJF, Shortest Job First）**：
   - 选择预计执行时间最短的进程进行调度。SJF可以是非抢占式（等待当前进程完成）或抢占式（新到达的短作业可以抢占当前作业）。它减少了平均等待时间，但可能导致长作业饥饿。

3. **优先级调度（Priority Scheduling）**：
   - 根据进程的优先级进行调度，优先级高的进程先执行。优先级可以是静态分配的，也可以是动态调整的。低优先级的进程可能会饥饿。

4. **时间片轮转（Round Robin, RR）**：
   - 将所有进程放入队列中，并为每个进程分配一个固定的时间片。CPU轮流执行队列中的进程，每个进程执行一个时间片。如果进程在时间片结束前未完成，则加入队列尾部等待下一次调度。RR算法简单且公平，适用于分时系统。

5. **多级队列调度（Multilevel Queue Scheduling）**：
   - 将进程分配到不同的队列中，每个队列有自己的调度算法。例如，前台进程可以使用RR算法，而后台进程使用FCFS。队列之间可以有不同的优先级。

6. **多级反馈队列（Multilevel Feedback Queue Scheduling）**：
   - 类似于多级队列调度，但进程可以在队列之间移动。新进程从高优先级队列开始，如果在时间片内未完成，则降低到下一个优先级队列。这种算法可以适应进程的行为变化。

7. **彩票调度（Lottery Scheduling）**：
   - 每次调度时，随机选择一个进程，每个进程根据其获得的“彩票”数量（即权重）被选中的概率不同。这种方法可以提供概率上的公平性。

8. **公平共享调度（Fair Share Scheduling）**：
   - 保证用户或组获得公平的CPU时间份额。调度器跟踪用户或组的资源使用情况，并相应地调整调度决策。

这些算法各有优缺点，适用于不同的应用场景和需求。在实际操作系统中，调度算法的选择和实现可能会根据具体的操作系统设计、目标应用和性能要求有所不同。

# 并发

参考 <a href = "../Server/java/java 多线程/多线程基础.md"> 多线程基础.md </a>

# JVM

参考 <a href = "../Server/java/java 虚拟机/深入理解java虚拟机.md"> 深入理解java虚拟机.md </a>

# 数据存储

参考 <a href = "数据存储.md"> 数据存储.md </a>

# 缓存

参考 <a href = "缓存.md"> 缓存.md </a>

# spring

参考 <a href = "spring.md"> spring.md </a> <br/>
参考 <a href = "../Server/java/java 常用框架/Spring/Spring cloud/Spring cloud.md"> Spring cloud.md </a><br/>
参考 <a href = "../Server/java/java 常用框架/Spring/SpringMVC/SpringMVC笔记.md"> SpringMVC笔记.md </a><br/>

# mybatis 

参考 <a href = "../Server/java/java 常用框架/Mybatis/mybatis.md"> mybatis.md </a>

# 消息中间件

## RabbitMQ

参考 <a href = "../架构相关/消息中间件/RabbitMQ/RabbitMQ.md"> RabbitMQ.md </a>

### RabbitMQ 的可靠消息是如何实现的

RabbitMQ 是一个开源的消息代理软件，它实现了高级消息队列协议（AMQP）。在消息队列系统中，可靠消息的传递是一个关键特性，它确保消息在生产者和消费者之间正确、可靠地传递。RabbitMQ 通过以下机制来实现可靠消息传递：

1. **消息持久化**：
   - 生产者可以将消息标记为持久化，这样即使 RabbitMQ 重启，这些消息也不会丢失。生产者通过设置消息属性中的 `delivery_mode` 为 2 来实现这一点。
   - RabbitMQ 服务器会将持久化消息写入磁盘，确保在系统故障时不会丢失。

2. **队列持久化**：
   - 队列也可以被设置为持久化。这意味着即使 RabbitMQ 重启，队列及其包含的消息也会被保留。
   - 持久化队列需要在声明队列时设置 `durable` 参数为 `true`。

3. **消息确认**：
   - RabbitMQ 使用确认机制来确保消息被消费者正确接收。当消费者接收到消息并处理完毕后，它会向 RabbitMQ 发送一个确认（acknowledgement）。
   - 如果消费者在处理消息时失败或超时，它不会发送确认，RabbitMQ 会将消息重新放入队列中供其他消费者处理。

4. **消息重试和死信队列**：
   - RabbitMQ 允许设置消息的 `TTL`（Time To Live），即消息的最大存活时间。如果消息在队列中超过了这个时间，它会变成“死信”。
   - 死信可以被发送到一个特殊的“死信队列”（Dead Letter Exchange），这样可以对无法处理的消息进行进一步的处理或分析。

5. **事务**：
   - RabbitMQ 支持事务，生产者可以使用事务来确保消息的发送和确认是原子操作。但是，事务会降低吞吐量，因此在高吞吐量的场景下不推荐使用。

6. **发布确认**：
   - 对于生产者来说，RabbitMQ 提供了发布确认机制，允许生产者知道消息是否成功被 RabbitMQ 接收并持久化。

7. **镜像队列**：
   - RabbitMQ 支持镜像队列，可以将队列复制到多个节点上，从而提供高可用性和故障转移能力。

通过这些机制，RabbitMQ 能够提供一个可靠的消息传递系统，确保消息在生产者和消费者之间正确、可靠地传递。然而，需要注意的是，这些机制需要根据具体的应用场景和需求进行适当的配置和使用。

在生产环境中由于一些不明原因，导致rabbitmq重启，在RabbitMQ重启期间**生产者消息投递失败，导致消息丢失**，需要手动处理和恢复。于是，我们开始思考，如何才能进行RabbitMQ的消息可靠投递呢？特别是在这样比较极端的情况，RabbitMQ集群不可用的时候，无法投递的消息该如何处理呢

一种可行的方案是可以引入缓存机制，如果RabbitMQ在重启期间不可用，生产者将无法收到确认回执，这时可以将消息保存在本地的缓存中，等待RabbitMQ重新可用后，使用定时任务对未发送成功的消息进行重新投递。

### 如何避免消息重复投递或重复消费

消息重复投递无法完全避免

重复消费由消费端保证幂等性

### RabbitMQ 集群模式

RabbitMQ 支持多种集群模式，允许消息代理在多个节点之间分布消息和负载，从而提高系统的可用性和容错能力。以下是几种常见的 RabbitMQ 集群模式：

1. **普通集群模式**：
   - 在这种模式下，多个 RabbitMQ 节点组成一个集群，每个节点都拥有自己的队列。
   - 队列数据只存储在声明它的节点上，不跨节点复制。
   - 当一个节点发生故障时，它上面的队列将不可用，直到该节点恢复。
   - 这种模式适用于队列数量较多，且对高可用性要求不是特别高的场景。

2. **镜像队列模式**（Mirrored Queues）：
   - 镜像队列是 RabbitMQ 提供的一种高可用性解决方案。
   - 在镜像队列模式下，队列会在多个节点上进行复制，形成一个镜像队列。
   - 当主节点（拥有队列的节点）发生故障时，一个镜像节点会自动成为新的主节点，保证队列的可用性。
   - 这种模式适用于对高可用性有严格要求的场景。

3. **联邦队列模式**（Federation）：
   - 联邦队列允许在不同的 RabbitMQ 集群之间建立连接，实现消息的转发。
   - 这种模式适用于大型分布式系统，可以跨越不同的数据中心或云环境。
   - 联邦队列通过联邦交换器（Federation Exchanges）和联邦队列（Federation Queues）实现，它们可以将消息从一个集群转发到另一个集群。

4. **Shovel 插件**：
   - Shovel 插件允许在不同的 RabbitMQ 集群或节点之间可靠地传输消息。
   - 它可以配置为从一个队列中拉取消息，并将它们推送到另一个队列或交换器。
   - Shovel 插件适用于需要在不同集群或节点之间传输大量消息的场景。

5. **Stream 集群模式**（仅限 RabbitMQ 3.9 及以上版本）：
   - Stream 是 RabbitMQ 3.9 引入的一种新的集群模式，它提供了一种更高级别的消息持久化和复制机制。
   - Stream 集群中的每个节点都存储了所有队列的数据，实现了数据的全复制。
   - 这种模式提供了更高的数据一致性和容错能力。

选择哪种集群模式取决于具体的应用需求、可用性要求和系统架构。在设计 RabbitMQ 集群时，需要考虑消息的可靠性、数据一致性、系统性能和容错能力等因素。

### 如何保证消息的顺序性

队列和消费者一对一

### 如何解决消息队列的延时以及过期失效问题？消息队列满了以后该怎么处理？有几百万消息持续积压几小时，说说怎么解决

**消息积压处理办法：临时紧急扩容**

1. **修复消费者问题**：首先，确保消费者（Consumer）能够正常工作，修复任何导致消费速度下降的问题。这可能包括优化消费者代码、增加资源（如内存、CPU）或解决网络问题等。

2. **停止现有消费者**：在确保消费者可以正常工作后，停止所有现有的消费者，以避免在扩容过程中产生新的积压。

3. **创建新 Topic 和 Queue**：创建一个新的 Topic，其 Partition 数量是原来的 10 倍，并相应地创建 10 倍数量的 Queue。这样可以显著增加消息处理的并行度。

4. **编写临时分发程序**：编写一个临时的消费者程序，该程序负责消费积压的数据。这个程序应该只进行简单的处理，然后将数据均匀地轮询写入新创建的 Queue 中。

5. **增加消费者资源**：临时征用 10 倍的机器资源来部署消费者，每个消费者消费一个 Queue 的数据。这样可以将消费速度提升到原来的 10 倍。

6. **消费完毕后恢复原架构**：一旦积压的数据被快速消费完毕，需要将系统恢复到原来的架构，并使用原来的消费者机器来继续消费消息。

**MQ  中消息丢失**

MQ中消息失效：假设你用的是 RabbitMQ，RabbtiMQ 是可以设置过期时间的，也就是 TTL。如果消息在 queue 中积压超过一定的时间就会被 RabbitMQ 给清理掉，这个数据就没了。我们可以采取一个方案，就是批量重导，就是大量积压的时候，直接丢弃数据了，然后等过了高峰期以后，将丢失的那批数据，写个临时程序，一点一点的查出来，然后重新灌入 mq 里面去，把白天丢的数据给他补回来。也只能是这样了。假设 1 万个订单积压在 mq 里面，没有处理，其中 1000个订单都丢了，你只能手动写程序把那 1000 个订单给查出来，手动发到 mq 里去再补一次

**消息队列满了**

只能预防，无法有效解决

mq消息队列块满了：如果消息积压在 mq 里，你很长时间都没有处理掉，此时导致 mq 都快写满了，咋办？这个还有别的办法吗？没有，谁让你第一个方案执行的太慢了，你临时写程序，接入数据来消费，消费一个丢弃一个，都不要了，快速消费掉所有的消息。然后走第二个方案，到了晚上再补数据吧

# Elasticsearch

参考 <a href = "../大数据/Elasticsearch/Elasticsearch.md"> Elasticsearch.md </a>

# Nginx 

参考 <a href = "../架构相关/Nginx/Nginx.md"> Nginx.md </a>

# Linux

## linux 常用命令

Linux系统中有很多常用的命令，这些命令可以帮助用户进行文件管理、系统监控、网络配置等操作。下面列出了一些基础且常用的Linux命令：

1. `ls` - 列出目录内容
   ```
   ls -l       # 以长格式列出详细信息
   ls -a       # 列出所有文件，包括隐藏文件
   ```

2. `cd` - 更改当前目录
   ```
   cd /        # 切换到根目录
   cd ..       # 切换到上一级目录
   cd ~        # 切换到用户的主目录
   ```

3. `pwd` - 显示当前工作目录的路径

4. `cp` - 复制文件或目录
   ```
   cp source.txt dest.txt       # 将source.txt复制为dest.txt
   cp -r dir1 dir2             # 递归复制dir1到dir2
   ```

5. `mv` - 移动或重命名文件或目录
   ```
   mv oldname.txt newname.txt   # 将oldname.txt重命名为newname.txt
   mv file1 file2 /path/to/dir  # 将file1和file2移动到指定目录
   ```

6. `rm` - 删除文件或目录
   ```
   rm file.txt                  # 删除文件file.txt
   rm -r dir                    # 递归删除目录dir
   ```

7. `mkdir` - 创建新目录
   ```
   mkdir newdir                 # 创建一个名为newdir的新目录
   mkdir -p parent/child        # 创建多级目录结构
   ```

8. `rmdir` - 删除空目录

9. `touch` - 创建空文件或更新文件时间戳
   ```
   touch newfile.txt            # 创建一个空文件newfile.txt
   touch -t 202301010000 file   # 设置文件的时间戳为2023年1月1日00:00
   ```

10. `cat` - 查看文件内容、创建文件、文件合并、追加文件内容等
    ```
    cat file.txt                # 查看file.txt的内容
    cat > newfile.txt           # 创建一个新文件并输入内容
    cat file1.txt file2.txt > combined.txt # 合并file1.txt和file2.txt的内容到combined.txt
    ```

11. `more` 和 `less` - 分页查看文件内容
    ```
    more file.txt               # 分页查看file.txt的内容
    less file.txt               # 交互式分页查看file.txt的内容
    ```

12. `head` 和 `tail` - 查看文件的开头或结尾部分
    ```
    head -n 10 file.txt         # 查看file.txt的前10行
    tail -n 10 file.txt         # 查看file.txt的最后10行
    ```

13. `grep` - 文本搜索工具
    ```
    grep "pattern" file.txt     # 在file.txt中搜索包含"pattern"的行
    ```

14. `find` - 查找文件或目录
    ```
    find / -name file.txt       # 在根目录下查找名为file.txt的文件
    ```

15. `df` - 显示磁盘空间使用情况
    ```
    df -h                       # 以易读的格式显示磁盘空间使用情况
    ```

16. `du` - 显示目录或文件的磁盘使用量
    ```
    du -sh dir                  # 显示目录dir的总大小
    ```

17. `chmod` - 更改文件或目录的权限
    ```
    chmod 755 file.txt          # 更改file.txt的权限为755
    ```

18. `chown` - 更改文件或目录的所有者
    ```
    chown user:group file.txt   # 更改file.txt的所有者为user，所属组为group
    ```

19. `ps` - 显示当前进程
    ```
    ps aux                      # 显示所有进程的详细信息
    ```

20. `top` - 实时显示进程状态
    ```
    top                         # 实时显示系统进程状态
    ```

21. `kill` - 终止进程
    ```
    kill -9 PID                 # 强制终止进程号为PID的进程
    ```

22. `tar` - 打包和解包文件
    ```
    tar -cvf archive.tar files/ # 打包files目录到archive.tar
    tar -xvf archive.tar        # 解包archive.tar
    ```

23. `gzip` 和 `gunzip` - 压缩或解压缩文件
    ```
    gzip file.txt               # 压缩file.txt
    gunzip file.txt.gz          # 解压缩file.txt.gz
    ```

24. `zip` 和 `unzip` - 压缩或解压缩ZIP文件
    ```
    zip archive.zip file.txt    # 压缩file.txt到archive.zip
    unzip archive.zip           # 解压缩archive.zip
    ```

25. `wget` - 从网络下载文件
    ```
    wget http://example.com/file.txt # 从指定URL下载file.txt
    ```

26. `curl` - 传输数据的工具，支持多种协议
    ```
    curl http://example.com     # 获取指定URL的内容
    ```

27. `ssh` - 安全地访问远程服务器
    ```
    ssh user@host               # 通过SSH连接到远程主机
    ```

28. `scp` - 安全地复制文件到远程服务器或从远程服务器复制文件
    ```
    scp localfile.txt user@host:/path/to/remote/directory # 将本地文件复制到远程服务器
    ```

29. `apt-get` (Debian/Ubuntu) 或 `yum` (CentOS/RHEL) - 管理软件包
    ```
    sudo apt-get update         # 更新软件包列表
    sudo apt-get install package # 安装软件包
    sudo apt-get remove package # 卸载软件包
    ```

30. `systemctl` - 控制systemd系统和服务管理器
    ```
    systemctl start service    # 启动服务
    systemctl stop service     # 停止服务
    systemctl restart service  # 重启服务
    systemctl status service   # 查看服务状态
    ```

## linux 高级命令

Linux系统中有很多高级命令，这些命令可以执行复杂的数据处理、系统管理、网络监控等任务。以下是一些高级命令的示例，它们在日常使用中可能不那么常见，但对系统管理员和高级用户来说非常有用：

1. `awk` - 文本和数据处理工具
   ```
   awk '/pattern/ {action}' file.txt # 对匹配模式的行执行动作
   ```

2. `sed` - 流编辑器，用于对文本进行过滤和转换
   ```
   sed 's/old/new/g' file.txt # 将file.txt中的所有old替换为new
   ```

3. `tr` - 转换或删除字符
   ```
   echo "Hello World" | tr 'l' 'L' # 将Hello World中的所有l转换为L
   ```

4. `cut` - 剪切文件中的列
   ```
   cut -d: -f1 /etc/passwd # 以冒号为分隔符，提取/etc/passwd文件的第一列
   ```

5. `sort` - 对文本文件的行进行排序
   ```
   sort -n -k 2 file.txt # 按第二列的数值进行排序
   ```

6. `uniq` - 报告或省略重复行
   ```
   sort file.txt | uniq # 排序后删除重复行
   ```

7. `diff` - 比较文件差异
   ```
   diff file1.txt file2.txt # 比较两个文件的差异
   ```

8. `patch` - 应用补丁文件
   ```
   patch < patchfile.diff # 应用补丁文件
   ```

9. `xargs` - 构建并执行命令行
   ```
   find . -name "*.txt" | xargs grep "pattern" # 搜索所有.txt文件中包含"pattern"的行
   ```

10. `nohup` - 运行命令忽略挂断信号
    ```
    nohup command & # 在后台运行command，即使终端关闭也不会终止
    ```

11. `screen` - 多窗口终端管理器
    ```
    screen -S session_name # 创建一个名为session_name的会话
    ```

12. `tmux` - 终端复用器，类似于screen
    ```
    tmux new -s session_name # 创建一个名为session_name的新会话
    ```

13. `strace` - 跟踪系统调用和信号
    ```
    strace -e trace=file ls # 跟踪ls命令的文件系统调用
    ```

14. `lsof` - 列出打开的文件
    ```
    lsof /path/to/file # 列出打开指定文件的所有进程
    ```

15. `netstat` - 网络连接、路由表、接口统计等信息
    ```
    netstat -tuln # 列出所有TCP和UDP的监听端口
    ```

16. `ss` - 显示套接字统计信息
    ```
    ss -tuln # 显示TCP和UDP的监听端口
    ```

17. `iostat` - 报告CPU统计信息和设备I/O
    ```
    iostat -x 1 # 每秒更新一次设备I/O统计信息
    ```

18. `vmstat` - 报告虚拟内存统计信息
    ```
    vmstat 1 # 每秒更新一次内存统计信息
    ```

19. `free` - 显示内存使用情况
    ```
    free -m # 以MB为单位显示内存使用情况
    ```

20. `df` 和 `du` - 磁盘空间使用情况
    ```
    df -h # 显示磁盘空间使用情况
    du -sh /path/to/directory # 显示指定目录的磁盘使用情况
    ```

21. `md5sum` 和 `sha256sum` - 计算和校验文件的MD5或SHA256校验和
    ```
    md5sum file.txt # 计算file.txt的MD5校验和
    sha256sum -c checksums.txt # 校验checksums.txt中的SHA256校验和
    ```

22. `rsync` - 远程文件同步工具
    ```
    rsync -avz source/ user@host:/dest/ # 同步本地目录到远程目录
    ```

23. `wget` 和 `curl` - 网络下载工具
    ```
    wget -O file.zip http://example.com/file.zip # 下载并重命名文件
    curl -o file.zip http://example.com/file.zip # 下载并重命名文件
    ```

24. `ping` - 检查网络连接
    ```
    ping -c 4 example.com # 发送4个ICMP请求到example.com
    ```

25. `traceroute` - 跟踪数据包到目的地的路径
    ```
    traceroute example.com # 跟踪到example.com的路径
    ```

26. `mtr` - 网络诊断工具
    ```
    mtr example.com # 结合了ping和traceroute的功能
    ```

27. `nmap` - 网络探测和安全审核工具
    ```
    nmap -sP 192.168.1.0/24 # 扫描192.168.1.0/24网络中的活跃主机
    ```

28. `tcpdump` - 网络数据包分析器
    ```
    tcpdump -i eth0 port 80 # 捕获eth0接口上端口80的数据包
    ```

29. `htop` - 交互式进程查看器
    ```
    htop # 以交互式方式查看和管理进程
    ```

30. `bc` - 命令行计算器
    ```
    echo "2+3" | bc # 使用bc进行简单的数学运算
    ```

## 查询端口的链接数量，例如查询应用数据库链接数量

`netstat -anpt | grep 16310 | wc -l`

`netstat -anpt | grep 16310 | wc -l` 是一个在类Unix操作系统中使用的命令行组合，用于统计特定端口（在这个例子中是16310端口）的连接数。下面是这个命令的详细解释：

1. `netstat` 是一个网络统计工具，用于显示网络连接、路由表、接口统计等信息。它是一个非常强大的网络诊断工具。

2. `-an` 参数组合：
   - `-a` (all) 显示所有选项，默认不显示LISTEN相关。
   - `-n` (numeric) 显示原始地址，而不是尝试确定符号名称。

3. `-p` 参数用于显示每个套接字所属的进程ID和名称。这需要root权限。

4. `-t` 参数用于显示TCP协议的连接。

5. `|` 是管道符号，它将前一个命令的输出作为后一个命令的输入。

6. `grep 16310` 是一个文本搜索工具，用于搜索包含特定文本的行。在这里，它用于从`netstat`命令的输出中筛选出包含端口号16310的行。

7. `wc -l` 是一个统计行数的工具，`-l` 参数表示统计行数。

将这些组合起来，`netstat -anpt | grep 16310 | wc -l` 命令的执行流程如下：

1. `netstat -anpt` 命令列出所有网络连接，包括TCP连接，并显示每个连接的进程ID和名称，同时不将地址转换为符号名称。

2. `grep 16310` 从`netstat`的输出中筛选出包含端口号16310的行。

3. `wc -l` 统计筛选后的行数，即端口16310的连接数。

这个命令通常用于快速检查特定端口的活动连接数，特别是在排查网络问题或监控服务状态时非常有用。需要注意的是，使用`-p`参数需要相应的权限，通常需要root权限才能正确显示进程信息。

# 容器化云原生

## docker

参考 <a href = "../架构相关/容器化云原生/docker/docker.md"> docker </a>

## Kubernetes

参考 <a href = "../架构相关/容器化云原生/K8S(施工中)/Kubernetes.md"> Kubernetes </a>

# vue

参考 <a href = "../Web 前端/vue/Vue基础.md"> Vue基础 </a>

# 计算机网络

## TCP 协议

TCP（Transmission Control Protocol，传输控制协议）是一种面向连接的、可靠的、基于字节流的传输层通信协议。它位于OSI模型的传输层，主要负责在不可靠的网络环境中提供可靠的、有序的和错误检查的数据传输服务。TCP协议是互联网中最基本的协议之一，广泛应用于各种网络应用中，如Web浏览、电子邮件、文件传输等。

### TCP协议的主要特点包括：

1. **面向连接**：在数据传输之前，TCP通过三次握手过程建立一个稳定的连接。这个连接在数据传输完成后通过四次挥手过程关闭。

2. **可靠传输**：TCP通过序列号、确认应答、重传机制、流量控制和拥塞控制等机制确保数据正确、有序地到达目的地。

3. **流量控制**：TCP使用滑动窗口机制来控制发送方的发送速率，以防止快速发送方淹没慢速接收方。

4. **拥塞控制**：TCP通过拥塞窗口和拥塞控制算法（如慢启动、拥塞避免、快速重传和快速恢复）来避免网络拥塞。

5. **全双工通信**：TCP允许数据在两个方向上同时传输，即数据可以同时从发送方流向接收方，也可以从接收方流向发送方。

6. **有序传输**：TCP保证数据包按照发送的顺序到达接收方。

7. **错误检测**：TCP使用校验和来检测数据在传输过程中是否出现错误。如果检测到错误，数据包将被丢弃，并且发送方会在超时后重新发送该数据包。

### TCP协议的应用场景：

由于TCP提供了可靠的数据传输服务，它适用于对数据传输可靠性要求高的应用。例如：

- Web浏览（HTTP/HTTPS）
- 电子邮件（SMTP, POP3, IMAP）
- 文件传输（FTP）
- 远程登录（SSH）
- 实时数据传输（如VoIP, 视频会议）

TCP协议通过其复杂的机制确保了数据传输的可靠性，但这也带来了额外的开销，因此在一些对实时性要求高、可以容忍一定数据丢失的应用中，可能会选择使用UDP（用户数据报协议）作为传输层协议。

## TCP 协议连接的建立过程

计算机网络中的TCP（传输控制协议）是一种面向连接的、可靠的、基于字节流的传输层通信协议。TCP通过三次握手建立连接，通过四次挥手断开连接。下面分别解释这两个过程：

三次握手（建立连接）

1. **SYN（同步序列编号）**：客户端发送一个SYN包（同步序列编号）到服务器，并进入SYN_SEND状态，等待服务器确认。SYN包中包含客户端的初始序列号，用于同步。

2. **SYN-ACK（同步确认）**：服务器收到客户端的SYN包后，必须确认客户端的SYN（ACK），同时自己也发送一个SYN包，即SYN+ACK包，此时服务器进入SYN_RECV状态。

3. **ACK（确认）**：客户端收到服务器的SYN+ACK包后，向服务器发送确认包ACK，此包发送完毕后，客户端和服务器进入ESTABLISHED状态，完成三次握手。

完成三次握手后，客户端和服务器之间就可以开始传输数据了。

四次挥手（断开连接）

1. **FIN（结束）**：当客户端完成数据发送任务后，它向服务器发送一个FIN包，请求关闭连接，客户端进入FIN_WAIT_1状态。

2. **ACK（确认）**：服务器收到客户端的FIN包后，发送一个ACK包作为应答，此时服务器进入CLOSE_WAIT状态，客户端收到ACK后，进入FIN_WAIT_2状态。

3. **FIN（结束）**：服务器准备好关闭连接时，向客户端发送一个FIN包，请求关闭连接，服务器进入LAST_ACK状态。

4. **ACK（确认）**：客户端收到服务器的FIN包后，发送一个ACK包作为应答，客户端进入TIME_WAIT状态。等待足够的时间以确保服务器收到其ACK包后，客户端关闭连接，服务器收到ACK后，也关闭连接。

四次挥手过程中，服务器和客户端之间通过发送和确认FIN和ACK包来确保双方都准备好关闭连接，从而优雅地终止连接。

TCP的三次握手和四次挥手机制确保了数据传输的可靠性和连接的有序关闭，是TCP协议能够提供稳定、可靠服务的关键所在。

## TCP 协议在数据传输中如何保证可靠性？

TCP（传输控制协议）是一种面向连接的、可靠的、基于字节流的传输层通信协议。它通过一系列机制来保证数据传输的可靠性，主要包括以下几个方面：

1. **三次握手**：通过三次握手建立连接，确保双方都准备好进行数据传输。

2. **序列号和确认应答**：TCP为每个发送的字节都分配一个序列号，并要求接收方对收到的数据包发送一个确认应答（ACK）。如果发送方没有收到确认应答，它会在超时后重新发送数据包。

3. **流量控制**：TCP使用滑动窗口机制来控制发送方的发送速率，以防止快速发送方淹没慢速接收方。窗口大小会根据接收方的处理能力和网络状况动态调整。

4. **拥塞控制**：TCP通过拥塞窗口和拥塞控制算法（如慢启动、拥塞避免、快速重传和快速恢复）来避免网络拥塞。这些算法会根据网络的拥塞情况动态调整数据包的发送速率。

5. **数据完整性**：TCP使用校验和来检测数据在传输过程中是否出现错误。如果检测到错误，数据包将被丢弃，并且发送方会在超时后重新发送该数据包。

6. **顺序保证**：TCP保证数据包按照发送的顺序到达接收方。如果数据包到达顺序错乱，TCP会重新排序它们。

7. **重传机制**：如果发送方在预定的超时时间内没有收到确认应答，它会重新发送数据包。TCP的超时时间会根据往返时间（RTT）动态调整。

8. **连接管理**：通过四次挥手来优雅地关闭连接，确保所有数据都已传输完毕。

通过这些机制，TCP能够提供一个可靠的数据传输服务，确保数据包在不可靠的网络中能够正确、有序地到达目的地。这使得TCP非常适合需要高可靠性的应用，如文件传输、电子邮件和Web浏览等。

## TCP 协议和 UDP 协议的区别

TCP（传输控制协议）和UDP（用户数据报协议）是互联网协议套件（TCP/IP）中的两种传输层协议，它们在设计上有着根本的不同，主要体现在以下几个方面：

1. **连接性**：
   - TCP是面向连接的协议，它在数据传输之前需要通过三次握手建立一个稳定的连接。
   - UDP是无连接的协议，发送数据之前不需要建立连接，直接发送数据包。

2. **可靠性**：
   - TCP提供可靠的数据传输服务，它通过序列号、确认应答、重传机制、流量控制和拥塞控制等机制确保数据正确、有序地到达目的地。
   - UDP不保证数据的可靠传输，它不提供确认应答、重传机制等可靠性保障，数据包可能会丢失、重复或乱序到达。

3. **顺序**：
   - TCP保证数据包按照发送的顺序到达接收方。
   - UDP不保证数据包的顺序，接收方收到的数据包顺序可能与发送顺序不同。

4. **效率**：
   - TCP由于需要建立连接和维护连接状态，以及进行拥塞控制等，开销较大，传输效率相对较低。
   - UDP由于没有建立连接和维护状态的开销，以及不进行复杂的拥塞控制，传输效率较高，适合对实时性要求高的应用。

5. **数据包大小和头部**：
   - TCP的数据包大小受到窗口大小的限制，头部固定为20字节（不包括选项）。
   - UDP的数据包大小受限于网络的MTU（最大传输单元），头部固定为8字节。

6. **应用场景**：
   - TCP适用于对数据传输可靠性要求高的应用，如Web浏览、电子邮件、文件传输等。
   - UDP适用于对实时性要求高的应用，如在线游戏、实时视频会议、语音通话等。

总结来说，TCP是一种面向连接、可靠、顺序保证的协议，适合需要高可靠性的数据传输；而UDP是一种无连接、不可靠、无顺序保证的协议，适合对实时性要求高的应用。根据应用的具体需求选择合适的协议是非常重要的。

## UDP 协议的传输特点

UDP（用户数据报协议）是一种无连接的网络协议，它在传输层提供了一种简单的数据传输服务。UDP协议的传输特点主要包括以下几点：

1. **无连接**：UDP在发送数据之前不需要建立连接，这使得它在发送数据时的开销非常小，适合于那些不需要建立连接的场景。

2. **不可靠传输**：UDP不保证数据包的可靠传输，它不提供确认应答、重传机制、流量控制和拥塞控制等功能。因此，数据包可能会丢失、重复或乱序到达。

3. **无序传输**：UDP不保证数据包的顺序，接收方收到的数据包顺序可能与发送顺序不同。

4. **低延迟**：由于UDP的无连接和不可靠传输特性，它能够提供比TCP更低的延迟，适合于对实时性要求高的应用，如在线游戏、实时视频会议、语音通话等。

5. **简单高效**：UDP协议的头部只有8个字节，远小于TCP的20个字节（不包括选项），这使得UDP在处理数据包时更加高效。

6. **适合广播和多播**：UDP支持广播和多播传输，这意味着它可以将数据包发送给多个目的地，而不需要为每个目的地单独发送数据包。

7. **应用层控制**：由于UDP不提供复杂的传输控制，应用层需要自己处理数据包的可靠性、顺序和完整性等问题。

8. **灵活性**：UDP允许应用层根据需要自定义数据包的大小和传输策略，提供了较高的灵活性。

总的来说，UDP协议的传输特点使得它非常适合于那些对实时性要求高、可以容忍一定数据丢失的应用场景。然而，由于UDP不提供数据传输的可靠性保证，开发者需要在应用层实现相应的机制来确保数据的正确性和完整性。

## UDP 协议的传输过程

UDP（用户数据报协议）的传输过程相对简单，因为它是一种无连接的协议，不涉及复杂的握手和连接维护过程。以下是UDP数据传输的基本步骤：

1. **数据封装**：应用层将要发送的数据封装成UDP数据报。UDP数据报包括源端口号、目的端口号、长度、校验和以及数据本身。

2. **数据发送**：UDP数据报被发送到网络层，然后封装成IP数据包（即IP头部加上UDP数据报）进行传输。

3. **路由选择**：IP数据包通过网络层的路由选择机制被发送到目标主机。这个过程中，数据包可能会经过多个路由器，直到到达目标网络。

4. **数据接收**：目标主机的网络层接收到IP数据包后，将其传递给传输层的UDP模块。

5. **数据解封装**：UDP模块接收到数据包后，首先进行校验和检查，以确保数据在传输过程中没有损坏。如果校验和检查通过，UDP模块将数据报解封装，提取出数据部分。

6. **数据交付**：最后，UDP将数据交付给目标端口的应用程序。如果目标端口没有应用程序在监听，数据将被丢弃。

在整个过程中，UDP不保证数据包的顺序、完整性或可靠性。如果数据包在传输过程中丢失或损坏，UDP不会进行重传。因此，使用UDP的应用程序需要自己处理这些情况，例如通过应用层协议来实现数据的确认和重传机制。

UDP的传输过程简单、快速，适合于那些对实时性要求高、可以容忍一定数据丢失的应用场景，如实时视频流、在线游戏、语音通话等。

## Socket

Socket通常被称为套接字，它是一种编程界面，提供了一种使用各种协议（如TCP、UDP）在网络中进行通信的方式。简单来说，Socket是对传输层中的TCP/UDP协议进行了封装，对用户隐藏了内部TCP/UDP是如何传输的，只提供一套接口（API）给程序员调用，从而完成socket编程。**Socket本身不是一种协议，而是对传输层中的TCP/UDP协议进行了封装**。

套接字可以分为不同的类型，最常见的是基于传输层协议的两种套接字类型：

1. **TCP套接字**：使用传输控制协议（TCP）的套接字，提供面向连接的、可靠的字节流服务。TCP套接字在数据传输之前需要建立连接，并在数据传输完成后关闭连接。这种类型的套接字适用于需要保证数据完整性和顺序的场景，如Web浏览、电子邮件和文件传输。

2. **UDP套接字**：使用用户数据报协议（UDP）的套接字，提供无连接的、不可靠的数据报服务。UDP套接字不需要建立连接即可发送数据，也不保证数据的顺序和完整性。这种类型的套接字适用于对实时性要求高、可以容忍一定数据丢失的场景，如实时视频流、在线游戏和语音通话。

套接字编程通常涉及以下几个步骤：

- **创建套接字**：使用系统调用创建一个新的套接字。
- **绑定套接字**：将套接字与本地地址和端口绑定，以便其他进程可以找到并连接到这个套接字。
- **监听连接**：对于TCP套接字，需要监听来自其他进程的连接请求。
- **接受连接**：对于TCP套接字，接受来自其他进程的连接请求，建立连接。
- **发送和接收数据**：通过套接字发送和接收数据。
- **关闭套接字**：完成数据传输后，关闭套接字以释放资源。

## HTTP 协议

HTTP（超文本传输协议）是一种应用层协议，用于在网络中传输超文本（例如网页）。HTTP本身是基于请求/响应模型的，它使用TCP作为其传输层协议。

HTTP连接是基于TCP连接的。当客户端发送一个HTTP请求时，它首先需要与服务器建立TCP连接。一旦连接建立，客户端就可以发送HTTP请求给服务器。服务器接收请求后，会返回一个响应给客户端。在请求结束后，TCP连接会被释放。

## Socket 、TCP 和 HTTP 都是什么，他们有什么联系，有什么区别？

Socket、TCP和HTTP都是网络通信领域中的重要概念，它们之间存在密切的联系，但各自扮演着不同的角色。

Socket（套接字）

Socket是网络通信的基础，它提供了一种在应用程序和网络之间进行数据交换的接口。Socket可以基于不同的传输层协议，如TCP或UDP，来实现数据的发送和接收。Socket编程允许开发者控制数据的传输细节，包括连接的建立、数据的发送和接收、以及连接的关闭等。

TCP（传输控制协议）

TCP是一种面向连接的、可靠的、基于字节流的传输层通信协议。它通过三次握手建立连接，确保数据的可靠传输，并通过序列号、确认应答、流量控制和拥塞控制等机制来保证数据的顺序和完整性。TCP适用于需要高可靠性的应用，如Web浏览、电子邮件和文件传输。

HTTP（超文本传输协议）

HTTP是一种应用层协议，它定义了客户端和服务器之间进行数据交换的格式和过程。HTTP通常运行在TCP之上，使用TCP作为其传输层协议，以确保数据的可靠传输。HTTP是无状态的，意味着服务器不会保存任何关于客户端请求的状态信息。HTTP/1.1引入了持久连接（Keep-Alive），允许在同一个TCP连接上进行多个请求和响应，从而提高了效率。

联系与区别

- **联系**：
  - HTTP和TCP都运行在传输层之上，HTTP通常使用TCP作为其传输层协议。
  - Socket是实现TCP和HTTP通信的基础接口，通过Socket可以进行TCP连接的建立和HTTP请求的发送。

- **区别**：
  - **层次不同**：TCP是传输层协议，而HTTP是应用层协议。Socket是网络通信的接口，可以基于不同的传输层协议实现通信。
  - **功能不同**：TCP提供面向连接的、可靠的字节流传输服务，而HTTP定义了客户端和服务器之间交换数据的格式和过程。
  - **状态管理**：HTTP是无状态的，而TCP是面向连接的，具有状态管理功能。
  - **使用场景**：TCP适用于需要高可靠性的数据传输，如文件传输、电子邮件等；HTTP适用于Web内容的请求和传输，如网页浏览、数据检索等。

总的来说，Socket是网络通信的基础，TCP是传输层的可靠协议，而HTTP是应用层的协议，通常运行在TCP之上，用于Web内容的请求和传输。

## Http 与 Https

HTTP（HyperText Transfer Protocol，超文本传输协议）和HTTPS（HyperText Transfer Protocol Secure，超文本传输安全协议）都是用于在互联网上进行数据传输的协议，但它们之间存在一些关键的区别。

HTTP的特点：

1. **无加密**：HTTP协议传输的数据是明文的，这意味着数据在传输过程中可以被第三方轻易截获和读取。

2. **无认证**：HTTP不提供服务器身份验证机制，因此客户端无法验证服务器的身份。

3. **无完整性保护**：HTTP不提供数据完整性保护，数据在传输过程中可能被篡改。

HTTPS的特点：

1. **加密**：HTTPS在HTTP的基础上通过SSL/TLS协议提供了数据加密功能，确保数据在传输过程中不会被窃听或篡改。

2. **服务器身份验证**：HTTPS通过SSL/TLS证书来验证服务器的身份，客户端可以确认它正在与预期的服务器通信。

3. **数据完整性保护**：HTTPS使用消息摘要和数字签名来确保数据的完整性，防止数据在传输过程中被篡改。

HTTPS的工作原理：

HTTPS在建立连接时，首先通过SSL/TLS协议进行握手，这个过程中会进行密钥交换、服务器身份验证和加密参数协商。一旦握手完成，数据传输就会使用协商好的加密算法和密钥进行加密，从而保证数据的安全性。

使用场景：

- **HTTP**：适用于对数据安全性要求不高的场景，如访问公开的网页内容。

- **HTTPS**：适用于需要保护数据隐私和安全的场景，如在线购物、网上银行、电子邮件等。

随着互联网安全意识的提高，HTTPS已经成为网站的标配，许多浏览器也对HTTP网站显示安全警告，鼓励网站使用HTTPS来保护用户数据的安全。

## HTTPS的加密过程是怎样的？

HTTPS的加密过程主要通过SSL/TLS协议来实现，它在HTTP的基础上增加了数据加密、服务器身份验证和数据完整性保护。以下是HTTPS加密过程的简化步骤：

1. SSL/TLS握手

当客户端（通常是Web浏览器）尝试通过HTTPS连接到服务器时，会启动SSL/TLS握手过程：

- **客户端Hello**：客户端向服务器发送一个“Client Hello”消息，包含客户端支持的SSL/TLS版本、加密套件列表、一个随机数（Client Random）和可能的其他扩展信息。

- **服务器Hello**：服务器响应一个“Server Hello”消息，选择客户端提供的加密套件中的一个，并提供服务器的SSL/TLS证书、一个随机数（Server Random）和可能的其他扩展信息。

- **证书验证**：客户端验证服务器证书的有效性，包括证书是否由受信任的证书颁发机构（CA）签发、证书是否过期、证书的域名是否与服务器域名匹配等。

- **密钥交换**：客户端和服务器使用Client Random和Server Random以及服务器证书中的公钥进行密钥交换，生成一个共享的会话密钥（Session Key）。这个过程可能使用不同的密钥交换算法，如RSA、ECDHE等。

2. 加密通信

一旦握手完成，客户端和服务器就拥有了一个共享的会话密钥，可以用于加密后续的通信：

- **加密数据传输**：客户端和服务器使用会话密钥对数据进行加密和解密。数据在发送前被加密，在接收后被解密，确保了数据传输的机密性和完整性。

- **数据完整性保护**：SSL/TLS协议还使用消息摘要和数字签名来确保数据在传输过程中没有被篡改。

3. 会话结束

当数据传输完成后，客户端和服务器可以结束会话。通常，会话结束时，会话密钥会被废弃，以防止未来的通信被解密。

HTTPS的加密过程确保了数据传输的安全性，防止了数据被窃听、篡改和伪造。通过使用SSL/TLS协议，HTTPS为Web通信提供了一个安全的通道。

# 网络安全

## CSRF 攻击

CSRF（Cross-Site Request Forgery，跨站请求伪造）攻击是一种常见的网络安全威胁，它利用了网站对用户浏览器的信任。在CSRF攻击中，攻击者诱使用户在已经认证的会话中执行非预期的操作。这种攻击通常发生在用户已经登录到一个网站后，攻击者通过某种方式（如诱导用户点击链接、加载图片等）使得用户的浏览器向该网站发送一个恶意请求。

[CSRF(跨站请求伪造)](https://blog.csdn.net/leiwuhen92/article/details/128724402)

CSRF攻击的几个关键点包括：

1. **用户认证状态**：攻击通常发生在用户已经登录到目标网站，并且网站信任用户的浏览器。

2. **用户操作**：攻击者需要诱使用户执行某些操作，比如点击一个链接或按钮，而用户可能并不知道这个操作会触发一个恶意请求。

3. **请求的合法性**：由于攻击利用的是用户已经认证的会话，因此从服务器的角度来看，这个请求是合法的，因为它是从一个已经认证的用户那里发出的。

CSRF攻击的常见类型包括：

- **GET型攻击**：攻击者诱导用户点击一个链接，导致用户在不知情的情况下向服务器发送GET请求。
- **POST型攻击**：攻击者可能通过隐藏表单或诱导用户提交表单来发送POST请求。
- **图片型攻击**（Image CSRF）：攻击者通过诱导用户加载一个图片（通过`<img>`标签），而这个图片的`src`属性实际上是一个恶意的POST请求。

为了防御CSRF攻击，可以采取以下措施：

- **使用CSRF令牌**：在服务器端生成一个随机的、一次性的令牌，并将其存储在用户的会话中。每次用户发起请求时，都需要在请求中包含这个令牌。服务器端验证请求中的令牌是否与会话中的令牌匹配。
- **检查HTTP请求头**：例如，可以检查`Referer`头，以确保请求是从预期的源发起的。
- **使用SameSite Cookie属性**：在Cookie中设置`SameSite`属性，可以限制Cookie只在第一方上下文中发送，从而减少跨站请求时Cookie被发送的可能性。
- **限制请求方法**：对于不需要修改服务器状态的请求，可以限制为GET请求，而对需要修改服务器状态的请求使用POST、PUT、DELETE等方法，并进行额外的验证。

通过这些措施，可以有效地减少CSRF攻击的风险，保护网站和用户的安全。

## XSS 攻击

XSS（Cross-Site Scripting，跨站脚本攻击）是一种常见的网络攻击手段，它允许攻击者在用户浏览器中执行恶意脚本。XSS攻击通常发生在Web应用中，攻击者通过在Web页面中注入恶意脚本，当其他用户浏览该页面时，恶意脚本会在用户的浏览器中执行，从而达到攻击者的目的。

XSS攻击的类型：

1. **存储型（Stored XSS）**：
   - 攻击者将恶意脚本存储在服务器上，比如在数据库、消息论坛、评论区等。
   - 当其他用户浏览这些存储了恶意脚本的页面时，脚本会被执行。
   - 存储型XSS是最危险的类型，因为攻击脚本可以长期存在服务器上。

2. **反射型（Reflected XSS）**：
   - 攻击者构造一个包含恶意脚本的链接或请求，然后诱导用户点击或访问。
   - 当用户点击链接或提交请求时，恶意脚本被反射回用户的浏览器执行。
   - 反射型XSS通常需要用户交互，攻击者需要诱使用户执行特定操作。

3. **DOM型（DOM-based XSS）**：
   - DOM型XSS攻击发生在客户端，攻击者利用浏览器端的脚本处理不当，导致恶意脚本被执行。
   - 这种攻击不需要服务器端的交互，攻击脚本直接在用户的浏览器中执行。

XSS攻击的影响：

- **数据窃取**：攻击者可以窃取用户的会话cookie、登录凭证等敏感信息。
- **网站篡改**：攻击者可以修改网页内容，展示错误或恶意信息。
- **恶意操作**：攻击者可以利用XSS执行各种恶意操作，如发送恶意请求、诱导用户点击广告等。

防御XSS攻击的方法：

1. **输入验证**：对所有用户输入进行验证，不允许执行或显示未经验证的脚本。
2. **输出编码**：对输出到HTML页面的内容进行适当的编码，防止脚本被浏览器执行。
3. **使用HTTP头**：设置合适的HTTP头，如`Content-Security-Policy`，限制脚本的执行。
4. **使用安全库和框架**：使用现代的Web框架和库，它们通常内置了XSS防护措施。
5. **更新和打补丁**：定期更新Web应用和依赖库，修复已知的安全漏洞。

通过采取这些措施，可以显著降低XSS攻击的风险，保护Web应用和用户的安全。

## DDoS 攻击

DDoS（Distributed Denial of Service，分布式拒绝服务）攻击是一种常见的网络攻击手段，其目的是通过大量生成的网络流量来使目标服务器或网络资源不可用。DDoS攻击通常涉及多个攻击源（如受感染的计算机、物联网设备等），这些攻击源被恶意软件控制，形成一个“僵尸网络”（Botnet），然后同时向目标发送请求，导致目标服务器过载，无法处理合法用户的请求。

DDoS攻击的类型

1. **流量攻击（Volume-based attacks）**：通过发送大量无用的数据包来耗尽目标的带宽。常见的流量攻击包括UDP洪水攻击、ICMP洪水攻击和SYN洪水攻击。

2. **协议攻击（Protocol attacks）**：利用网络协议的弱点，如TCP握手过程中的资源消耗，导致目标服务器资源耗尽。例如，SYN洪水攻击就是一种协议攻击。

3. **应用层攻击（Application-layer attacks）**：针对特定的应用程序或服务，通过发送大量正常的请求来耗尽服务器资源。例如，HTTP洪水攻击就是针对Web服务器的。

DDoS攻击的防御

1. **增加带宽**：增加服务器的带宽可以提高抵御流量攻击的能力，但这并不是一个经济高效的长期解决方案。

2. **使用DDoS防护服务**：许多云服务提供商和网络安全公司提供DDoS防护服务，可以在攻击发生时自动检测并缓解攻击。

3. **流量清洗**：通过流量清洗技术，可以识别并过滤掉恶意流量，只允许合法流量到达服务器。

4. **入侵检测和防御系统（IDS/IPS）**：部署IDS和IPS可以帮助检测和阻止恶意流量。

5. **黑洞路由**：在检测到DDoS攻击时，可以将恶意流量重定向到一个“黑洞”，从而保护目标服务器。

6. **挑战-响应机制**：通过要求请求者解决一个简单的计算问题（如CAPTCHA），可以有效阻止自动化工具发起的攻击。

7. **网络架构优化**：优化网络架构，如使用负载均衡、冗余设计等，可以提高网络的弹性。

8. **教育和培训**：提高员工的安全意识，防止通过钓鱼邮件等社会工程手段感染恶意软件。

结论

DDoS攻击是一种严重的网络安全威胁，需要通过技术手段和管理措施相结合的方式来防御。由于DDoS攻击的复杂性和多样性，通常需要专业的安全团队和先进的安全工具来应对。对于企业和服务提供商来说，投资于DDoS防护措施是保护业务连续性和用户信任的重要步骤。

##  使用 OAuth 2.0 ＋ JWT 的认证过程

OAuth 2.0 是一个授权框架，允许第三方应用获取有限的访问权限（即令牌）到一个Web服务上的资源，而不需要将用户名和密码等敏感信息共享给第三方应用。JWT（JSON Web Tokens）是一种用于双方之间安全传输信息的紧凑型令牌格式。结合OAuth 2.0和JWT，可以实现一个安全、高效的身份验证和授权流程。以下是使用OAuth 2.0结合JWT的认证过程：

1. 用户授权

用户访问第三方应用，并请求访问受保护的资源。第三方应用将用户重定向到授权服务器（例如，Google、Facebook、自建的认证服务器等）。

2. 用户登录和授权

用户在授权服务器上进行登录，并根据第三方应用请求的权限范围（scope）授权。授权服务器会提示用户确认是否同意第三方应用访问其信息。

3. 授权服务器发放授权码

一旦用户授权，授权服务器会发放一个授权码（authorization code）给第三方应用。

4. 第三方应用请求访问令牌

第三方应用使用授权码向授权服务器请求访问令牌（access token）。这个请求通常包括客户端ID、客户端密钥、授权码以及重定向URI。

5. 授权服务器发放访问令牌

授权服务器验证请求的有效性，如果验证通过，它将发放一个访问令牌给第三方应用。这个访问令牌通常是一个JWT，包含了用户的身份信息和权限范围。

6. 第三方应用使用JWT访问资源服务器

第三方应用使用JWT访问令牌请求资源服务器上的受保护资源。资源服务器验证JWT的有效性，包括签名验证、令牌过期时间检查等。

7. 资源服务器响应

如果JWT有效，资源服务器将返回请求的资源给第三方应用。如果JWT无效或过期，资源服务器将拒绝请求，并返回错误信息。

8. 访问令牌的刷新

如果访问令牌过期，第三方应用可以使用之前获得的刷新令牌（refresh token）来请求一个新的访问令牌。这个过程不需要用户再次参与。

## JWT 签名和验证的具体过程

JWT（JSON Web Tokens）的签名和验证过程是确保其安全性和完整性的关键步骤。以下是这个过程的详细说明：

**签名过程**

1. **创建JWT结构**：JWT由三个部分组成，分别是Header（头部）、Payload（负载）和Signature（签名）。这三部分通过点（`.`）连接起来，形成一个字符串。

   - **Header**：通常包含两部分信息，即令牌的类型（即JWT）和所使用的签名算法，如HS256、RS256等。
   - **Payload**：包含声明（Claims），即关于实体（通常是用户）的声明和其他元数据。声明可以是注册的（registered）或公开的（public），也可以是私有的（private）。
   - **Signature**：用于验证消息在传递过程中未被更改，并且，对于使用私有密钥签名的令牌，它还可以验证JWT的发送者。

2. **编码Header和Payload**：将Header和Payload部分转换为Base64URL编码格式。

3. **签名**：使用Header中指定的算法，结合编码后的Header和Payload以及一个密钥（对于对称加密算法如HS256，使用同一个密钥；对于非对称加密算法如RS256，使用私钥），生成签名。签名的目的是验证消息的发送者身份和确保消息在传输过程中未被篡改。

   - 对于HS256，签名过程是将Header和Payload的Base64URL编码字符串拼接起来，然后使用密钥进行HMAC SHA256加密。
   - 对于RS256，签名过程是使用私钥对Header和Payload的Base64URL编码字符串进行RSA签名。

4. **组合JWT**：将编码后的Header、Payload和Signature用点（`.`）连接起来，形成最终的JWT。

**验证过程**

1. **接收JWT**：服务器端接收到客户端发送的JWT。

2. **解码Header和Payload**：将JWT的Header和Payload部分从Base64URL编码格式解码回原始格式。

3. **获取签名**：从JWT中提取出Signature部分。

4. **验证签名**：使用与签名过程相同的算法和密钥（对于对称加密算法是同一个密钥，对于非对称加密算法是公钥），对Header和Payload进行签名。然后将生成的签名与JWT中的Signature进行比较。

   - 如果签名匹配，说明JWT在传输过程中未被篡改，且确实由持有相应密钥的实体签名。
   - 如果签名不匹配，说明JWT可能被篡改或不是由持有相应密钥的实体签名。

5. **检查过期时间**：验证Payload中的`exp`（过期时间）声明，确保JWT未过期。

6. **其他验证**：根据需要，服务器端还可以执行其他验证，如检查`iss`（发行者）声明、`aud`（受众）声明等。

通过这个过程，服务器可以确保JWT的完整性和安全性，从而信任JWT中包含的信息。

## JWT 的访问令牌撤销应该如何实现

令牌撤销是身份验证和授权流程中的一个重要环节，它允许服务器在令牌被泄露、滥用或过期后立即停止令牌的使用。实现令牌撤销的方法有多种，以下是一些常见的实现方式：

1. 黑名单机制

在服务器端维护一个黑名单列表，用于存储被撤销的令牌。每当令牌被使用时，服务器都会检查该令牌是否存在于黑名单中。如果令牌在黑名单中，则拒绝访问。

**优点**：实现简单，易于理解。

**缺点**：随着令牌数量的增加，黑名单的维护成本会增加，可能影响性能。

2. 令牌过期时间

为每个令牌设置一个过期时间（exp claim），一旦令牌过期，它就自动失效，无需服务器端进行额外操作。

**优点**：简单易行，不需要额外的存储空间。

**缺点**：令牌在过期之前仍然有效，如果令牌在过期前被泄露，那么在过期之前这段时间内无法阻止令牌的使用。

3. 令牌使用次数限制

限制每个令牌的使用次数。一旦令牌的使用次数达到限制，令牌就会失效。

**优点**：可以减少令牌被滥用的风险。

**缺点**：需要在服务器端跟踪每个令牌的使用次数，增加了复杂性。

4. 令牌刷新机制

使用刷新令牌（refresh token）来获取新的访问令牌（access token）。当访问令牌被撤销时，相应的刷新令牌也会被撤销，从而阻止新的访问令牌的生成。

**优点**：可以有效地撤销令牌，同时保持用户体验。

**缺点**：需要额外的逻辑来管理刷新令牌。

5. 令牌状态检查

在服务器端维护一个令牌状态的存储，每次令牌使用时都检查其状态。如果令牌被撤销，则更新其状态为无效。

**优点**：可以即时撤销令牌。

**缺点**：需要服务器端维护状态信息，可能会增加服务器的负担。

6. 基于时间戳的令牌

使用时间戳来生成令牌，服务器端可以检查令牌的时间戳，以确定令牌是否在有效期内。

**优点**：可以减少存储需求，因为不需要存储令牌本身。

**缺点**：需要服务器端同步时间，且令牌的生成和验证过程可能更复杂。

实际应用

在实际应用中，通常会结合使用多种方法来实现令牌撤销。例如，可以使用过期时间来减少令牌的有效期，同时使用黑名单机制来立即撤销特定的令牌。此外，还可以结合使用令牌刷新机制和令牌状态检查，以提供更灵活和安全的令牌管理策略。

总之，令牌撤销的实现需要根据应用的具体需求和环境来定制，以确保既满足安全要求，又不会对性能造成过大影响。

# 常见应用场景分析

## 权限系统设计原则

参考 <a href = "../Server/java/java 常用框架/Spring/Spring Security（施工中）/Spring Security.md"> Spring Security.md </a>

# 分布式ID生成中心

## 美团 leaf

https://tech.meituan.com/2017/04/21/mt-leaf.html?spm=a2c6h.12873639.article-detail.20.1ee648140bqvMI

leaf snowflake 雪花算法

由于结构是由

标志位 ＋ 时间戳 ＋ 机器ID（10位） ＋ 顺序码

组成，在集群时最大可支持 1024 台机器组成高可用集群，则集群总体可保证秒级别顺序递增（时间戳在高位，且各个机器时间有误差时间，总体控制在1秒以内）

不同业务由 zookeeper 创建不同的根节点来隔离实现。

# 项目详情

项目描述

该项目按照公司业务部需求，基于旧监管平台进行改造，实现对现有系统国产化并实现配置化报送，简化报送流程，提高效率，同时使得业务人员能够根据监管要求的变化，快速调整报送策略和内容。

项目改造主要围绕旧平台展开，旧平台基于 oracle 为数据结构支撑，由oracle存储过程完成数据校验，面对亿级数据较为吃力，新平台主要围绕该点展开。

新架构以 mysql 集群为数据存储，Elasticsearch 为数据检索及展示，其难点在于亿级数据 mysql 集群与 Elasticsearch 间的数据准实时展示，

项目详情

基于 spring cloud 微服务技术栈 ＋ vue.js ＋ 自研云平台 构建，选用 MySQL 作为关系型数据库，Elasticsearch 作为数据检索引擎，Redis 为分布式缓存中间件，rabbitMQ 为分布式消息中间件。

项目职责

1. 重构业务数据录入功能

功能主要为业务提供一个数据录入入口，可通过 Excel 文件形式将数据批量录入系统，单文件最大支持 5W 数据批量录入。导入形式以表为粒度，即每次导入的数据都是一个表模型的数据。

**并发修改控制阶段**

在数据导入时**对表模型**添加分布式锁，防止同一时间内多个业务人员对数据进行并发修改。

**数据分片阶段**

系统会为每次导入的文件生成一个唯一的文件编号，存储在**文件上传记录表**中，表中存储文件上传的信息。

将从文件读取的数据拆分为批次数据，以 5W 数据示例，则每个批次为 1000 条，共 50 个批次，并为每个批次生成一个全局唯一的批次号。

建立一张批次表，用于存储每个批次的所属文件编号、消息发送内容，消息发送状态和数据处理状态，为了防止在生成消息的过程中应用宕机导致消息只发送了一部分，要求在新增批次信息时应保持事务，即拆分的 50 个小批次消息应一起入库或一起失败。

由定时任务扫描批次任务表，将未发送状态的批次信息发送至 rabbitMQ 中，等待消费端消费。

**数据消费阶段**

这个消费过程一定是幂等的

建立一张错误数据表，存储错误的数据信息、错误原因、批次信息、所属文件编号、录入人员等，用于后续业务人员查询数据处理结果。文件编号+批次号+数据ID+数据字段ID+校验规则ID 作为唯一约束

消费端接收到消息后，先判断该批次数据是否是已处理过的，若为已处理过的数据则直接丢弃即可，否则

- 首先将数据从消息中读入内存
- 然后根据配置的数据 ID 生成规则为每条数据生成一个全局唯一的 ID 来唯一标识该条数据。这个 ID 生成算法是固定的，即对于同一条数据每次生成的 ID 是相同的。
- 再根据配置的校验规则来对数据进行校验，这个过程在内存中进行，对于相同的数据，多次校验的结果是一致的。
- 将数据库中该文件编号下该批次的错误信息删除，并将新生成的未通过校验的数据插入错误数据表，同时将该条数据从批次数据中剔除。删除步骤为了防止不完整消费逻辑导致的重复消费，如上次消费时只处理到一半服务宕机了。
- 然后从数据库查询该批次信息是否已经存在变更记录，如有则直接使用，否则删除变更记录（没有变更记录说明上次是在此步骤宕机的，那么也可确定该批次数据还未索引入库），该步骤仍是为了防止不完整消费逻辑导致的重复消费，如上次消费时只处理到一半服务宕机了。
- 根据数据的唯一 ID 从 ES 中查询出是否存在对应的历史数据，如有则与数据库数据字段比较生成数据变更记录。并将变更记录记录到数据库中。

**数据索引阶段**

如何保证数据与修改记录的索引的同步性与事务性？

- 将批次数据索引入库至 ES，如未收到 ES 反馈结果，说明可能是网络波动导致，由于结果未知，消费过程失败，等待下次消费
- 收到 ES 反馈结果，部分索引成功，部分失败，记录失败记录 ID
- 剔除失败数据的修改记录，将修改记录入库
- 修改记录仍有可能部分成功或整体失败，将失败的修改记录记录下来
- 同失败数据一起发往


在每个批次索引入库成功后，接收一条成功或失败回调，回调使用消息方式触发，回调信息中携带有批次、异常数据等信息，将索引失败的数据信息插入错误数据表，待业务后续查询处理。

待文件的所有批次数据索引完成后更新文件上传成功。并释放该表模型的锁。

1. ES 数据入库方案

1.1 数据分批

由于业务场景原因，导致可能在短时间内有大量数据索引进入 ES，可能会遇到性能瓶颈、资源不足或数据丢失等问题。将与 ES 交互的功能独立为一个新的服务。利用批量索引（Bulk Indexing）功能索引数据。

将文件中读出的数据分批次处理，保证每次批量索引的数据在在 5MB 到 15MB 之间，过大可能导致内存不足，过小则无法充分利用网络和磁盘带宽。经过测试确定将数据分为 1000 条为一个批次，5W 条数据则应分为 50 个批次。

1.2 批次数据事务

业务场景要求 5W 数据需保持事务性，即成功则都成功，失败则全部失败。首先为每次导入的数据生成一个全局唯一的批次号（UUID），用来标识数据属于哪个批次。

将该批次的数据发送至分布式消息队列 rabbitMQ ，由 ES 消费端消费数据索引入库，

引入分布式消息队列 rabbitMQ 来实现异步调用，防止由于网络波动导致的调用失败问题，


，同时在本地建立一张任务表，表中存储以索引批次为粒度，并记录每个批次的批次号、正文数据，

1.3 可靠消息的保证

在将消息发送至 rabbitMQ 时可利用其提供的可靠消息（发布确认+消息持久化+消息应答ACK）机制来保证消息可靠性，但在发布确认与消息应答过程中仍有可能遇到网络波动导致消息重复发送或重复消费问题。

**消息发送端**

- 首先在消息发送端增加消息状态表，在发送消息时先记录一条消息发送记录，包括全局唯一的消息ID，消息正文等必要信息，发送标识为未发送
- 在消息发送并收到确认回执后更新消息状态为发送成功。
- 在后台定时任务中定时扫描发送失败的消息，并重新发送。这里应使用分布式调度任务或分布式锁来防止多个应用实例争抢发送消息问题。

采取以上措施后可保证消息一定可以传达至消费端，但无法解决消息重复消费问题。

**消息消费端**

- 首先在消息消费端增加消息消费状态表，在收到消息时，先根据消息唯一 ID 查询消息消费状态表，如有记录且状态为已消费或消费中则丢弃该消息，并应答消息，否则记录消息的全局唯一的消息ID，消息正文等必要信息，状态为未消费。
- 业务逻辑处理开始时更新消息状态为消费中，处理完成后，更新消息状态为已消费。

注意：即使采取以上措施，消息依旧可能会重复发送或重复消费，因为如果服务在发送消息完成后还没来的及更新数据库状态或消费时消费完成还没来得及更新消费状态时宕机，消息仍会被再次消费，所以在使用消息异步调用方法时，一定需要保证接口的幂等性。

2. 系统权限设计和重构，提升配置效率

参与项目的功能分析和设计讨论，负责对配置化数据处理、权限系统、系统配置等功能的设计开发和重构优化。

3. 直连报送报送机改造
4. 数据推送功能开发



pod 规格 4C 12G






1. 系统架构：系统使用微服务技术搭建， 以 Spring Cloud 为基本框架，Spring MVC + Spring + Mybatis 为主体构建
2. 数据持久化存储：MySQL 与 oracle 为数据存储
3. 数据检索及加工引擎：Elasticsearch
4. 分布式缓存中间件：Redis
5. 消息中间件：RabbitMQ
6. 前端页面展示：Vue.js



## 应用拆分

基础应用:负责配置信息，包括报表配置和人员权限配置信息等
明细应用 指标应用 一表通应用 计算引擎 利率报备报送机 2 ＋ 8 ＋ 8 ＋ 8 ＋ 8 ＋ 4  ＝ 38 台

## 注册/配置中心

注册中心 nacos 3 台

### 为什么选择使用 nacos，nacos 与 zk 的区别

nacos 相对于 zk 来说，具有更加成熟的服务管理机制，且集成了配置中心的功能，有效避免了二次开发的成本，一般的，服务注册中心都是要求高可用结构，而 zk 在高可用方面不如 nacos ，在选举期间 zk 不可用。

### nacos 的高可用解决方案

nacos 和 Eureka 类似，当微服务与 Nacos 失联时，Nacos 客户端（即微服务中的 Nacos SDK）会尝试重新连接到 Nacos 服务器。在这个过程中，Nacos 客户端会根据配置的策略来处理服务列表的缓存。

Nacos 客户端默认会缓存从 Nacos 服务器获取的服务列表信息。这意味着即使在与 Nacos 服务器失联的情况下，微服务仍然可以使用本地缓存的服务列表信息进行服务调用。这种机制可以提高系统的容错性和稳定性，确保在 Nacos 服务器暂时不可用时，微服务仍然能够正常工作。

能够选择这种模型的底气在于万一客户端拿到了已经发生变动的错误地址，也能够通过 Ribbon 和 Sentinel 模块配合来兜底，实现故障转移（Failover）或者快速失败（Failfast）

尽管 Nacos 客户端并没有自动支持 Ribbon ，但我们依然可以在项目中显式地集成 Ribbon。

在 Spring Cloud 中，通常通过在项目中引入 `spring-cloud-starter-netflix-ribbon` 依赖来集成 Ribbon。然后，你可以使用 `@LoadBalanced` 注解来标注 RestTemplate，这样就可以利用 Ribbon 进行客户端负载均衡了。

例如：

```java
@Configuration
public class RibbonConfig {

    @Bean
    @LoadBalanced
    public RestTemplate restTemplate() {
        return new RestTemplate();
    }
}
```

在服务调用时：

```java
@Service
public class MyService {

    @Autowired
    private RestTemplate restTemplate;

    public String callService(String serviceName, String endpoint) {
        return restTemplate.getForObject("http://" + serviceName + "/" + endpoint, String.class);
    }
}
```

### AP 与 CP 的选择

一般来说，导致集群网络错误一般都是网络分区错误，则

- 如果这件事情对你并没有太大的影响，甚至有可能还是有益的，就应该倾向于选择 AP式的服务发现。譬如假设 A、B 就是不同的机房，是机房间的网络交换机导致服务发现集群出现的分区问题，但每个分区中的服务仍然能独立提供完整且正确的服务能力，此时尽管不是有意而为，但网络分区在事实上避免了跨机房的服务请求，反而还带来了服务调用链路优化的效果。

- 如果这件事情也可能对你影响非常之大，甚至可能带来比整个系统宕机更坏的结果，就应该倾向于选择 CP 式的服务发现。譬如系统中大量依赖了集中式缓存、消息总线、或者其他有状态的服务，一旦这些服务全部或者部分被分隔到某一个分区中，会对整个系统的操作的正确性产生直接影响的话，那与其最后弄出一堆数据错误，还不如直接停机来得痛快。

## 网关服务器

Nginx 2 台 ＋ springCloud Gateway 2 台 都是一主一备

### API 网关的作用

微服务架构下，每个服务节点都可能由不同团队负责，都有着自己独立的、互不相同的接口，如果服务集群缺少一个统一对外交互的代理人角色，那外部的服务消费者就必须知道所有微服务节点在集群中的精确坐标，这样，消费者不仅会受到服务集群的网络限制（不能确保集群中每个节点都有外网连接）、安全限制（不仅是服务节点的安全，外部自身也会受到如浏览器同源策略的约束）、依赖限制（服务坐标这类信息不属于对外接口承诺的内容，随时可能变动，不应该依赖它），就算是调用服务的程序员，自己也不会愿意记住每一个服务的坐标位置来编写代码。

由此可见，微服务中网关的首要职责就是作为统一的出口对外提供服务，将外部访问网关地址的流量，根据适当的规则路由到内部集群中正确的服务节点之上，因此，微服务中的网关，也常被称为“服务网关”或者“API 网关”。

### nginx 与 API 网关的区别

Nginx 除了具有代理与负载的作用以外，在现代前后端分离的项目中，Nginx 还担任了静态资源前置的作用。

### 网关部署集群方案

Nginx + Keepalived 3 台 

在多个 Nginx 实例上安装 Keepalived。
配置 Keepalived，设置虚拟 IP 地址和 VRRP 实例。
当主 Nginx 实例发生故障时，Keepalived 会自动将虚拟 IP 地址切换到备用实例，从而实现故障转移。

spring gatway 3 台 处理动态路由和微服务间的请求路由，Spring Gateway 本身是一个无状态的组件，这意味着它不需要在多个实例之间共享状态。因此，Spring Gateway 可以通过简单的水平扩展来实现集群部署。

###  如何在 Spring Cloud Gateway 中进行身份验证

在Spring Cloud Gateway中进行身份验证通常涉及以下步骤：

1. **创建身份验证过滤器**：
   创建一个自定义的过滤器（`GatewayFilter`），用于在请求到达目标服务之前进行身份验证。这个过滤器可以检查请求头中的令牌（如JWT）、基本认证信息等。

2. **配置过滤器**：
   将自定义的身份验证过滤器添加到Spring Cloud Gateway的过滤器链中。这可以通过编程方式或使用配置文件完成。

3. **处理身份验证逻辑**：
   在过滤器中实现身份验证逻辑，如验证令牌的有效性、查询用户信息等。

4. **处理身份验证失败**：
   如果身份验证失败，过滤器应返回适当的HTTP状态码和错误信息。

下面是一个简单的示例，演示如何创建一个基于JWT令牌的身份验证过滤器：

```java
import org.springframework.cloud.gateway.filter.GatewayFilter;
import org.springframework.cloud.gateway.filter.factory.AbstractGatewayFilterFactory;
import org.springframework.http.server.reactive.ServerHttpRequest;
import org.springframework.http.server.reactive.ServerHttpResponse;
import org.springframework.stereotype.Component;
import org.springframework.web.server.ServerWebExchange;
import reactor.core.publisher.Mono;

@Component
public class JwtAuthenticationFilter extends AbstractGatewayFilterFactory<JwtAuthenticationFilter.Config> {

    public JwtAuthenticationFilter() {
        super(Config.class);
    }

    @Override
    public GatewayFilter apply(Config config) {
        return (exchange, chain) -> {
            ServerHttpRequest request = exchange.getRequest();
            String token = request.getHeaders().getFirst("Authorization");
            
            // 这里添加你的身份验证逻辑
            if (token == null || !isValidToken(token)) {
                ServerHttpResponse response = exchange.getResponse();
                response.setStatusCode(HttpStatus.UNAUTHORIZED);
                return response.setComplete();
            }

            return chain.filter(exchange);
        };
    }

    public boolean isValidToken(String token) {
        // 这里添加验证JWT令牌的逻辑
        // 例如，使用JWT库解析token，并验证签名、过期时间等
        return true;
    }

    public static class Config {
        // 可以添加配置属性
    }
}
```

在上面的代码中，`JwtAuthenticationFilter`类继承了`AbstractGatewayFilterFactory`，并重写了`apply`方法来实现自定义的过滤逻辑。如果请求头中没有有效的JWT令牌，过滤器将返回401未授权状态。

接下来，你需要将这个过滤器添加到Spring Cloud Gateway的路由配置中：

```yaml
spring:
  cloud:
    gateway:
      routes:
        - id: your_route_id
          uri: http://your-service-uri
          predicates:
            - Path=/your-service/**
          filters:
            - name: JwtAuthenticationFilter
```

在这个配置中，`your_route_id`是路由的ID，`your-service-uri`是目标服务的URI，`your-service/**`是匹配路径。`- name: JwtAuthenticationFilter`表示将自定义的`JwtAuthenticationFilter`应用到这个路由上。

请注意，这只是一个简单的示例，实际的身份验证逻辑会更复杂，可能需要与用户服务进行交互验证令牌的有效性，处理令牌刷新等。此外，你可能还需要考虑安全性问题，比如使用HTTPS来保护令牌在传输过程中的安全。

### 如何配置Spring Cloud Gateway以支持OAuth2认证？

要在Spring Cloud Gateway中配置OAuth2认证，你需要使用Spring Security OAuth2客户端库，并结合Spring Cloud Gateway的内置安全功能。以下是一个基本的配置步骤，用于在Spring Cloud Gateway中集成OAuth2认证：

1. **添加依赖**：
    确保你的项目中包含了Spring Cloud Gateway和Spring Security OAuth2的依赖。对于Maven项目，添加如下依赖：

    ```xml
    <dependency>
        <groupId>org.springframework.cloud</groupId>
        <artifactId>spring-cloud-starter-gateway</artifactId>
    </dependency>
    <dependency>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-security</artifactId>
    </dependency>
    <dependency>
        <groupId>org.springframework.security</groupId>
        <artifactId>spring-security-oauth2-client</artifactId>
    </dependency>
    ```

2. **配置OAuth2客户端**：
    在`application.yml`或`application.properties`中配置OAuth2客户端信息。这包括客户端ID、客户端密钥、认证服务器的地址等。

    ```yaml
    spring:
      security:
        oauth2:
          client:
            registration:
              my-oauth2:
                clientId: your-client-id
                clientSecret: your-client-secret
                clientName: My OAuth2 Client
                authorizationGrantType: authorization_code
                redirectUri: "{baseUrl}/login/oauth2/code/{registrationId}"
                scope: read,write
                clientAuthenticationMethod: post
            provider:
              my-oauth2:
                authorizationUri: https://your-auth-server.com/oauth/authorize
                tokenUri: https://your-auth-server.com/oauth/token
                userInfoUri: https://your-auth-server.com/userinfo
                userNameAttribute: name
    ```

    在上面的配置中，`my-oauth2`是注册的OAuth2客户端的ID，你需要根据实际情况替换为你的客户端ID和密钥等信息。

3. **配置路由**：
    在Spring Cloud Gateway中配置路由规则，指定需要进行OAuth2认证的路由。

    ```yaml
    spring:
      cloud:
        gateway:
          routes:
            - id: my-service-route
              uri: http://localhost:8081
              predicates:
                - Path=/my-service/**
              filters:
                - name: OAuth2Client
                  args:
                    name: my-oauth2
    ```

    在这个配置中，`OAuth2Client`过滤器被添加到路由中，`name`参数指定了之前配置的OAuth2客户端ID。

4. **配置安全策略**：
    如果需要，可以进一步配置安全策略，例如要求特定的权限或角色才能访问某些路由。

    ```java
    @Configuration
    public class SecurityConfig extends WebSecurityConfigurerAdapter {
        @Override
        protected void configure(HttpSecurity http) throws Exception {
            http
                .authorizeRequests()
                .antMatchers("/my-service/**").authenticated() // 仅认证用户可以访问
                .and()
                .oauth2Login(); // 使用OAuth2登录
        }
    }
    ```

5. **启动应用并测试**：
    启动你的Spring Cloud Gateway应用，并访问配置的路由，检查是否能够正确地重定向到OAuth2认证服务器进行认证。

通过以上步骤，你可以在Spring Cloud Gateway中配置OAuth2认证，从而保护你的微服务路由。请注意，根据你的认证服务器和具体需求，可能需要调整配置细节。此外，确保你的认证服务器支持你所使用的OAuth2流程（如授权码流程）。

### 如何在Spring Cloud Gateway中配置Sentinel限流规则？

在Spring Cloud Gateway中配置Sentinel限流规则通常涉及以下几个步骤：

1. **添加依赖**：
   首先确保你的项目中包含了Spring Cloud Gateway和Sentinel的依赖。对于Maven项目，添加如下依赖：

   ```xml
   <dependency>
       <groupId>com.alibaba.cloud</groupId>
       <artifactId>spring-cloud-starter-alibaba-sentinel</artifactId>
   </dependency>
   <dependency>
       <groupId>com.alibaba.csp</groupId>
       <artifactId>sentinel-spring-cloud-gateway-adapter</artifactId>
   </dependency>
   ```

2. **配置Sentinel**：
   在`application.yml`或`application.properties`中配置Sentinel，包括连接到Sentinel控制台的地址：

   ```yaml
   spring:
     cloud:
       sentinel:
         transport:
           dashboard: localhost:8080 # Sentinel 控制台地址
         eager: true # 启动时加载限流规则
   ```

3. **定义限流规则**：
   你可以通过编程方式定义限流规则，也可以通过配置文件定义。这里以编程方式为例，创建一个配置类来定义规则：

   ```java
   @Configuration
   public class SentinelConfiguration {
       private final List<GatewayFlowRule> gatewayFlowRules = new ArrayList<>();
   
       @PostConstruct
       public void init() {
           // 定义一个限流规则，限制对某个路由的访问
           GatewayFlowRule flowRule = new GatewayFlowRule("your_route_id");
           flowRule.setCount(1); // 设置每秒最多通过1个请求
           flowRule.setIntervalSec(1); // 时间窗口为1秒
           gatewayFlowRules.add(flowRule);
       }
   
       @Bean
       @Primary
       public SentinelGatewayBlockRuleManager sentinelGatewayBlockRuleManager() {
           return new SentinelGatewayBlockRuleManager() {
               @Override
               public void loadRules(List<GatewayFlowRule> rules) {
                   gatewayFlowRules.addAll(rules);
               }
           };
       }
   }
   ```

   在上面的代码中，`your_route_id`是你的路由ID，你需要根据实际情况替换。`count`和`intervalSec`定义了限流的规则，即每秒最多允许通过的请求数量和时间窗口。

4. **启动Sentinel控制台**：
   为了能够动态地管理限流规则，你需要启动Sentinel控制台。Sentinel控制台允许你通过图形界面实时查看流量情况，并动态调整限流规则。

5. **启动应用并测试**：
   启动你的Spring Cloud Gateway应用，并通过访问不同的路由来测试限流是否生效。

通过以上步骤，你可以在Spring Cloud Gateway中成功配置Sentinel限流规则。Sentinel提供了强大的流量控制和熔断功能，可以有效地保护你的微服务架构，防止因流量过大导致的服务不可用。

## 分布式消息中间件

rabbitMQ 3 台 

### rabbitMQ 在项目中的作用

- 异步调用：项目中存在短时间内出现大量耗费内存和时间的请求，比如生成报表文件、任务自动下发、数据自动推送等场景，这些功能如果在短时间内大量实时处理，那么服务器可能会无法承受导致宕机，而这些功能实时性要求不高，就考虑使用消息中间件来异步处理。在生成消息的时候需要为每一个消息生成一个唯一且有序的 ID，在 redis 中维护该 ID 的执行状态，在消费消息的时候加分布式锁并判断任务 ID 的执行状态，同时将接口设计为幂等接口，避免因为消息超时而引发的重复消费。同时应记录消息被消费的次数和消费状态，当消费一直失败达到阈值时，发出告警邮件并通知人工处理。

### 为什么选择 rabbitMQ 作为消息中间件

springCloud strem 支持的消息中间件目前就仅有 rabbitMQ 和 kafka ，而系统用不到 kafka 那么大的访问量，也是从成本考虑吧

## 流量控制

sentinel 实现服务限流和熔断降级，并将规则持久化到 MySQL 中，避免服务崩溃后丢失

### 在什么业务中或场景下需要使用 sentinel

1. 当调用服务频繁超时，说明目标服务压力过大或已宕机，则可降级运行，避免服务雪崩

### @sentinelResource 自定义规则

`@SentinelResource` 是在使用 Sentinel 进行微服务流量控制和熔断时，用于定义资源的一个注解。在 Java 应用程序中，特别是在使用 Spring Cloud 或其他微服务框架时，`@SentinelResource` 注解用于标记某个方法或代码块作为 Sentinel 的资源点，这样 Sentinel 就可以对这些资源进行监控和管理。

使用 `@SentinelResource` 注解可以实现以下功能：

1. **资源定义**：通过注解，开发者可以明确指定哪些方法或代码段需要被 Sentinel 监控。每个被 `@SentinelResource` 标记的方法或代码块代表一个资源。

2. **流控规则**：可以为标记的资源设置流控规则，例如限制某个接口的访问频率，当达到设定的阈值时，触发流控，防止系统过载。

3. **降级规则**：可以为资源设置降级规则，当资源访问异常或响应时间过长时，可以触发降级逻辑，比如返回默认值或错误信息，以保护系统稳定。

4. **自定义处理逻辑**：`@SentinelResource` 注解允许开发者指定一个 `blockHandler` 方法，当资源被流控或降级时，会调用这个方法进行处理。同时，还可以指定 `fallback` 方法，用于处理资源执行过程中抛出的异常。

5. **异常处理**：通过 `@SentinelResource` 注解，可以对资源执行过程中抛出的异常进行分类处理，比如区分业务异常和系统异常，分别进行不同的处理策略。

6. **链路追踪**：Sentinel 还支持链路追踪功能，通过 `@SentinelResource` 注解标记的资源可以被整合到链路追踪系统中，方便问题定位和性能分析。

下面是一个简单的 `@SentinelResource` 注解使用示例：

```java
import com.alibaba.csp.sentinel.annotation.SentinelResource;
import com.alibaba.csp.sentinel.slots.block.BlockException;

public class YourService {

    @SentinelResource(value = "yourResource", blockHandler = "handleBlock", fallback = "fallbackMethod")
    public String yourMethod(String param) {
        // 业务逻辑
        return "Success";
    }

    public String handleBlock(String param, BlockException ex) {
        // 流控或降级时的处理逻辑
        return "Blocked by Sentinel";
    }

    public String fallbackMethod(String param, Throwable e) {
        // 异常时的处理逻辑
        return "Fallback due to exception";
    }
}
```

在这个例子中，`yourMethod` 方法被标记为一个 Sentinel 资源。当该方法因为流控或降级被 Sentinel 拦截时，会调用 `handleBlock` 方法；如果在执行 `yourMethod` 过程中抛出异常，则会调用 `fallbackMethod` 方法。

通过使用 `@SentinelResource` 注解，开发者可以非常方便地对微服务的关键资源进行流量控制和熔断处理，从而提高系统的稳定性和可用性。



## redis 集群

哨兵模式 ＋ 一主多从 ＋ 多集群模式

### redis 在项目中的作用

1. 作为分布式缓存，缓存一些不常变化的数据，提高系统体验，减少数据库压力


## 登录

常规登录 （第三方） OAuth 2.0 + JWT ＋ session + redis
应急登录 session ＋ redis

## 权限设计

基于 RBAC 设计，自定义权限实现 ＋ 权限框架 Spring Security

## 多数据源的数据一致性

没有使用分布式事务，有对账程序 ＋ 人工数据补录

消息中间件 ＋ 最终一致性 ＋ 失败告警邮件 ＋ 手工干预

采用 SAGA 事务模型

1. 假如有多个阶段提交操作，则将每个阶段看做是一个个单独的事物，且为每个单独的事物提供反向补偿机制，且提交和补偿都应是幂等的。
2. 由于事物系统本身也可能崩溃，所以需要将操作以方法调用日志的形式记录下来，比如在执行某个方法时应在方法进入时记录一条开始执行日志，在方法返回时记录一条方法结束日志，如果方法执行过程中程序崩溃，还可以通过调用日志来恢复数据。
3. 假如事物链有三个节点，则第一个节点失败则宣告直接失败。若第二个或第三个节点失败，则事物T1执行成功后：
  1. 调用T2过程中网络出现问题，则失败重试，重试三次仍失败后发送消息通知全部应用回滚事物，因为网路问题可分为调用未抵达和调用返回未抵达，很有可能下游应用以完成事物而返回丢失。
  2. 调用T2发现事物无法完成（余额不足），则T2在事物失败后，发送消息（MQ）并持久化到消息日志数据库，其他应用接到消息通知回滚，其他应用收到消息回滚成功后确认消费，直至全部应用回滚完成，若回滚过程中发生消息崩溃，则还存在消息日志记录。后台调度线程可定时扫描未完成的消息重新发送。

还需要考虑一个问题，就是在事物完成中间数据的脏读脏写问题，通常来说，脏写是一定要避免的，所有传统关系数据库在最低的隔离级别上都仍然要加锁以避免脏写，因为脏写情况一旦发生，人工其实也很难进行有效处理。所以 GTS 增加了一个“全局锁”（Global Lock）的机制来实现写隔离，要求本地事务提交之前，一定要先拿到针对修改记录的全局锁后才允许提交，没有获得全局锁之前就必须一直等待，这种设计以牺牲一定性能为代价，避免了有两个分布式事务中包含的本地事务修改了同一个数据，从而避免脏写。

在每个事物的参与者服务中都记录一张交易的流水记录表，一方面来保证交易的幂等性，另一方面在事物过程中如果失败，可以发送消息通知，根据交易流水表来进行反向补偿。但实际上这样是会有类似于脏读的情况的，例如在库存系统中，用户看到的库存没了，但可能一会又有了这种情况，但总体能接受，因为可以提升吞吐量

当然流水表会随着时间变得越来越大，那么可以做一个冷热数据分离存储的方案，例如一月的数据在以后是很少用到的。那么就可以启动一个定时任务，每月或每天将冷门数据迁移到ES或冷数据库中。



## 自动化投产

全栈云 ＋ k8s + DEVOPS

## ES 集群

物理机 ＋ 73 个数据节点

## 数据存储

MySQL ＋ Oracle 多数据源

## 全局唯一 ID

系统流水ID：雪花ID变种 ＋ ID 分段缓存 
业务数据ID：由业务提供规则，可配置方式生成

## 系统日志&链路监控

切面 ＋ 消息中间件（kafka）＋ ES 

## 零信任网络

## 集群监控以及预警

## 加强

Sentinel 、Netty

## 链路追踪

sofa-tracer 商业版阿里巴巴开源的分布式链路追踪系统
调用日志 由 filebeat 收集到 kafka 由 kafka 写入 ES 集群

## 分布式调度中心

xxl-job

xxl-job 是一个轻量级的调度平台，分为调度中心与客户端，调度中心是单独部署的一个服务，客户端即我们的应用服务器，当应用上线时将自动将自身注册到调度中心，调度中医依赖 MySQL 表悲观锁来保证任务在集群的执行情况，调度中心也可以高可用部署



## 微服务见内部鉴权的意义

防止外部调用一个中间阶段的接口
https://cloud.tencent.com/developer/article/1661115

微服务架构中，内部鉴权（内部服务之间的认证和授权）是非常重要的，它有助于确保服务之间的通信安全，防止未授权的访问和操作。以下是一些内部鉴权的意义和作用：

1. **保护服务资源**：每个微服务都可能拥有自己的资源和数据，内部鉴权可以确保只有经过授权的服务才能访问这些资源，从而保护服务的私有数据不被未授权访问。

2. **防止未授权调用**：通过内部鉴权，可以防止外部攻击者或未授权的内部服务调用敏感的内部接口。这在微服务架构中尤为重要，因为服务间的调用频繁且复杂。

3. **实现细粒度的访问控制**：内部鉴权可以实现细粒度的访问控制，即根据不同的用户角色和权限，控制对特定服务或服务方法的访问。这有助于实现最小权限原则，即只授予完成任务所必需的权限。

4. **增强服务间通信的安全性**：内部鉴权机制可以增强服务间通信的安全性，通过加密和签名等手段，确保数据在传输过程中的安全。

5. **支持合规性和审计**：内部鉴权可以记录详细的访问日志，这对于审计和合规性检查非常重要。在发生安全事件时，这些日志可以作为调查和取证的重要依据。

6. **提高系统的整体安全性**：通过内部鉴权，可以提高整个微服务系统的安全性，减少安全漏洞和攻击面，从而降低系统被攻击的风险。

7. **支持跨域和多租户架构**：在多租户或跨域的微服务架构中，内部鉴权可以帮助区分不同租户或域的数据和资源，确保数据隔离和安全。

8. **简化安全策略管理**：通过集中式的鉴权服务，可以简化安全策略的管理，使得安全规则的更新和维护更加方便。

在微服务架构中，内部鉴权通常通过API网关、服务网格（如Istio）、OAuth2.0、JWT（JSON Web Tokens）等机制实现。选择哪种机制取决于具体的业务需求、安全要求和系统复杂度。重要的是，内部鉴权应该与外部鉴权策略相结合，形成一个全面的安全防护体系。



内部鉴权的实现方式取决于具体的业务需求、系统架构和安全策略。在微服务架构中，内部鉴权可以采用分散在各个服务中的方式，也可以采用集中鉴权中心的方式，或者两者结合使用。下面分别介绍这两种方式的优缺点：

### 分散在各个服务中

**优点**:
- **自主性**: 每个服务可以独立控制自己的访问策略，不需要依赖外部系统。
- **灵活性**: 服务可以根据自己的业务逻辑和安全需求定制鉴权规则。
- **容错性**: 即使某个服务的鉴权机制出现问题，也不会影响到其他服务。

**缺点**:
- **复杂性**: 每个服务都需要实现鉴权逻辑，增加了开发和维护的复杂性。
- **一致性**: 需要确保所有服务的鉴权策略保持一致，否则可能会导致安全漏洞。
- **维护成本**: 鉴权逻辑分散在各个服务中，增加了维护和更新鉴权策略的难度。

### 集中鉴权中心

**优点**:
- **统一管理**: 所有服务的鉴权逻辑集中在一个地方，便于管理和维护。
- **一致性**: 集中鉴权可以确保所有服务的鉴权策略保持一致，减少安全漏洞。
- **扩展性**: 新服务加入时，可以轻松地接入集中鉴权系统，无需重新实现鉴权逻辑。

**缺点**:
- **单点故障**: 集中鉴权中心成为系统的单点故障点，一旦出现问题，可能影响到所有服务。
- **性能瓶颈**: 所有鉴权请求都需要经过鉴权中心，可能会成为系统的性能瓶颈。
- **复杂性**: 需要设计和实现一个高可用、高性能的鉴权中心。

### 结合使用

在实际应用中，很多系统会结合使用分散和集中鉴权的方式。例如，可以将鉴权逻辑的某些通用部分（如用户身份验证、令牌验证等）集中到鉴权中心，而将与业务逻辑紧密相关的鉴权规则保留在各个服务中。这种方式既保证了鉴权策略的一致性和集中管理，又保留了服务的灵活性和自主性。

最终选择哪种方式，需要根据系统的规模、业务复杂度、团队的技术栈和运维能力等因素综合考虑。在设计鉴权策略时，应确保鉴权机制既安全又高效，同时便于维护和扩展。



分布式鉴权中心通常负责处理用户身份认证和授权决策。用户身份认证是确保用户身份真实性的过程，通常涉及以下几个步骤：

1. **用户身份验证**：
   - 用户通过登录界面输入用户名和密码。
   - 鉴权中心接收到这些凭据后，与存储在数据库或目录服务中的用户信息进行比对。
   - 如果凭据匹配，用户身份验证成功；否则，验证失败。

2. **多因素认证**（可选）：
   - 为了增强安全性，除了用户名和密码之外，还可以要求用户提供额外的验证因素，如短信验证码、电子邮件链接、生物识别信息等。

3. **生成令牌**：
   - 用户身份验证成功后，鉴权中心生成一个令牌（如JWT、OAuth令牌等），该令牌包含了用户的身份信息和权限声明。
   - 令牌通常会被加密和签名，以确保其安全性和完整性。

4. **令牌分发**：
   - 鉴权中心将生成的令牌返回给用户，用户在后续的请求中携带这个令牌进行身份验证和授权。

5. **令牌验证**：
   - 用户在访问受保护的资源时，会将令牌附加在请求中。
   - 服务端接收到请求后，会将令牌发送到鉴权中心进行验证。
   - 鉴权中心验证令牌的有效性，包括检查签名、令牌是否过期、令牌是否被撤销等。

6. **授权决策**：
   - 如果令牌验证成功，鉴权中心会根据令牌中的权限声明和用户的角色信息，做出授权决策。
   - 授权决策决定了用户是否有权限访问请求的资源。

7. **令牌刷新**（可选）：
   - 为了防止令牌被长期使用，可以设置令牌的过期时间。
   - 用户可以在令牌过期前请求刷新令牌，鉴权中心会生成一个新的令牌，并废除旧的令牌。

8. **令牌撤销**：
   - 如果用户登出或令牌被泄露，鉴权中心可以撤销令牌，防止未授权的访问。

分布式鉴权中心通常需要具备高可用性和扩展性，以应对高并发的认证请求。此外，鉴权中心还需要与服务发现、负载均衡、API网关等组件协同工作，以实现整个分布式系统的安全访问控制。


鉴权中心的作用，认证用户身份，刷新令牌，令牌回收等

# 补充

1. 设计并开发系统公共组件，如方法拦截器与基于拦截器的参数校验、异步任务、方法限流等功能
2. 明细与指标类报表的数据展示与修改
3. 报表配置的设计与开发

