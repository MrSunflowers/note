# 关系型数据库

## MySQL

### 查询优化

https://blog.csdn.net/weixin_30342639/article/details/105348038

https://blog.csdn.net/weixin_30342639/article/details/110300394

#### 分页查询优化

  因为PageHelper对于MySQL的分页逻辑采用的是SQL后面追加limit子句的方式，这样在小数据量情况下是没有问题的。但是对于大数据量的时候，比如limit 100000, 10，MySQL的运作机理是查出100010条数据，再抛弃掉前100000条，留下剩余10条数据。所以执行效率并不高。

1. 根据自增且连续的主键排序查询

```sql
EXPLAIN select * from employees limit 90000,5;
```

```sql
EXPLAIN select * from employees where id > 90000 limit 5;
```

这种方式有两个限制：**主键必须是自增且连续的，而且结果是按照主键进行排序的**。

从执行计划上可以看到使用了范围索引，但是正如上面所说，该种情况的要求还是比较严格的，在很多场景并不实用，因为实际情况下可能中间的数据被删除了导致主键不再连续，这样查询出的结果和实际有差别。

2. 根据非主键字段排序查询

```sql
EXPLAIN select * from employees ORDER BY name limit 90000,5;
```

可以看到并没有使用索引，而且使用到了文件排序。MySQL优化器会内部进行判断，如果发现全表扫描的成本要低于走索引，那么就不会使用索引。改用下面的方式：

```sql
EXPLAIN select * from employees e inner join (select id from employees order by name limit 90000,5) ed on e.id = ed.id;
```

从执行计划上可以看到会先执行子查询，而子查询因为查的是主键id，所以会走覆盖索引。然后再根据id查外面的查询。因为分页的话一页一般都是10条数据，最多也就50条，数据量很小，所以外查询的效率也并不低。

#### 关联查询优化

- 关联字段要加上索引。
- 小标驱动大表，如果left join和inner join都能达到需求的话，尽量使用inner join，让MySQL优化器去判断谁是小表，因为大部分情况下mysql优化器是比人要聪明的。

#### in 和 exsits 优化

in：当B表的数据量小于A表的数据量时，in 优于 exists

```sql
select * from A where id in (select id from B)
```

exists：当 A 表的数据量小于 B 表的数据量时，exists 优于 in

```sql
select * from A where exists (select 1 from B where B.id = A.id)
```

#### count 查询优化

```sql
EXPLAIN select count(1) from employees;
EXPLAIN select count(id) from employees;
EXPLAIN select count(name) from employees;
EXPLAIN select count(*) from employees;
```

可以看到四种sql的执行计划都是一样的，说明这四种sql的效率应该是差不多的。区别是如果使用第三种根据某个非主键字段进行count的话，需要留意该字段是否有null值，该种方式是不会统计null值的数量的，而其它三种会统计。

这里可能会对第二种方式有些疑惑，为什么根据主键进行count查找不会走主键索引而走了二级索引？原因是因为二级索引B+树的叶子节点上只会保存指向主键索引B+树上的主键的指针，而主键索引B+树上叶子节点会存放所有这行的数据。二级索引相比于主键索引数据量会更少，理论上来说检索的性能会更高。

对于SELECT COUNT(1)和SELECT COUNT(*)这两种查询，它们在大多数情况下是等价的，因为MySQL内部会将COUNT(*)优化为COUNT(1)。这意味着它们通常会有相同的执行计划。

尽管在大多数情况下COUNT(*)和COUNT(1)在执行计划上是相同的，但理论上，COUNT(1)可能会稍微快一点，因为它明确指定了一个常量值，而COUNT(*)需要计算所有列。然而，这种差异通常非常微小，几乎可以忽略不计。

### mysql 的存储引擎类型及其区别

1. **InnoDB**（默认存储引擎）
   - 支持事务处理，提供ACID（原子性、一致性、隔离性、持久性）特性。
   - 支持行级锁定，适合高并发的事务处理。
   - 支持外键约束，保证数据的完整性。
   - 支持MVCC（多版本并发控制），提高读写性能。
   - 适用于OLTP（在线事务处理）系统，如电子商务、银行系统等。

2. **MyISAM**
   - 不支持事务处理。
   - 支持表级锁定，适合读操作多、写操作少的场景。
   - 不支持外键约束。
   - 适用于OLAP（在线分析处理）系统，如数据仓库、报表系统等。
   - 由于不支持事务，所以执行速度较快。

3. **MEMORY**（也称为HEAP）
   - 数据存储在内存中，读写速度非常快。
   - 不支持事务处理。
   - 支持表级锁定。
   - 适用于临时数据存储，如缓存、会话数据等。
   - 数据在重启后会丢失。

4. **ARCHIVE**
   - 用于存储大量数据，但不经常访问的数据。
   - 支持数据压缩，节省存储空间。
   - 不支持索引，只支持插入和查询操作。
   - 适用于日志记录、历史数据存储等场景。

5. **CSV**
   - 数据以CSV格式存储，可以被Excel等电子表格软件直接读取。
   - 不支持索引，查询性能较低。
   - 适用于数据交换和数据迁移。

6. **BLACKHOLE**
   - 用于数据的黑洞存储，所有写入的数据都会被丢弃。
   - 不存储数据，但可以记录日志。
   - 适用于测试和日志记录。

7. **FEDERATED**
   - 允许MySQL服务器访问远程数据库。
   - 不存储数据，而是作为远程数据库的代理。
   - 适用于分布式数据库系统。

8. **NDB（也称为NDBCLUSTER）**
   - 用于MySQL集群，提供高可用性和高性能。
   - 支持数据的自动复制和分片。
   - 适用于需要高可用性和高并发的应用。

### 锁

客户端发往 MySQL 的一条条 SQL 语句，实际上都可以理解成一个个单独的事务（一条sql语句默认就是一个事务）。而事务是基于数据库连接的，每个数据库连接在MySQL中，又会用一条工作线程来维护，也意味着一个事务的执行，本质上就是一条工作线程在执行，当出现多个事务同时执行时，这种情况则被称之为并发事务，所谓的并发事务也就是指多条线程并发执行。

多线程并发执行自然就会出问题，也就是脏写、脏读、不可重复读及幻读问题。而对于这些问题又可以通过调整事务的隔离级别来避免，不同的隔离级别中，工作线程执行SQL语句时，用的锁粒度、类型不同。

**锁分类**

MySQL 的锁机制与索引机制类似，都是由存储引擎负责实现的，这也就意味着不同的存储引擎，支持的锁也并不同，这里是指不同的引擎实现的锁粒度不同。但除开从锁粒度来划分锁之外，其实锁也可以从其他的维度来划分，因此也会造出很多关于锁的名词，下面先简单梳理一下 MySQL 的锁体系：

- 以锁粒度的维度划分
  - 全局锁：锁定数据库中的所有表。加上全局锁之后，整个数据库只能允许读，不允许做任何写操作
  - 表级锁：每次操作锁住整张表。主要分为三类
    - 表锁（分为表共享读锁 read lock、表独占写锁 write lock）
    - 元数据锁（meta data lock，MDL）：基于表的元数据加锁，加锁后整张表不允许其他事务操作。这里的元数据可以简单理解为一张表的表结构
    - 意向锁（分为意向共享锁、意向排他锁）：这个是InnoDB中为了支持多粒度的锁，为了兼容行锁、表锁而设计的，使得表锁不用检查每行数据是否加锁，使用意向锁来减少表锁的检查
  - 行级锁：每次操作锁住对应的行数据。主要分为三类
    - 记录锁 / Record 锁：也就是行锁，一条记录和一行数据是同一个意思。防止其他事务对此行进行update和delete，在 RC、RR隔离级别下都支持
    - 间隙锁 / Gap 锁：锁定索引记录间隙（不含该记录），确保索引记录间隙不变，防止其他事务在这个间隙进行insert，产生幻读。在RR隔离级别下都支持
    - 临键锁 / Next-Key 锁：间隙锁的升级版，同时具备记录锁+间隙锁的功能，在RR隔离级别下支持
- 以互斥性的角度划分
  - 共享锁 / S锁：不同事务之间不会相互排斥、可以同时获取的锁
  - 排他锁 / X锁：不同事务之间会相互排斥、同时只能允许一个事务获取的锁
  - 共享排他锁 / SX锁：MySQL5.7 版本中新引入的锁，主要是解决SMO带来的问题
- 以操作类型的维度划分
  - 读锁：查询数据时使用的锁
  - 写锁：执行插入、删除、修改、DDL语句时使用的锁
- 以加锁方式的维度划分
  - 显示锁：编写SQL语句时，手动指定加锁的粒度
  - 隐式锁：执行SQL语句时，根据隔离级别自动为SQL操作加锁
- 以思想的维度划分
  - 乐观锁：每次执行前认为自己会成功，因此先尝试执行，失败时再获取锁
  - 悲观锁：每次执行前都认为自己无法成功，因此会先获取锁，然后再执行

放眼望下来，是不是看着还蛮多的，但总归说来说去其实就共享锁、排他锁两种，只是加的方式不同、加的地方不同，因此就演化出了这么多锁的称呼。

**共享锁与排他锁**

共享锁（S锁）

一个事务已获取共享锁，当另一个事务尝试对具备共享锁的数据进行读操作时，可正常读；进行写操作时，会被共享锁排斥。

> 事务T1对ID=18的数据加了一个共享锁，此时事务T2、T3也来读取ID=18的这条数据，这时T2、T3是可以获取共享锁执行的；但此刻又来了一个事务T4，它则是想对ID=18的这条数据执行修改操作，此时共享锁会出现排斥行为，不允许T4获取锁执行。

在MySQL中，我们可以在SQL语句后加上相关的关键字来使用共享锁，语法如下：

```sql
SELECT ... LOCK IN SHARE MODE;
-- MySQL8.0之后也优化了写法，如下：
SELECT ... FOR SHARE;
```

这种通过在SQL后添加关键字的加锁形式，被称为显式锁，而实际上为数据库设置了不同的事务隔离级别后，MySQL也会对SQL自动加锁，这种形式则被称之为隐式锁。

排他锁（X锁）

当一个线程获取到独占锁后，会排斥其他线程（进行读写操作），如若其他线程也想对共享资源/同一数据进行操作，必须等到当前线程释放锁并竞争到锁资源才行。

> 值得注意的一点是：**排他锁并不是只能用于写操作，对于一个读操作，咱们也可以手动地指定为获取排他锁，当一个事务在读数据时，获取了排他锁，那当其他事务来读、写同一数据时，都会被排斥**。比如事务T1对ID=18的这条数据加了一个排他锁，此时T2来加排他锁读取这条数据，T3来修改这条数据，都会被T1排斥。

在MySQL中，可以通过如下方式显式获取独占锁：

```sql
SELECT ... FOR UPTATE;
```

**MySQL 中锁的释放**

其实MySQL中释放锁的动作都是隐式的，毕竟如果交给咱们来释放，很容易由于操作不当造成死锁问题发生。因此对于锁的释放工作，MySQL自己来干，就类似于JVM中的GC机制一样，把内存释放的工作留给了自己完成。

但对于锁的释放时机，在不同的隔离级别中也并不相同，比如在“读未提交”级别中，是SQL执行完成后就立马释放锁；而在“可重复读”级别中，是在事务结束后才会释放。

> 如果完全按照数据库规范来实现RC隔离级别，为了保证其他事务可以读到未提交的数据，那就必须得在SQL执行完成后，立马释放掉锁，这时另一个事务才能读到SQL对应写的数据，但在InnoDB引擎中，它基于MVCC机制实现了该效果，为此，InnoDB的RC级别中，SQL执行结束后并不会释放锁。

#### 全局锁

全局锁就是对整个数据库实例加锁，加锁后整个实例就处于只读状态，后续的DML的写语句，DDL语句，已经更新操作的事务提交语句都将被阻塞。

其典型的使用场景是做全库的逻辑备份，对所有的表进行锁定，从而获取一致性视图，保证数据的完整性。

```sql
# 加全局锁、获取全局锁
flush tables with read lock;  

# 数据备份。具体指令可见 
mysqldump -u 用户名 -p 数据库名 > /back/backup.sql

# 释放全局锁
unlock tables;
```

数据库中加全局锁，是一个比较重的操作，存在以下问题：

- 如果在主库上备份，那么在备份期间都不能执行更新，业务基本上就得停摆。
- 如果在从库上备份，那么在备份期间从库不能执行主库同步过来的二进制日志（binlog），会导致主从延迟。

在InnoDB引擎中，我们可以在备份时加上参数 --single-transaction 参数来完成不加锁的一致性数据备份。

```sql
mysqldump --single-transaction -uroot –p123456 test > backup.sql
```

#### 表级锁

表级锁，每次操作锁住整张表。锁定粒度大，发生锁冲突的概率最高，并发度最低。应用在MyISAM、InnoDB、BDB等存储引擎中。

#### 行级锁

行级锁，每次操作锁住对应的行数据。锁定粒度最小，发生锁冲突的概率最低，并发度最高。在MySQL诸多的存储引擎中，仅有InnoDB引擎支持行锁（不考虑那些闭源自研的），MyISAM等引擎不支持行锁，因为InnoDB支持聚簇索引——将数据存储与索引放到了一块，索引结构的叶子节点保存了行数据。InnoDB中如果能够命中索引数据，就会加行锁，无法命中则会加表锁。

### MySQL 可重复读的实现

InnoDB 引擎通过 MVCC 和 NEXT-KEY Locks，解决了在可重复读的事务隔离级别下出现幻读的问题。

下面先讲解 InnoDB 独有的三种锁，记录锁、间隙锁、临键锁

#### 记录锁

记录锁是基于主键索引或唯一索引记录上的锁，它锁定的行数是固定的、明确的，根据情况它可以是共享锁、排他锁。InnoDB通过索引记录来实现行级锁定。当事务需要锁定某行数据时，它实际上锁定的是索引记录。

这意味着，当事务执行加锁操作时，InnoDB 会尝试锁定索引记录，而不是锁定整行数据。这种基于索引的锁定机制可以显著减少锁定的范围，从而提高并发性能。

##### 退化为临键锁

```sql
-- id 列为主键列或唯一索引列
SELECT * FROM table WHERE id = 1 FOR UPDATE;　　
```
id 为 1 的记录行会被锁住。

需要注意的是：id 列必须为唯一索引列或主键列，否则上述语句加的锁就会变成临键锁。这是因为非唯一索引列允许有重复值，InnoDB 需要防止在相同索引值的其他行上发生幻读。

同时查询语句必须为精准匹配（=），不能为 >、<、like等范围查询，否则也会退化成临键锁。

##### 退化为表锁

如果一个加锁操作**无法利用任何索引**，例如：

- 使用了全表扫描的查询（例如，没有 WHERE 条件或者 WHERE 条件无法利用索引）。
- 使用了不包含任何索引列的 SELECT ... FOR UPDATE 或者 SELECT ... LOCK IN SHARE MODE 语句。

在这种情况下，InnoDB 无法对特定的索引记录加锁，因此它会退化为表锁。表锁会锁定整个表，这会减少并发性，因为其他事务在表锁定期间无法对表中的任何行进行读写操作。

#### 间隙锁

间隙锁基于**非唯一索引**实现，它锁定一段范围内的索引记录。使用间隙锁锁住的是一个区间，而是这个区间中的数据。间隙锁主要用于锁定索引记录之间的间隙，而不是锁定具体的行。因此，如果事务 B 尝试向间隙内新增数据，将被间隙锁阻塞，如果事务 B 尝试更新间隙内已存在的某行数据，该操作通常不会被间隙锁阻止，除非该行数据的更新导致它跨越了间隙锁锁定的间隙范围。

间隙锁的目的是在RR级别下，防止幻读，幻读的产生是当前事务多次的查询结果数量上不一致，间隙锁的目的就是保证当前范围内的数据不会被更改，所以它会锁住某些个区间的数据。

想象一下，图书馆的书架上按照书名的字母顺序排列着各种书籍。间隙锁就像是在书架上预留出一个“间隙”，防止别人在这个间隙里插入新的书。

- **例子**：假设书架上书的顺序是这样的：A, C, D, F, G。现在你正在查找所有以"B"开头的书。虽然没有以"B"开头的书，但你担心有人会在这个间隙（B的位置）插入一本新的书。因此，你在这个位置放置了一个“间隙锁”，这样别人就不能在这个区间（A和C之间）插入新的书了。

#### 临键锁

临键锁是查询时 InnoDB 根据查询的条件而锁定的一个范围，这个范围中包含有间隙锁和记录锁；临键锁=间隙锁+记录锁。

其设计的目的是为了解决 Phantom Problem(幻读)，因此临键锁主要是阻塞的是 insert，但由于临键锁中包含有记录锁，因此临键锁所锁定的范围内如果包含有记录，那么也会给这些记录添加记录锁，从而造成阻塞除 insert 之外的操作；

临键锁的主要目的，也是为了避免幻读(Phantom Read)。**如果把事务的隔离级别降级为RC，临键锁则也会失效。**

每个数据行上的**非唯一索引列**上都会存在一把临键锁，当某个事务持有该数据行的临键锁时，会锁住一段左开右闭区间的数据。需要强调的一点是，InnoDB 中行级锁是基于索引实现的，临键锁只与非唯一索引列有关，在唯一索引列（包括主键列）上不存在临键锁。

假设有如下表：
MySql，InnoDB，Repeatable-Read：table(id PK, age KEY, name)

| id | age | name   |
|----|-----|--------|
| 1  | 10  | Lee    |
| 3  | 24  | Soraka |
| 5  | 32  | Zed    |
| 7  | 45  | Talon  |

该表中 age 列潜在的临键锁有：

(-∞, 10],
(10, 24],
(24, 32],
(32, 45],
(45, +∞],

在事务 A 中执行如下命令：

```sql
-- 根据非唯一索引列 UPDATE 某条记录
UPDATE table SET name = Vladimir WHERE age = 24;
-- 或根据非唯一索引列 锁住某条记录
SELECT * FROM table WHERE age = 24 FOR UPDATE;
```

不管执行了上述 SQL 中的哪一句，之后如果在事务 B 中执行以下命令，则该命令会被阻塞：

```sql
INSERT INTO table VALUES(100, 26, 'Ezreal');
```

很明显，事务 A 在对 age 为 24 的列进行 UPDATE 操作的同时，也获取了 (24, 32] 这个区间内的临键锁。

不仅如此，在执行以下 SQL 时，也会陷入阻塞等待：

```sql
INSERT INTO table VALUES(100, 30, 'Ezreal');
```

那最终我们就可以得知，在根据非唯一索引 对记录行进行 UPDATE \ FOR UPDATE \ LOCK IN SHARE MODE 操作时，InnoDB 会获取该记录行的 临键锁 ，并同时获取该记录行下一个区间的间隙锁。

即事务 A在执行了上述的 SQL 后，最终被锁住的记录区间为 (10, 32)。

#### 总结

1. InnoDB 中的行锁的实现依赖于**索引**，一旦某个加锁操作没有使用到索引，那么该锁就会退化为表锁。
2. 记录锁存在于包括主键索引在内的**唯一索引**中，锁定单条索引记录。
3. 间隙锁存在于**非唯一索引**中，锁定开区间范围内的一段间隔，它是基于临键锁实现的。
4. 临键锁存在于**非唯一索引**中，该类型的每条记录的索引上都存在这种锁，它是一种特殊的间隙锁，锁定一段左开右闭的索引区间。

#### 多版本并发控制 （MVCC）

多版本并发控制（MVCC）和锁（Locking）是数据库管理系统中用于实现事务隔离和并发控制的两种不同机制。MVCC 主要用于提高并发读取的性能，而锁则用于处理并发写入时的数据一致性问题。

在数据库系统中，隔离级别是用来定义事务之间相互隔离的程度的。MySQL/InnoDB的默认隔离级别是可重复读（Repeatable Read），这个级别保证了在一个事务中多次读取同一数据的结果是一致的，即事务开始后，它读取到的数据不会因为其他并发事务的提交而改变。

在可重复读隔离级别下，InnoDB通过使用多版本并发控制（MVCC，Multi-Version Concurrency Control）机制来避免幻读问题。MVCC允许事务读取到事务开始时存在的数据版本，即使这些数据在事务执行过程中被其他事务修改或删除。因此，在只读事务中，即使其他事务插入了新数据，只读事务也不会看到这些新数据，从而避免了幻读。

然而，对于读写事务，情况就有所不同。如果一个事务在执行过程中需要读取其他事务可能修改的数据，那么就可能遇到幻读问题。幻读是指当一个事务在读取某个范围内的记录时，另一个并发事务插入了新的记录，当第一个事务再次读取该范围时，会看到之前不存在的“幻影”记录。

在MySQL/InnoDB中，即使在可重复读隔离级别下，读写事务在执行更新操作时，如果涉及到范围查询（如“所有小于100元的书”），仍然可能遇到幻读问题。这是因为更新操作需要确保它操作的数据在事务开始时就存在，如果在事务执行过程中有新的记录被插入到这个范围内，那么更新操作可能会影响到这些新记录，导致幻读。

为了防止幻读，可以使用更高级别的隔离级别，如串行化（Serializable），在这种隔离级别下，事务是完全串行执行的，从而避免了幻读和其他并发问题。但是，串行化隔离级别可能会显著降低数据库的并发性能。

在实际应用中，选择合适的隔离级别需要在保证数据一致性的同时，考虑到系统的并发性能和业务需求。对于读写事务，如果业务逻辑需要避免幻读，可能需要在应用层面或者通过其他机制（如使用锁）来确保数据的一致性。

InnoDB 里面每个事务都有一个唯一的事务 ID，叫作 transaction id。它在事务开始的时候向 InnoDB 的事务系统申请的，是按申请顺序严格递增的。而表中的每行数据也都是有多个版本的。每次事务更新数据的时候，都会生成一个新的数据版本，并且把 transaction id 赋值给这个数据版本的事务 ID，记为 row trx_id。同时，旧的数据版本要保留，并且在新的数据版本中，能够有信息可以直接拿到它。也就是说，数据表中的一行记录，其实可能有多个版本 (row)，每个版本有自己的 row trx_id。

表中的每行记录在更新的时候都会同时记录一条 undo log，这条 log 就会记录上当前事务的 transaction id，记为 row trx_id。记录上的最新值，通过回滚操作，都可以得到前一个状态的值。

在可重复读隔离级别下，一个事务在启动时，InnoDB 会为事务构造一个数组，用来保存这个事务启动瞬间，当前**正在”活跃“的所有事务ID**。”活跃“指的是，启动了但还没提交的事务。

这个数组里面事务 ID 为最小值记为低水位，**当前系统里面已经创建过的事务 ID 的最大值**加 1 记为高水位。

这个视图数组把所有的 row trx_id 分成了几种不同的情况。

- 如果当前读到的这行数据的 trx_id 小于低水位，表示这个版本的数据在当前事务启动前已经提交，是安全的，可见
- 如果当前读到的这行数据的 trx_id 大于高水位，表示这个版本的数据是在当前事务启动后生成的，不可见
- 如果当前读到的这行数据的 trx_id 大于低水位，小于高水位，分为两种情况
  - 如果当前读到的这行数据的 trx_id 在数组中，表示这个版本在当前事务启动时还未提交，不可见
  - 如果当前读到的这行数据的 trx_id 不在数组中，表示这个版本在当前事务启动时已经提交，可见

假设事务A, B, C 的 trx_id 分别为 100, 101, 102。事务 A 开始前活跃的事务 ID 只有 99，并且 id=1 这一行数据的 trx_id=90，数据 K = 1。假设 A,B,C 按顺序启动，得出事务启动瞬间的视图数组：事务A：[99, 100]，事务B：[99, 100, 101]，事务C：[99, 100, 101, 102]。此时进行如下操作：

1. 事务C通过更新语句，把 k 更新为 2，此时trx_id=102；
2. 事务B通过更新语句，把 k 更新为 3，此时trx_id=101；
3. 事务B通过查询语句，查询到最新一条记录为3，trx_id=101，满足隔离条件，返回 k=3；
4. 事务A通过查询语句：
   1. 查询到最新一条记录为3，trx_id=101，比高水位大，不可见；
   2. 通过 undo log，找到上一个历史版本，trx_id=102，比高水位大，还是不可见；
   3. 继续找上一个历史版本，trx_id=90，比低水位小，可见。

也就是说**事务B更新的时候是能看到事务C的修改的**

如果事务B在更新的看不到事务C的修改就会出问题：

1. 事务B查询到最新一条记录为2，trx_id=102，比高水位大，不可见；
2. 通过 undo log，找到上一个版本，trx_id=90，比低水位小，可见；
3. 返回记录 k=1，执行 k=k+1，把 k 更新为2，此时 trx_id=101。

此时事务B覆盖了事务C的更新，所以，InnoDB在更新时运用一条规则：**更新数据都是先读后写的，而这个读，只能读当前最新的值，称为“当前读“ （current read）**，因此，事务B在更新时要拿到最新的数据，在此基础上做更新。紧接着，事务B在读取的时候，查询到最新的记录为3， trx_id=101 为当前事务ID，可见

再假设另一种情况：

事务B在更新之后，事务C紧接着更新，事务B回滚了，事务C成功提交

如果按照当前读的定义，会发生以下事故，假设当前 K=1：

1. 事务B把 k 更新为 2；
2. 事务C读取到当前最新值，k=2，更新为3；
3. 事务B回滚；
4. 事务C提交。

这时候，事务C发现自己想要执行的是 +1 操作，结果变成了 ”+2“ 操作。

InnoDB 肯定不允许这种情况的发生，因此事务B在执行更新语句时，会给该行加上行锁，直到事务B结束，才会释放这个锁。

小结

1. InnoDB 的行数据有多个版本，每个版本都有 row trx_id。
2. 事务根据 undo log 和 trx_id 构建出满足当前隔离级别的一致性视图。
3. 可重复读的核心是一致性读，而事务更新数据的时候，只能使用当前读，如果当前记录的行锁被其他事务占用，就需要进入锁等待。

### 索引

索引的具体实现方式与数据库有关，不同的数据库管理系统（DBMS）可能会采用不同的数据结构和算法来实现索引，以优化查询性能和数据管理。

#### 索引的分类

在 InnoDB 存储引擎中，索引可以按照它们的特点分为两种主要类型：主键索引（Primary Index）和辅助索引（Secondary Index），主键索引和辅助索引都使用 B+ 树数据结构来实现。

##### 主键索引（一级索引）

主键索引是一种特殊的索引，它唯一标识表中的每一行记录。在InnoDB中，每张表必须有一个主键索引，如果表中没有显式定义主键，InnoDB 会自动选择一个**唯一的非空**列作为主键，或者创建一个隐藏的行 ID（称为聚簇索引）作为主键。

聚簇索引也叫聚集索引。并不是一种单独的索引类型，而是一种数据存储方式。虽然是使用 B+ 树数据结构，但实现细节有所不同。

- 在聚簇索引中，数据行本身存储在索引的叶子节点中。这意味着，当通过聚簇索引访问数据时，实际上是在访问数据行本身。而在B+树中，叶子节点通常存储数据的引用（如行指针或行ID），而不是数据行本身。
- 聚簇索引的索引键通常是表的主键，而B+树的索引键可以是任何列或列组合。
- 聚簇索引的索引键必须是唯一的，因为数据行是根据索引键的值排序的。而B+树的索引键可以是唯一的，也可以不是唯一的，这取决于索引的类型（唯一索引或非唯一索引）。

![img](https://raw.githubusercontent.com/MrSunflowers/images/main/note/images/202205171703423.png)

其余特点则与B＋树类似：

- 所有的非叶子结点可以看成是索引部分，节点中含有其子树中最大或最小的关键字
- 叶子节点中身依关键字大小自小到大顺序连接，形成一个有序的双向链表
- 查询必须最终查找到叶子节点

##### 辅助索引（二级索引）

- 辅助索引也称为非聚簇索引，它们是除了主键索引之外的其他索引。辅助索引的叶子节点存储了主键值和索引列的值，而不是整个数据行。
- 当通过辅助索引查询数据时，首先通过辅助索引找到主键值，然后使用主键值在主键索引中定位到完整的数据行。这种机制称为“回表”操作，它比直接通过主键索引查询要多一次查找。
- 主键索引可以单独存在，辅助索引不能单独存在，必须依附于主键索引

MySQL支持以下几种类型的辅助索引：

1. **普通索引（Normal Index）**：
   这是最基本的索引类型，它不包含任何特殊属性。普通索引可以加速基于索引列的查询，但不会强制列的唯一性。

2. **唯一索引（Unique Index）**：
   唯一索引确保索引列中的所有值都是唯一的，不允许有重复值。这可以用于确保数据的完整性，比如在用户表中，电子邮件地址可以设置为唯一索引，以防止重复注册。

3. **全文索引（Full-text Index）**：
   全文索引用于在文本字段中进行全文搜索。它允许对文本内容进行复杂的查询，如包含特定单词、短语或模式的文档。MySQL 5.6及以上版本支持全文索引。

4. 空间索引（Spatial Index）：
   空间索引用于优化对空间数据类型（如GEOMETRY或GEOGRAPHY）的查询。空间索引可以加速对地理信息的查询，如查找特定区域内的对象。

5. **组合索引（Composite Index）**：
   组合索引是基于表中两个或更多列创建的索引。在组合索引中，索引的顺序很重要，因为查询优化器会根据索引的顺序来优化查询。例如，如果创建了一个基于列A和列B的组合索引，那么查询条件中列A和列B的顺序必须与索引中定义的顺序一致，才能利用到索引。

6. 前缀索引（Prefix Index）：
   前缀索引是针对列值的前N个字符创建的索引。这在处理大型文本或BLOB类型数据时非常有用，可以减少索引的大小，提高性能。

7. 单列索引（Single-Column Index）：
   单列索引是基于单个列创建的索引。这是最简单的索引类型，适用于基于单个列的查询。

8. 多列索引（Multi-Column Index）：
   多列索引是基于两个或更多列创建的索引。它允许在多个列上进行查询优化，但同样需要注意列的顺序。

[(37条消息) MySQL的一级索引和二级索引介绍_无趣的人民艺术家的博客-CSDN博客_一级索引和二级索引](https://blog.csdn.net/weixin_43606861/article/details/116202806)

#### 索引的最左匹配原则

在MySQL中，如果是联合索引，当建立联合索引时，联合索引还是一颗B+树，比如建立一个联合索引(a, b),那么它的索引结构应该是这样的。

![](https://raw.githubusercontent.com/MrSunflowers/images/main/note/images/202205072115193.png)

a索引：1，1，2，2，3，3

b索引：1，2，1，4，1，2

通过观察可以发现，在联合索引中，对于a索引来说，索引是有序排列的，对于b索引是无序排列的。**同时还可以发现对于a值相等的情况下，b值也是有序的。**

这种有序是相对的，a>1 and b=4 遇到这种范围查询，就不会再去走索引，这种情况下a值可以走索引，而b值在这个范围内是无序的，所以最终也不会走索引。

那么就基本可以得出最左匹配原则的定义：最左优先，以最左边的为起点任何连续的索引都能匹配上。同时遇到范围查询(>、<、between、like) 就会停止匹配

例如建立一个索引

```sql
INDEX score_age_index (`score`, `age`)
```

**对于全值匹配来说**

```sql
select name from tb_student where age=20 and score=90;
```

查询会走索引，虽然定义索引的顺序是(score, age)，mysql 可以进行优化，自动帮我们改变顺序。

**对于单值来说**

```sql
select name from tb_student where score=90;
```

也是会走索引的，但是下面

```sql
select name from tb_student where age=19;
```

是不会走索引的，因为它并没有从最左连续匹配

**对于字符串类型来说**

它的比较规则是先比较字符串的第一个字符，第一个字符小的哪个字符串就比较小，如果两个字符串第一个字符相同，那就再比较第二个字符，第二个字符比较小的那个字符串就比较小，依次类推，比较字符串。

```sql
select * from tb_student  where a like 'As%'; //前缀都是排好序的，走索引查询
select * from tb_student  where  a like '%As'//全表查询
select * from tb_student  where  a like '%As%'//全表查询
```

**对于范围值来说**

可以对左边的列进行范围查询，结果是一定会走索引的。

```sql
select name from tb_student where score > 60 and score < 90;
```

多个列同时进行范围查找时，只有对索引左边的那个列进行范围查找才用到B+树索引，也就是只有score用到了索引，在90>score>60的情况下，age是无序的，不能用索引，找到90>score>60的记录后，只能根据条件 age>20 继续逐条过滤.

**对于精确匹配某一列并范围匹配另一列**

如果左边的列是精确查找的，右边的列可以进行范围查找，因为如果score=90，age是有序的

**排序**

```sql
select name from tb_student order by score,age;
```

因为b+树索引本身就是按照上述规则排序的，order by的子句后面的顺序也必须按照索引列的顺序给出，就会走索引。如果数据库中的数据量过小的时候，mysql数据库会自动为我们做优化，它会认为全表扫描要比索引更快，所以就采用全表扫描方式。

```sql
explain select name from tb_student order by age,score;
```

列的顺序反过来就不会走索引

如果最左边列的值是定值，则对其他列顺序排序是可以用到索引的。

#### InnoDB 的索引限制 16？

- 一个表的最大索引数量（非主键索引）为64个
- 复合索引最多可以包括16个列，超过会报错：ERROR 1070 (42000): Too many key parts specified; max 16 parts allowed

[限制](https://www.cnblogs.com/jackssybin/p/16258953.html)

### MySQL 的集群部署方案

MySQL集群部署方案是指在多个服务器上部署MySQL数据库，以实现高可用性、负载均衡和数据冗余。MySQL集群可以提高系统的稳定性和性能，同时确保数据的安全性和一致性。以下是几种常见的MySQL集群部署方案：

1. MySQL Replication（复制）

MySQL复制是一种简单的集群部署方案，它通过主从复制机制实现数据的同步。在这种方案中，一个服务器作为主服务器（Master），负责处理所有的写操作；其他服务器作为从服务器（Slaves），负责读操作和数据备份。

- **优点**：实现简单，成本较低，可以实现读写分离，提高读取性能。
- **缺点**：主服务器故障时，需要手动切换到新的主服务器，存在单点故障风险。

2. MySQL Cluster（NDB Cluster）

MySQL Cluster是MySQL官方提供的一个高可用性、高性能的集群解决方案，它使用NDB存储引擎，支持自动故障转移和数据冗余。

- **优点**：高可用性，自动故障转移，支持在线扩展。
- **缺点**：配置和管理相对复杂，需要专门的存储引擎（NDB）。

3. MySQL Group Replication

MySQL Group Replication是MySQL 5.7及以上版本引入的一种新的集群技术，它基于Paxos协议，允许多个节点组成一个复制组，实现数据的强一致性。

- **优点**：高可用性，自动故障转移，支持多主写入。
- **缺点**：配置和管理相对复杂，对网络要求较高。

4. ProxySQL + MySQL Replication

ProxySQL是一个高性能的MySQL代理，可以与MySQL Replication结合使用，实现负载均衡和故障转移。

- **优点**：通过ProxySQL可以实现读写分离，提高读取性能，同时可以实现自动故障转移。
- **缺点**：需要额外的ProxySQL服务器，增加了系统的复杂性。

5. Galera Cluster for MySQL

Galera Cluster是一个开源的多主复制集群解决方案，它支持MySQL和MariaDB数据库。Galera Cluster通过同步复制实现数据的实时同步。

- **优点**：高可用性，自动故障转移，支持多主写入。
- **缺点**：配置和管理相对复杂，对网络要求较高。

实施步骤：

1. **需求分析**：根据业务需求和系统规模，确定合适的集群方案。
2. **环境准备**：准备服务器硬件和操作系统环境。
3. **安装配置**：安装MySQL数据库和集群软件，进行配置。
4. **数据同步**：配置数据同步机制，如复制或集群同步。
5. **测试验证**：进行压力测试和功能测试，确保集群的稳定性和性能。
6. **监控部署**：部署监控系统，实时监控集群状态和性能指标。
7. **文档记录**：记录部署过程和配置细节，便于后续维护和故障排查。

选择合适的MySQL集群部署方案需要根据具体的应用场景、业务需求、预算和团队的技术能力来决定。每种方案都有其优势和局限性，需要综合考虑后做出决策。

## oracle

### oracle 中的表分区方式

范围分区、Hash分区、List分区、时间分区

## sql 的执行顺序

SQL语句的执行顺序通常遵循以下步骤，以`SELECT`语句为例：

1. **FROM**：首先，SQL引擎会处理`FROM`子句，确定查询的数据源，这可以是单个表、多个表的连接、子查询等。

2. **JOIN**：如果在`FROM`子句中使用了`JOIN`操作，那么会根据`JOIN`条件进行表的连接操作。

3. **ON**：在`JOIN`操作之后，会应用`ON`子句中的条件来过滤连接结果。

4. **WHERE**：接着，SQL引擎会处理`WHERE`子句中的条件，过滤掉不符合条件的行。

5. **GROUP BY**：如果使用了`GROUP BY`子句，那么会根据指定的列对结果集进行分组。

6. **HAVING**：在`GROUP BY`之后，如果使用了`HAVING`子句，那么会根据`HAVING`子句中的条件过滤分组后的结果。

7. **SELECT**：然后，SQL引擎会处理`SELECT`子句，确定最终返回哪些列。

8. **DISTINCT**：如果在`SELECT`子句中使用了`DISTINCT`关键字，那么会去除结果集中的重复行。

9. **ORDER BY**：最后，如果使用了`ORDER BY`子句，那么会根据指定的列对结果集进行排序。

10. **LIMIT/OFFSET**：在某些数据库系统中，可以使用`LIMIT`和`OFFSET`子句来限制返回的行数和指定返回结果的起始位置。

需要注意的是，不同的数据库系统可能会有细微的差别，例如在某些数据库中，`WHERE`子句可能在`GROUP BY`之后执行，或者`HAVING`子句在`ORDER BY`之后执行。此外，`SELECT`子句中的计算表达式和函数调用通常在`FROM`和`WHERE`子句之后执行。

在编写SQL语句时，了解这些执行顺序对于编写高效且正确的查询至关重要。例如，如果在`WHERE`子句中使用了聚合函数（如`COUNT`, `SUM`, `AVG`等），这通常会导致语法错误，因为聚合函数应该在`GROUP BY`之后使用。同样，如果在`SELECT`列表中使用了`ORDER BY`子句中未出现的列，这可能会导致意外的结果，因为`ORDER BY`子句是在`SELECT`子句之后执行的。

## drop、delete 与 truncate

在数据库操作中，`DROP`、`DELETE`和`TRUNCATE`都是用于删除数据的SQL命令，但它们在使用场景、执行方式和影响上有所不同。以下是它们之间的主要区别：

1. **DROP**：
   - `DROP`命令用于删除整个表或数据库。
   - 它会删除表结构及其所有数据。
   - `DROP`操作是不可逆的，一旦执行，表中的数据将永久丢失。
   - `DROP`操作会释放表所占用的存储空间。
   - 通常用于删除不再需要的表或数据库。
   - 示例：`DROP TABLE table_name;` 或 `DROP DATABASE database_name;`

2. **DELETE**：
   - `DELETE`命令用于删除表中的数据，但保留表结构。
   - 它可以删除表中的所有行或根据条件删除特定的行。
   - `DELETE`操作是可逆的，可以通过事务回滚来撤销。
   - `DELETE`操作不会释放表所占用的存储空间，除非表中没有数据。
   - 通常用于删除表中的特定数据或清理数据。
   - 示例：`DELETE FROM table_name WHERE condition;`

3. **TRUNCATE**：
   - `TRUNCATE`命令用于快速删除表中的所有数据，但保留表结构。
   - 它通过删除并重新创建表来实现，因此比`DELETE`操作快。
   - `TRUNCATE`操作是不可逆的，一旦执行，表中的数据将永久丢失。
   - `TRUNCATE`操作会释放表所占用的存储空间。
   - 通常用于删除大量数据时，需要快速清理表。
   - 示例：`TRUNCATE TABLE table_name;`

总结：
- `DROP`用于删除整个表或数据库。
- `DELETE`用于删除表中的数据，可以是全部或部分。
- `TRUNCATE`用于快速删除表中的所有数据，通常比`DELETE`快。

在选择使用哪种命令时，需要根据具体需求和数据的重要性来决定。如果需要删除整个表或数据库，或者需要快速删除大量数据，`TRUNCATE`可能是更好的选择。如果需要根据特定条件删除数据，或者需要保留事务回滚的能力，`DELETE`会是更合适的选择。而`DROP`则用于彻底删除表或数据库结构。

## 并发事务带来的问题

虽然并发事务可以提高数据库的性能和响应速度，但同时也可能带来一系列问题，这些问题通常被称为并发控制问题。以下是几个常见的并发事务带来的问题：

1. **脏读（Dirty Read）**：
   当一个事务读取了另一个事务尚未提交的数据时，就发生了脏读。如果第一个事务回滚，那么第二个事务读取的数据就是无效的。

2. **不可重复读（Non-Repeatable Read）**：
   在一个事务中，如果它两次读取同一数据项，但在这两次读取之间，另一个事务修改了该数据项并提交了更改，那么第一个事务就会读取到不同的值。这导致了数据的不一致。

3. **幻读（Phantom Read）**：
   幻读发生在当一个事务在执行两次相同的查询时，由于另一个事务在两次查询之间插入了新的数据行并提交了更改，导致第一个事务在第二次查询时看到了新的数据行。这与不可重复读类似，但关注的是数据行的增加，而不是数据值的改变。

4. **丢失更新（Lost Update）**：
   当两个或多个事务同时读取同一数据项，并且都尝试更新该数据项时，如果没有适当的并发控制机制，那么最后一个提交的事务可能会覆盖其他事务所做的更新，导致前面的更新丢失。

5. **写偏斜（Write Skew）**：
   写偏斜是更复杂的一种并发问题，它发生在两个事务读取了相关但不完全相同的数据集，并且基于这些读取结果做出决策，然后更新数据库。如果这些更新导致了违反了数据库的某些约束（如唯一性约束），那么就发生了写偏斜。

## 事务的隔离级别

事务的隔离级别是数据库管理系统（DBMS）中用于控制事务并发执行时数据一致性和隔离性的机制。不同的隔离级别提供了不同程度的隔离，以平衡并发性能和数据一致性之间的关系。SQL标准定义了以下四种隔离级别：

1. **读未提交（Read Uncommitted）**：
   这是最宽松的隔离级别。在该级别下，事务可以读取到其他事务未提交的数据（脏读）。这种隔离级别几乎不提供任何隔离，因此可能会导致数据不一致的问题。

2. **读已提交（Read Committed）oracle 默认**：
   在读已提交的隔离级别下，事务只能读取到其他事务已经提交的数据。这避免了脏读问题，但仍然可能发生不可重复读和幻读。这是许多数据库系统默认的隔离级别。

3. **可重复读（Repeatable Read）innoDB 默认**：
   在可重复读的隔离级别下，事务在读取数据时，其他事务对这些数据的修改不会影响当前事务的读取结果。这意味着在同一个事务中，对同一数据的多次读取将返回相同的结果。然而，这种隔离级别仍然允许幻读的发生。

4. **串行化（Serializable）**：
   串行化是最高级别的隔离级别。在该级别下，事务的执行效果与它们按照某种顺序串行执行时的效果相同。这意味着事务之间完全隔离，不会发生脏读、不可重复读和幻读。这种隔离级别虽然保证了数据的一致性，但可能会导致并发性能下降，因为事务需要排队执行。

## 分库分表的方案

垂直分库分表，水平分库分表，表分区等方案

### 分库分表后的数据一致性问题

- 在业务逻辑设计时，尽量避免跨库事务，减少对数据一致性的要求。
- 使用数据库中间件（如ShardingSphere、MyCAT等）来管理分库分表，中间件可以提供分布式事务支持，简化应用层的事务处理。
- 使用消息队列和分布式事务来保证数据的最终一致性

### 分库分表后的数据查询问题

以下是一些具体的策略和方法：

1. **分布式查询**：在分库分表的环境中，传统的单数据库查询已经不再适用。我们需要采用分布式数据库系统或中间件，如Apache Cassandra、Google Spanner等，这些系统能够处理跨多个数据库实例的查询。在实施分布式查询时，需要考虑如何将查询请求分解为多个子查询，发送到相应的数据库实例，并将结果合并返回给用户。

2. **数据聚合**：为了简化查询操作，可以建立一个数据仓库或使用ETL（Extract, Transform, Load）工具定期从各个分库中提取数据，进行汇总和聚合。这样，用户查询时可以直接访问数据仓库，避免了跨多个分库的复杂查询。

3. **应用层逻辑**：在应用层实现查询逻辑，可以有效减少数据库的直接查询压力。例如，可以使用缓存机制，如Redis或Memcached，来存储经常查询的数据，从而减少对数据库的直接访问。此外，还可以通过应用逻辑来优化查询，比如使用缓存穿透、缓存雪崩等策略来提高查询效率。

4. **分布式查询优化**：在分库分表的环境中，合理创建索引和重写查询语句是提高查询效率的关键。索引的创建应考虑查询的热点和数据分布，而查询语句的优化则需要根据数据库的执行计划来调整，以减少不必要的数据扫描和提高查询性能。

5. **读写分离**：通过将读操作和写操作分离到不同的数据库实例，可以显著提高查询性能。读操作可以使用主库的从库，而写操作则直接在主库上进行。这样可以减少主库的读压力，提高查询效率

极大量数据可以提供给分布式数据库实现。

## 主键自增或序列达到最大值时出现的问题和解决方案

一般来说，自增主键是完全够用的，以 MySQL 为例，当自增主键达到最大值时，如果您尝试插入新的行，则会收到错误消息，指示插入失败。例如，如果使用int类型作为自增主键的数据类型，则在达到 2147483647 时，任何插入新行的尝试都会失败。可以将int类型更改为bigint类型，从而将自增主键的最大值增加到9223372036854775807

## count 语句的优化

- 使用索引列进行 COUNT
- 避免使用 COUNT(*) 例如使用无极分页
- 使用 COUNT(1) 或 COUNT(0)
- 限制查询范围
- 使用缓存，最有用的优化方式，因为一般 COUNT 的场景变化都不是很大

## MySQL 数据库作发布系统的存储，一天五万条以上的增量，预计运维三年,怎么优化

多方面来说，如果是某个单表一天五万条以上的增量，其实分表就可以，也要看系统硬件的情况，
对于时间敏感的数据，其实对老旧数据的查询和修改频率会远远小于近期的数据

## 外连接、内连接与自连接的区别

在数据库查询中，连接（JOIN）操作用于结合两个或多个表中的行。根据连接的类型，可以分为内连接（INNER JOIN）、外连接（OUTER JOIN）和自连接（SELF JOIN）。下面是它们之间的区别：

**内连接（INNER JOIN）**

内连接是连接操作中最常见的类型，它返回两个表中匹配的行。只有当两个表中的行在连接条件中满足匹配时，这些行才会出现在结果集中。

```sql
SELECT *
FROM table1
INNER JOIN table2
ON table1.common_column = table2.common_column;
```

在这个例子中，只有当`table1`和`table2`中的`common_column`值相等时，相应的行才会被选中。

**外连接（OUTER JOIN）**

外连接分为左外连接（LEFT OUTER JOIN）、右外连接（RIGHT OUTER JOIN）和全外连接（FULL OUTER JOIN）。外连接不仅返回匹配的行，还会返回不匹配的行。

- **左外连接（LEFT OUTER JOIN）**：返回左表（`table1`）的所有行，如果右表（`table2`）中没有匹配的行，则结果集中右表的列将显示为NULL。
  
```sql
SELECT *
FROM table1
LEFT OUTER JOIN table2
ON table1.common_column = table2.common_column;
```

- **右外连接（RIGHT OUTER JOIN）**：返回右表（`table2`）的所有行，如果左表（`table1`）中没有匹配的行，则结果集中左表的列将显示为NULL。

```sql
SELECT *
FROM table1
RIGHT OUTER JOIN table2
ON table1.common_column = table2.common_column;
```

- **全外连接（FULL OUTER JOIN）**：返回两个表中的所有行，如果某一行在另一个表中没有匹配的行，则结果集中对应的列将显示为NULL。

```sql
SELECT *
FROM table1
FULL OUTER JOIN table2
ON table1.common_column = table2.common_column;
```

**自连接（SELF JOIN）**

自连接是一种特殊的连接操作，它在同一个表上进行连接。这通常用于处理表中具有层次结构的数据，或者当表中的行需要与同一表中的其他行进行比较时。

```sql
SELECT a.column1, b.column2
FROM table1 AS a
JOIN table1 AS b
ON a.common_column = b.common_column;
```

在这个例子中，`table1`被赋予了别名`a`和`b`，然后`a`和`b`之间根据`common_column`进行连接。

总结来说，内连接只返回匹配的行，外连接返回匹配的行以及不匹配的行（其中不匹配的行用NULL填充），而自连接则是在同一个表上进行连接操作。选择哪种连接类型取决于具体的数据查询需求。

## 游标是什么

游标（Cursor）是数据库管理系统（DBMS）中用于处理数据的一种机制，它允许用户逐行地处理查询结果集中的数据。游标提供了一种方式来遍历结果集中的每一行，并对每一行执行特定的操作，如更新、删除或读取数据。

游标的主要用途包括：

1. **逐行处理数据**：当需要对查询结果集中的每一行数据进行不同的处理时，游标非常有用。例如，可能需要根据每一行数据的特定条件执行不同的业务逻辑。

2. **处理大量数据**：在处理大量数据时，游标可以避免一次性将所有数据加载到内存中，从而减少内存的使用。

3. **复杂的数据操作**：在需要进行复杂的数据操作，如多表连接、子查询等，且这些操作的结果需要逐行处理时，游标提供了一种有效的解决方案。

4. **事务处理**：在事务中，游标可以用来确保数据的一致性和完整性。例如，可以使用游标来检查数据的有效性，然后根据检查结果决定是否提交或回滚事务。

游标的使用通常涉及以下几个步骤：

1. **声明游标**：定义游标，指定要处理的查询语句。

2. **打开游标**：执行查询语句，填充游标的结果集。

3. **提取数据**：逐行提取结果集中的数据。

4. **处理数据**：对提取的数据执行所需的操作。

5. **关闭游标**：完成数据处理后，关闭游标以释放资源。

6. **释放游标**：在不需要游标时，释放游标以确保资源得到正确管理。

需要注意的是，虽然游标在某些情况下非常有用，但它们的使用可能会对数据库性能产生影响，特别是当处理大量数据时。因此，在使用游标时，应考虑其对性能的影响，并尽可能地优化查询和数据处理逻辑，以减少对性能的影响。在一些现代数据库系统中，游标可能被更高效的机制所替代，如使用批处理或直接在查询中进行数据处理。

## 存储过程

存储过程（Stored Procedure）是数据库管理系统（DBMS）中预先编译并存储在数据库中的一个或多个SQL语句的集合。存储过程可以接受输入参数、执行一系列操作（如数据查询、数据更新等），并可以返回输出参数或结果集。它们是数据库编程的重要组成部分，提供了封装业务逻辑、提高代码重用性、增强数据安全性和提高数据库操作效率等优点。

**存储过程的优点**：

1. **代码重用**：存储过程可以被多次调用，避免了重复编写相同的SQL代码。

2. **性能提升**：存储过程在数据库服务器上执行，减少了网络传输的数据量，提高了执行效率。

3. **安全性**：通过存储过程可以限制对数据的直接访问，只允许通过存储过程进行数据操作，增强了数据的安全性。

4. **事务控制**：存储过程可以包含事务控制语句，如BEGIN、COMMIT、ROLLBACK等，便于进行事务管理。

5. **简化应用逻辑**：应用程序可以调用存储过程来执行复杂的业务逻辑，简化了应用程序的代码。

**存储过程的使用**：

存储过程的创建和调用通常通过数据库的特定语言（如SQL Server的T-SQL、Oracle的PL/SQL等）来完成。以下是一个简单的存储过程示例：

```sql
-- 创建存储过程
CREATE PROCEDURE GetEmployeeDetails
    @EmployeeID INT
AS
BEGIN
    SELECT * FROM Employees WHERE EmployeeID = @EmployeeID;
END;

-- 调用存储过程
EXEC GetEmployeeDetails @EmployeeID = 123;
```

在这个例子中，`GetEmployeeDetails` 是一个存储过程，它接受一个名为 `@EmployeeID` 的参数，并返回与该员工ID匹配的员工详细信息。

**存储过程的限制**：

尽管存储过程有很多优点，但它们也有一些限制：

1. **可移植性**：不同的数据库系统可能使用不同的存储过程语言，这限制了存储过程的可移植性。

2. **维护成本**：存储过程的维护可能比维护应用程序代码更复杂，特别是当存储过程非常复杂或数量众多时。

3. **调试难度**：在某些数据库系统中，调试存储过程可能比调试应用程序代码更困难。

4. **版本控制**：存储过程的版本控制可能不如应用程序代码那样直观。

总之，存储过程是数据库编程中一个非常有用的工具，它们可以提高数据库操作的效率和安全性，但同时也需要谨慎使用，以确保系统的可维护性和可扩展性。

## 怎样避免数据库死锁

1，尽量不要在一个事务中实现过于复杂的查询或更新操作。原因很简单，越是复杂的数据库操作，占用数据库资源的时间越长，引发死锁的可能性越大。

2，尽量不要在数据库事务中要求用户响应。原因同1，这也会导致事务长时间无法结束，浪费数据库资料。

3，死锁是由于并发访问数据库资源造成的，减少死锁就应该限制应用系统的并发访问量。我们应该合理设置后台服务的线程数，将大量数据的操作分解，分步骤，分阶段的执行。也应该避免在用户量大的时候大规模的进行后台数据库操作，应该将大规模的数据库操作放在用户量最少的时候进行。

4，尽可能以分区表或分区视图的方式拆分包含大量数据的表，将它们保存在不同的物量磁盘和文件组中。在访问数据时，可以分散访问保存在不同分区的数据，从而减少因为在大型表中放置锁而造成其它事务长时间等待的概率。

5，尽量避免使用占用很长的复杂查询,在条件允许的情况下应该尽量使用分页查询或缩小结果集的方式。因为复杂查询会长时间占用数据库资源，增加发生死锁的概率。

6，尽可能使用较低的隔离级别，如READ UNCOMMITTED，因为隔离级别低时，事务之间相互等待的情况会减少，这样每个事务都会尽可能快地完成数据库操作，然后释放其拥有的锁资源，这样就会降低出现锁等待或死锁的概率。当然，用户在设计数据库应用程序时，需要考虑如何解决事务中数据不一致的情况。

7，应该注意统一访问表的顺序，尽量避免有的事务先查询表A然后更新表B，而有的事务先查询表B再更新表A的情况。

8，如果一个事务中只进行读取数据的操作，则可以在该事务中使用快照(SNAPSHOT)隔离级别。因为在快照隔离级别中，数据库引擎不会阻塞其他事务对当前事务所占用资源的修改操作，当前事务会认为它所拥有的资源没有被修改过（实际上它所拥有的资源是一个快照）。这样就可以减少因为等待资源而产生死锁的情况。

[(37条消息) 数据库常见死锁原因及处理_zxcodestudy的博客-CSDN博客_数据库的死锁](https://blog.csdn.net/qq_16681169/article/details/74784193?spm=1001.2101.3001.6661.1&utm_medium=distribute.pc_relevant_t0.none-task-blog-2~default~BlogCommendFromBaidu~default-1-74784193-blog-105745720.pc_relevant_without_ctrlist_v4&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-2~default~BlogCommendFromBaidu~default-1-74784193-blog-105745720.pc_relevant_without_ctrlist_v4&utm_relevant_index=1)

## 事务

事务的实现，MySQL 可重复读原理，全局事务，共享事务，分布式事务

参考 <a href = "../架构相关/凤凰架构/凤凰架构-周志明.pdf"> 凤凰架构-周志明#事务处理 </a>

# 临时表

在数据库操作中，临时表的应用非常广泛，用于处理各种类型的业务场景，以下是一些实际应用中的场景示例：

1. 复杂查询的中间结果存储

**场景描述**：假设你需要从一个大型表中提取数据，然后根据多个条件进行分组和汇总，最后再与其他表进行连接查询。如果直接在一个查询中完成这些操作，可能会非常复杂且效率低下。

**临时表应用**：
1. 首先，将提取的数据和初步的分组汇总结果存入临时表。
2. 然后，对临时表进行进一步的处理，如连接其他表或进行更复杂的计算。
3. 最后，执行最终的查询。

2. 大数据量的分批处理

**场景描述**：当需要处理大量数据，但单次查询或操作无法有效处理时，可以使用临时表分批处理数据。

**临时表应用**：
1. 将数据分批插入临时表。
2. 对每一批数据执行所需的操作，如更新、删除或汇总。
3. 清空临时表，加载下一批数据，重复执行操作。

3. 多步骤数据转换和清洗

**场景描述**：在数据仓库或ETL（提取、转换、加载）流程中，数据经常需要经过多个步骤的转换和清洗才能用于分析。

**临时表应用**：
1. 将原始数据加载到临时表。
2. 执行数据清洗和转换操作，如去除重复项、格式化日期、转换数据类型等。
3. 将清洗后的数据加载到另一个临时表或最终的目标表中。

4. 处理复杂的报表生成

**场景描述**：生成复杂的报表时，可能需要从多个表中提取数据，并进行复杂的计算和汇总。

**临时表应用**：
1. 将每个表的初步查询结果存入临时表。
2. 对临时表进行连接、汇总等操作。
3. 最后，从临时表中生成报表所需的最终结果集。

5. 临时存储用于后续操作的数据

**场景描述**：在某些情况下，你可能需要先执行一个查询，然后基于这个查询的结果执行另一个查询。

**临时表应用**：
1. 执行第一个查询，并将结果存入临时表。
2. 使用临时表中的数据执行第二个查询，可能涉及连接、子查询等操作。

在所有这些场景中，临时表提供了一种灵活的方式来处理和存储中间数据，使得复杂的查询和数据处理流程更加高效和易于管理。不过，使用临时表时，也要注意它们对数据库性能的影响，特别是在涉及大量数据时，确保合理管理临时表的生命周期和资源使用。

## 实现自动删除临时表

在数据库中实现临时表的自动删除，主要依赖于数据库管理系统提供的特定功能和特性。不同的数据库系统有不同的机制来处理临时表的生命周期。以下是一些常见数据库系统中实现临时表自动删除的方法：

1. SQL Server

在 SQL Server 中，可以使用 `DROP TABLE` 语句来删除临时表，但通常不需要手动删除，因为 SQL Server 提供了两种类型的临时表，它们会自动处理生命周期：

- **局部临时表**：以 `#` 开头的表名，仅在创建它的会话中可见，并在会话结束时自动删除。
- **全局临时表**：以 `##` 开头的表名，对所有会话可见，但在最后一个引用它的会话结束时自动删除。

2. MySQL

MySQL 中的临时表同样具有自动删除的特性：

- **会话级临时表**：以 `#` 开头的表名，仅在创建它的会话中可见，并在会话结束时自动删除。
- **显式删除**：虽然 MySQL 不会自动删除显式创建的临时表，但可以通过 `DROP TEMPORARY TABLE` 语句手动删除。通常，最佳实践是在不再需要临时表时立即删除它们。

3. PostgreSQL

在 PostgreSQL 中，可以使用 `CREATE TEMPORARY TABLE` 语句创建临时表，它们仅在当前会话中存在，并在会话结束时自动删除。

4. Oracle

Oracle 数据库中，可以使用 `CREATE GLOBAL TEMPORARY TABLE` 语句创建临时表，它们在会话或事务结束时自动删除。

通用建议

- **避免手动删除**：在大多数情况下，应依赖数据库系统提供的自动删除机制，避免手动删除临时表。
- **事务管理**：确保事务正确管理，特别是在使用事务级临时表时，事务提交或回滚后临时表会自动删除。
- **会话管理**：确保会话在不再需要时关闭，这样会话级临时表也会随之自动删除。

### 注意事项

- **显式创建的临时表**：如果在某些数据库系统中显式创建了临时表（例如，使用了非标准的临时表名称），则需要在不再需要时手动删除这些表。
- **资源管理**：即使临时表会自动删除，也应避免创建大量临时表或存储大量数据，以免对数据库性能造成影响。

总之，大多数数据库系统都提供了自动管理临时表生命周期的机制，合理利用这些特性可以简化数据库管理并减少资源浪费。在使用临时表时，始终要考虑到它们的生命周期和对数据库性能的潜在影响。

可以通过DROP TABLE语句删除临时表，但不推荐这样，因为当临时表与永久表同名时，有可能会误删永久表，当然若你已经准备好机票，我就祝你一路顺风吧！若你未曾准备好机票，这里也给你提供中航订票电话：0086-95583 | 0086-10-95583，祝你好运！

推荐:

```sql
DROP TEMPORARY TABLE table_name;
```

注意：

（1）如果尝试使用该 `DROP TEMPORARY TABLE` 语句删除永久表，则会收到一条错误消息，提示您尝试删除的表是未知的。愉快地避免删表的误操作了。
（2）**如果开发使用连接池或持久连接的应用程序，则不能保证在终止应用程序时自动删除临时表**。因为该应用程序使用的数据库连接可能仍处于打开状态，并放置在连接池中，以便其他客户端以后再使用。因此，一个好习惯是在不再使用临时表时始终删除它们。
（3）在采用连接池的情况下，为防止多次 `CREATE 、 DROP TEMPORARY TABLE` 带来的性能瓶颈，可以使用 `CREATE IF NOT EXISTS + TRUNCATE TABLE` 的方式来提升性能。（注意：IF NOT EXISTS 是在 TABLE 之后，table_name 之前的。）























