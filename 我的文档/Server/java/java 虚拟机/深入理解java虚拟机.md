[TOC]

# Java内存区域

## 运行时数据区域

根据《Java虚拟机规范》（Java Virtual Machine Specification），Java虚拟机在执行Java程序的过程中会将所管理的内存划分为若干个运行时数据区域，这些区域包括：

![image-20240625214255479](https://raw.githubusercontent.com/MrSunflowers/images/main/note/images/202406252143579.png)

1. **堆（Heap）**：
   - **用途**：堆是Java虚拟机所管理的内存中最大的一块，用于存放对象实例。
   - **创建和销毁**：堆是随着虚拟机的启动而创建的，随着虚拟机的关闭而销毁。

2. **方法区（Method Area）**：
   - **用途**：方法区用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。
   - **创建和销毁**：方法区与堆一样，是线程共享的内存区域，它在虚拟机启动时创建，并在虚拟机关闭时销毁。

3. **虚拟机栈（VM Stack）**：
   - **用途**：虚拟机栈用于存储局部变量表、操作数栈、动态链接、方法出口等信息。
   - **创建和销毁**：虚拟机栈是线程私有的，它的生命周期与线程相同。每个线程创建时都会创建一个虚拟机栈，线程结束时虚拟机栈也随之销毁。

4. **本地方法栈（Native Method Stack）**：
   - **用途**：本地方法栈与虚拟机栈类似，用于支持Java虚拟机执行本地（native）方法服务。
   - **创建和销毁**：本地方法栈也是线程私有的，它的生命周期与线程相同。每个线程创建时都会创建一个本地方法栈，线程结束时本地方法栈也随之销毁。

5. **程序计数器（Program Counter Register）**：
   - **用途**：程序计数器是一块较小的内存空间，它可以看作是当前线程所执行的字节码的行号指示器。
   - **创建和销毁**：程序计数器是线程私有的，它的生命周期与线程相同。每个线程创建时都会创建一个程序计数器，线程结束时程序计数器也随之销毁。

除了上述五个主要的运行时数据区域外，Java虚拟机规范还提到了一些其他的数据区域，例如：

- **直接内存（Direct Memory）**：
  - **用途**：直接内存不是Java虚拟机规范中定义的运行时数据区域，但它在Java NIO中被广泛使用。直接内存允许Java程序使用本地方法直接分配堆外内存，从而提高性能。

- **运行时常量池（Runtime Constant Pool）**：
  - **用途**：运行时常量池是方法区的一部分，用于存放编译期生成的各种字面量和符号引用。

Java虚拟机的内存管理机制确保了Java程序在运行时的高效性和稳定性。通过合理地管理这些运行时数据区域，Java虚拟机能够有效地支持Java程序的执行。随着Java版本的更新，这些运行时数据区域的实现和管理方式也在不断优化和改进。

### 程序计数器

程序计数器，是一块较小的内存空间，它是**当前线程**所执行的字节码的行号指示器。字节码解释器的工作就是**通过改变这个计数器的值来选取下一条需要执行的**字节码**指令**。字节码解释器工作时，就是通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳准、异常处理、线程恢复等基础功能都需要依赖这个计数器来完成。

JAVA代码编译后的**字节码在未经过JIT**（实时编译器）**编译前**，其执行方式是**通过“字节码解释器”进行解释执行**。简单的工作原理为解释器读取装载入内存的字节码，按照顺序读取字节码指令。**读取一个指令后，将该指令“翻译”成机器码**，并根据这些来执行流程。

由于java虚拟机的多线程是通过线程轮流切换并分配处理器执行时间的方式来实现的，在任何一个确定的时刻，一个处理器（对于多核处理器来说是一个内核）只会执行一条线程中的指令。因此，为了线程切换后能恢复到正确的执行位置，每条线程都需要有一个独立的程序计数器，各条线程之间的计数器互不影响，独立存储，我们称这类内存区域为“线程私有”的内存。

若当前线程执行的是一个java方法，这个计数器记录的是正在执行的虚拟机字节码指令的地址；如果执行的是Native方法，这个计数器为空（Undefined）。此内存区域是唯一一个在java虚拟机规范中没有规定任何OutOfMemoryError情况的区域。

### java虚拟机栈

与程序计数器一样，Java虚拟机栈也是**线程私有**的，它的生命周期与线程相同。虚拟机栈描述的是Java方法执行的内存模型：每个方法在执行的同时都会创建一个栈帧，用于存储局部变量表、操作数栈、动态链接、方法出口等信息。**每一个方法从调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中入栈到出栈的过程**。

一般来说，所谓的"堆内存",“栈内存”,中的“栈内存”就是讲的虚拟机栈。

#### 局部变量表

局部变量表存放了编译期可知的各种**基本数据类型**（boolean、byte、char、short、int、 float、long、double）、**对象引用类型**（reference类型，它不等同于对象本身，可能是一个指向对象起始地址的引用指针，也可能是指向一个代表对象的句柄或其他与此对象相关的位置）和 **returnAddress类型**（指向了一条字节码指令的地址）。

这些数据类型在局部变量表中的存储空间以局部变量槽(Slot)来表示,其中64位长度的long和double类型的数据会占用2个局部变量空间（Slot），其余的数据类型只占用1个。局部变量表所需的内存空间在**编译期间**完成分配，当进入一个方法时，这个方法需要在帧中分配多大的局部变量空间是完全确定的，在方法运行期间不会改变局部变量表的大小,这里的大小指的是变量槽的数量,而真正使用多大的内存空间(比如一个变量槽占用32bit或是64bit或是更多)完全由具体的虚拟机实现自行决定。

- 当线程请求的栈深度大于虚拟机所允许的深度，抛出StackOverflowError。
- 当虚拟机栈空间可以动态扩展，扩展时无法申请到足够的内存，抛出OutOfMemoryError。
- 随着线程栈的大小越大，能够支持越多的方法调用，也即是能够存储更多的栈帧。
- 局部变量表内容越多，那么栈帧就越大，栈深度就越小。

### 本地方法栈

本地方法栈与虚拟机栈所发挥的作用是非常相似的，它们之间的区别不过是虚拟机栈为虚拟机执行Java方法（也就是字节码）服务，而本地方法栈则为虚拟机使用到的Native方法服务。在虚拟机规范中对本地方法栈中方法使用的语言、使用方式与数据结构并没有强制规定，因此具体的虚拟机可以自由实现它。甚至有的虚拟机（譬如 Sun HotSpot虚拟机）直接就把本地方法栈和虚拟机栈合二为一。与虚拟机栈一样，本地方法栈区域也会抛出StackOverflowError和OutOfMemoryError异常。

### java堆

对于大多数应用来说，Java堆是Java虚拟机所管理的内存中最大的一块。Java堆是**被所有线程共享**的一块内存区域，在虚拟机启动时创建。此内存区域的唯一目的就是存放对象实例，**几乎**所有的对象实例都在这里分配内存。这一点在Java虚拟机规范中的描述是：所有的对象实例以及数组都要在堆上分配，但是随着JIT编译器的发展与逃逸分析技 术逐渐成熟，栈上分配、标量替换优化技术将会导致一些微妙的变化发生，所有的对象都 分配在堆上也渐渐变得不是那么“绝对”了。

Java堆是垃圾收集器管理的主要区域，因此很多时候也被称做“GC堆”。根据Java虚拟机规范的规定，Java堆可以处于物理上不连续的内存空间中，只要逻辑上是连续的即可，就像使用磁盘空间存储文件一样,并不要求每个文件都连续存放。在实现时，既可以实现成固定大小的，也可以是可扩展的，不过当前主流的虚拟机都是按照可扩展来实现的（通过-Xmx和-Xms控制）。如果在堆中没有内存完成实例分配，并且堆也无法再扩展时，将会抛出OutOfMemoryError异常。

### 方法区

方法区与Java堆一样，是**各个线程共享**的内存区域，它用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。虽然Java虚拟机规范把方法区描述为堆的一个逻辑部分，但是它却有一个别名叫做Non-Heap（非堆），目的应该是与Java堆区分开来。

对于习惯在HotSpot虚拟机上开发、部署程序的开发者来说，很多人都更愿意把方法区称为“永久代”，本质上两者并不等价，仅仅是因为HotSpot虚拟机的设计团队选择把GC分代收集扩展至方法区，或者说使用永久代来实现方法区而已，这样HotSpot的垃圾收集器可以像管理Java堆一样管理这部分内存，能够省去专门为方法区编写内存管理代码的工作。对于其他虚拟机（如BEA JRockit、IBM J9等）来说是不存在永久代的概念的。原则上，如何实现方法区属于虚拟机实现细节，不受虚拟机规范约束，但使用永久代来实现方法区，现在看来并不是一个好主意，因为这样更容易遇到内存溢出问题（永久代 有-XX：MaxPermSize的上限，J9和JRockit只要没有触碰到进程可用内存的上限，例如32位系统中的4GB，就不会出现问题），而且有极少数方法（例如String.intern（））会因这个原因 导致不同虚拟机下有不同的表现。因此，在JDK8的版本中，方法区被移除，取而代之的是metaspace（元数据空间）。

元空间与永久代的主要区别在于：

1. **存储位置**：
   - **永久代**：位于JVM的堆内存中。
   - **元空间**：位于JVM的本地内存（Native Memory）中，即直接使用操作系统的内存。

2. **大小限制**：
   - **永久代**：大小是固定的，或者在启动时通过JVM参数设置，容易出现内存溢出（OutOfMemoryError）。
   - **元空间**：大小可以动态扩展，直到达到操作系统的限制，减少了因永久代内存不足导致的内存溢出问题。

3. **类的元数据存储**：
   - **永久代**：类的元数据（如类的名称、字段、方法信息等）存储在永久代中。
   - **元空间**：类的元数据存储在本地内存中，而类的静态变量仍然存储在堆中。

4. **垃圾回收**：
   - **永久代**：需要进行垃圾回收，但因为其与堆内存的紧密联系，垃圾回收的效率可能受到影响。
   - **元空间**：由于元空间使用的是本地内存，所以垃圾回收的效率更高，且与堆内存的垃圾回收相对独立。

5. **配置方式**：
   - **永久代**：可以通过JVM参数 `-XX:PermSize` 和 `-XX:MaxPermSize` 来设置永久代的初始大小和最大大小。
   - **元空间**：可以通过JVM参数 `-XX:MetaspaceSize` 和 `-XX:MaxMetaspaceSize` 来设置元空间的初始大小和最大大小。

Java 8的这些变化主要是为了提高JVM的性能和可扩展性，特别是对于大型应用和需要大量动态类加载的应用。通过将方法区的实现从永久代迁移到元空间，JVM能够更有效地管理内存，减少内存溢出的风险，并且提高了垃圾回收的效率。

需要注意的是，尽管Java 8引入了元空间，但**方法区的概念仍然存在，只是其实现方式发生了变化**。方法区仍然是JVM规范中定义的一个逻辑区域，用于存储类信息、常量、静态变量等数据。

#### 运行时常量池

运行时常量池是方法区的一部分。Class文件中除了有类的版本、字段、方法、接口等描述信息外，还有一项信息是常量池，用于存放**编译期生成的**各种字面量和符号引用，这部分内容将在类加载后进入方法区的运行时常量池中存放。

Java虚拟机对Class文件每一部分（自然也包括常量池）的格式都有严格规定，每一个字节用于存储哪种数据都必须符合规范上的要求才会被虚拟机认可、装载和执行，但对于运行时常量池，Java虚拟机规范没有做任何细节的要求，不同的提供商实现的虚拟机可以按照自己的需要来实现这个内存区域。不过，一般来说，除了保存Class文件中描述的符号引用外，还会把翻译出来的直接引用也存储在运行时常量池中。

运行时常量池相对于class文件常量池的另外一个重要特征是具备动态性，Java语言并不要求常量一定只有编译期才能产生，也就是并非预置入Class文件中常量池的内容才能进入方法区运行时常量池，运行期间也可能将新的常量放入池中，这种特性被开发人员利用得比较多的便是String类的`intern()`方法。

在Java中，运行时常量池（Runtime Constant Pool）是方法区的一部分，它存储了类文件常量池（Class File Constant Pool）中的符号引用，并且在运行时动态地添加了其他常量。这些常量包括：

1. **字面量**：如字符串字面量、整数字面量、浮点数字面量、布尔字面量（true和false）等。
2. **符号引用**：如类和接口的全限定名、字段的名称和描述符、方法的名称和描述符等。
3. **动态生成的常量**：运行时通过`String.intern()`方法或其他方式动态添加到运行时常量池中的字符串常量。

运行时常量池的动态性主要体现在以下几个方面：

- **字符串常量池**：Java 7引入了字符串常量池的概念，**位于堆内存中**。当使用`String.intern()`方法时，如果字符串常量池中不存在该字符串的引用，就会在常量池中创建一个引用指向该字符串对象。如果字符串常量池中已存在该字符串的引用，则直接返回该引用。这样可以减少内存的使用，因为相同的字符串只会在常量池中存储一份。

- **动态类加载**：当使用`Class.forName()`或`ClassLoader.loadClass()`等方法动态加载类时，类的常量池会被加载到运行时常量池中。

- **动态方法调用**：通过反射API动态调用方法时，方法的符号引用会被加载到运行时常量池中。

- **动态生成的类**：使用动态代理、CGLIB等技术动态生成的类，它们的常量池也会被加载到运行时常量池中。

运行时常量池的动态性使得Java程序在运行时可以更加灵活地处理常量，而不仅仅是依赖于编译时确定的常量。这种动态性为Java程序提供了强大的灵活性和扩展性，使得Java语言在处理字符串和类加载等场景时更加高效和方便。然而，这也意味着运行时常量池的管理变得更加复杂，需要JVM进行更细致的内存管理和垃圾回收。

##### 字符串常量池

Java 7引入了字符串常量池的概念，这个概念是Java虚拟机（JVM）为了优化字符串处理而引入的。字符串常量池位于堆内存中，它与方法区中的运行时常量池有联系，但也有区别。

在Java中，字符串字面量（例如`String s = "hello";`中的`"hello"`）在编译时会被放入方法区的运行时常量池中。当运行时遇到相同的字符串字面量时，JVM会检查字符串常量池中是否已经存在该字符串的引用，如果存在，则直接使用该引用，而不是创建新的字符串对象。这样可以节省内存空间，提高字符串处理的效率。

然而，随着Java应用的不断增长，字符串常量池的大小也不断增大，如果继续放在方法区中，可能会导致方法区的内存溢出。因此，Java 7将字符串常量池从方法区移动到了堆内存中。这样做有几个好处：

1. **内存管理**：堆内存是Java虚拟机管理的主要内存区域，通过垃圾回收机制可以有效地管理字符串常量池中的对象，避免内存泄漏。

2. **性能优化**：堆内存的访问速度通常比方法区快，将字符串常量池放在堆内存中可以提高字符串操作的性能。

3. **内存分配**：堆内存的大小可以动态调整，而方法区的大小相对固定。将字符串常量池放在堆内存中，可以更好地适应不同应用对内存的需求。

4. **减少方法区压力**：将字符串常量池从方法区中移出，可以减少方法区的压力，使得方法区可以专注于存储类信息、常量、静态变量等其他数据。

需要注意的是，**虽然字符串常量池现在位于堆内存中，但它仍然与方法区中的运行时常量池有联系。例如，当类加载时，类中的字符串字面量会被解析并放入运行时常量池中，而运行时常量池中的字符串引用则指向堆内存中的字符串常量池**。

从Java 7开始，字符串常量池被放置在堆内存中，这一特性在后续的Java版本中得到了保留。Java 8引入了元空间来替代永久代，而Java 9及以后版本继续沿用了这一设计，并对字符串常量池的管理进行了优化。这些变化主要是为了提高内存管理的效率和灵活性，以及解决内存不足的问题。

## 直接内存

直接内存（Direct Memory）并不是虚拟机运行时数据区的一部分，也不是Java虚拟机规范中定义的内存区域。但是这部分内存也被频繁地使用，而且也可能导致 OutOfMemoryError 异常出现。

在 JDK 1.4 中新加入了 NIO（New Input/Output）类，引入了一种基于通道（Channel）与缓冲区（Buffer）的I/O方式，它可以使用Native函数库直接分配**堆外内存**，然后通过一个存储在Java堆中的`DirectByteBuffer`对象作为这块内存的引用进行操作。这样能在一些场景中显著提高性能，因为**避免了在Java堆和Native堆中来回复制数据**。

显然，本机直接内存的分配不会受到Java堆大小的限制，但是，既然是内存，肯定还是会受到本机总内存（包括RAM以及SWAP区或者分页文件）大小以及处理器寻址空间的限制。服务器管理员在配置虚拟机参数时，会根据实际内存设置-Xmx等参数信息，但经常忽略直接内存，使得各个内存区域总和大于物理内存限制（包括物理的和操作系统级的限制）， 从而导致动态扩展时出现OutOfMemoryError异常。

# 内存溢出异常和解决思路

## Java堆溢出

```
java.lang.OutOfMemoryError: Java heap space
Dumping heap to java_pid3404.hprof ...
Heap dump file created [22045981 bytes in 0.663 secs]
```

通过参数-XX：+HeapDumpOnOutOf-MemoryError可以让虚拟机在出现内存溢出异常的时候Dump出当前的内存堆转储快照以便进行事后分析

Java堆内存的OutOfMemoryError异常是实际应用中最常见的内存溢出异常情况。出现Java堆内存溢出时，异常堆栈信息“java.lang.OutOfMemoryError”会跟随进一步提示“Java heap space”。

要解决这个内存区域的异常，常规的处理方法是首先通过内存映像分析工具（如Eclipse Memory Analyzer）对Dump出来的堆转储快照进行分析。第一步首先应确认内存中导致OOM的对象是否是必要的，也就是要先分清楚到底是出现了内存泄漏（Memory Leak）还是内存溢出（Memory Overflow）。

如果是内存泄漏，可进一步通过工具查看泄漏对象到GC Roots的引用链，找到泄漏对象是通过怎样的引用路径、与哪些GC Roots相关联，才导致垃圾收集器无法回收它们，根据泄漏对象的类型信息以及它到GC Roots引用链的信息，一般可以比较准确地定位到这些对象创建的位置，进而找出产生内存泄漏的代码的具体位置。

如果不是内存泄漏，换句话说就是内存中的对象确实都是必须存活的，那就应当检查Java虚拟机的堆参数（-Xmx与-Xms）设置，与机器的内存对比，看看是否还有向上调整的空间。再从代码上检查是否存在某些对象生命周期过长、持有状态时间过长、存储结构设计不合理等情况，尽量减少程序运行期的内存消耗。

## 虚拟机栈和本地方法栈溢出

由于HotSpot虚拟机中并不区分虚拟机栈和本地方法栈，因此对于HotSpot来说，-Xoss参数（设置本地方法栈大小）虽然存在，但实际上是没有任何效果的，栈容量只能由-Xss参数来设定。关于虚拟机栈和本地方法栈，在《Java虚拟机规范》中描述了两种异常：

- 1）如果线程请求的栈深度大于虚拟机所允许的最大深度，将抛出 StackOverflowError 异常。
- 2）如果虚拟机的栈内存允许动态扩展，当扩展栈容量无法申请到足够的内存时，将抛出 OutOfMemoryError异常。

《Java虚拟机规范》明确允许Java虚拟机实现自行选择是否支持栈的动态扩展，而 HotSpot 虚拟机的选择是不支持扩展，所以除非在创建线程申请内存时就因无法获得足够内存而出现 OutOfMemoryError异常，否则在线程运行时是不会因为扩展而导致内存溢出的，只会因为栈容量无法容纳新的栈帧而导致StackOverflowError异常。

```
stack length:2402
Exception in thread "main" java.lang.StackOverflowError
	at org.fenixsoft.oom. JavaVMStackSOF.leak(JavaVMStackSOF.java:20)
	at org.fenixsoft.oom. JavaVMStackSOF.leak(JavaVMStackSOF.java:21)
	at org.fenixsoft.oom. JavaVMStackSOF.leak(JavaVMStackSOF.java:21)
……后续异常堆栈信息省略
```

对于不同版本的Java虚拟机和不同的操作系统，栈容量最小值可能会有所限制，这主要取决于操作系统内存分页大小。譬如-Xss128k可以正常用于32位Windows系统下的JDK 6，但是如果用于64位Windows系统下的JDK 11，则会提示栈容量最小不能低于180K，而在Linux下这个值则可能是228K，如果低于这个最小限制，HotSpot虚拟器启动时会给出如下提示：

```
The Java thread stack size specified is too small. Specify at least 228k
```

无论是由于栈帧太大还是虚拟机栈容量太小，当新的栈帧内存无法分配的时候，HotSpot虚拟机抛出的都是StackOverflowError异常。可是如果在允许动态扩展栈容量大小的虚拟机上，相同代码则会导致不一样的情况。譬如远古时代的Classic虚拟机，这款虚拟机可以支持动态扩展栈内存的容量，在Windows上的JDK 1.0.2运行的话（如果这时候要调整栈容量就应该改用-oss参数了），得到的结果是：

```
stack length:3716
java.lang.OutOfMemoryError
	at org.fenixsoft.oom. JavaVMStackSOF.leak(JavaVMStackSOF.java:27)
	at org.fenixsoft.oom. JavaVMStackSOF.leak(JavaVMStackSOF.java:28)
	at org.fenixsoft.oom. JavaVMStackSOF.leak(JavaVMStackSOF.java:28)
……后续异常堆栈信息省略
```

可见相同的代码在Classic虚拟机中成功产生了OutOfMemoryError而不是StackOver-flowError异常。如果测试时不限于单线程，通过不断建立线程的方式，在HotSpot上也是可以产生内存溢出异常的，具体如代码清单2-6所示。但是这样产生的内存溢出异常和栈空间是否足够并不存在任何直接的关系，主要取决于操作系统本身的内存使用状态。甚至可以说，在这种情况下，给每个线程的栈分配的内存越大，反而越容易产生内存溢出异常。

原因其实不难理解，操作系统分配给每个进程的内存是有限制的，譬如32位Windows的单个进程最大内存限制为2GB。HotSpot虚拟机提供了参数可以控制Java堆和方法区这两部分的内存的最大值，那剩余的内存即为2GB（操作系统限制）减去最大堆容量，再减去最大方法区容量，由于程序计数器消耗内存很小，可以忽略掉，如果把直接内存和虚拟机进程本身耗费的内存也去掉的话，剩下的内存就由虚拟机栈和本地方法栈来分配了。因此为每个线程分配到的栈内存越大，可以建立的线程数量自然就越少，建立线程时就越容易把剩下的内存耗尽。

出现StackOverflowError异常时，会有明确错误堆栈可供分析，相对而言比较容易定位到问题所在。如果使用HotSpot虚拟机默认参数，栈深度在大多数情况下（因为每个方法压入栈的帧大小并不是一样的，所以只能说大多数情况下）到达1000~2000是完全没有问题，对于正常的方法调用（包括不能做尾递归优化的递归调用），这个深度应该完全够用了。但是，如果是建立过多线程导致的内存溢出，在不能减少线程数量或者更换64位虚拟机的情况下，就只能通过减少最大堆和减少栈容量来换取更多的线程。

这种通过“减少内存”的手段来解决内存溢出的方式，如果没有这方面处理经验，一般比较难以想到，这一点读者需要在开发32位系统的多线程应用时注意。也是由于这种问题较为隐蔽，从 JDK 7起，以上提示信息中 “unable to create native thread” 后面，虚拟机会特别注明原因可能是“ possibly out of memory or process/resource limits reached ”。

```
Exception in thread "main" java.lang.OutOfMemoryError: unable to create native thread
```

## 方法区和运行时常量池溢出

由于运行时常量池是方法区的一部分，所以这两个区域的溢出测试可以放到一起进行。前面曾经提到HotSpot从JDK 7开始逐步“去永久代”的计划，并在JDK 8中完全使用元空间来代替永久代的背景故事，在此我们就以测试代码来观察一下，使用“永久代”还是“元空间”来实现方法区，对程序有什么实际的影响。

String::intern()是一个本地方法，它的作用是如果字符串常量池中已经包含一个等于此String对象的字符串，则返回代表池中这个字符串的String对象的引用；否则，会将此String对象包含的字符串添加到常量池中，并且返回此String对象的引用。

在JDK 6或更早之前的HotSpot虚拟机中，常量池都是分配在永久代中，我们可以通过-XX：PermSize和-XX：MaxPermSize限制永久代的大小，即可间接限制其中常量池的容量，具体实现如代码清单2-7所示，请读者测试时首先以JDK 6来运行代码。

```java
/**
 * VM Args: -XX:PermSize=6M -XX:MaxPermSize=6M
 */
public class RuntimeConstantPoolOOM {
    public static void main(String[] args) {
        // 使用Set保持着常量池引用，避免Full GC回收常量池行为
        Set<String> set = new HashSet<String>();
        // 在short范围内足以让6MB的PermSize产生OOM了
        short i = 0;
        while (true) {
            set.add(String.valueOf(i++).intern());
        }
    }
}
```

运行结果

```
Exception in thread "main" java.lang.OutOfMemoryError: PermGen space
	at java.lang.String.intern(Native Method)
	at org.fenixsoft.oom.RuntimeConstantPoolOOM.main(RuntimeConstantPoolOOM.java: 18)
```

从运行结果中可以看到，运行时常量池溢出时，在OutOfMemoryError异常后面跟随的提示信息是“PermGen space”，说明运行时常量池的确是属于方法区（即JDK 6的HotSpot虚拟机中的永久代）的一部分。

而使用JDK 7或更高版本的JDK来运行这段程序并不会得到相同的结果，无论是在JDK 7中继续使用-XX：MaxPermSize参数或者在JDK 8及以上版本使用-XX：MaxMeta-spaceSize参数把方法区容量同样限制在6MB，也都不会重现JDK 6中的溢出异常，循环将一直进行下去，永不停歇。

出现这种变化，是因为自JDK 7起，原本存放在永久代的字符串常量池被移至Java堆之中，所以在JDK 7及以上版本，限制方法区的容量对该测试用例来说是毫无意义的。这时候使用-Xmx参数限制最大堆到6MB就能够看到以下两种运行结果之一，具体取决于哪里的对象分配时产生了溢出：

```
// OOM异常一：
Exception in thread "main" java.lang.OutOfMemoryError: Java heap space
	at java.base/java.lang.Integer.toString(Integer.java:440)
	at java.base/java.lang.String.valueOf(String.java:3058)
	at RuntimeConstantPoolOOM.main(RuntimeConstantPoolOOM.java:12)
// OOM异常二：
Exception in thread "main" java.lang.OutOfMemoryError: Java heap space
	at java.base/java.util.HashMap.resize(HashMap.java:699)
	at java.base/java.util.HashMap.putVal(HashMap.java:658)
	at java.base/java.util.HashMap.put(HashMap.java:607)
	at java.base/java.util.HashSet.add(HashSet.java:220)
	at RuntimeConstantPoolOOM.main(RuntimeConstantPoolOOM.java from InputFile-Object:14)
```

### String::intern()

关于这个字符串常量池的实现在哪里出现问题，还可以引申出一些更有意思的影响。

```java
public class RuntimeConstantPoolOOM {
    public static void main(String[] args) {
        String str1 = new StringBuilder("计算机").append("软件").toString();
        System.out.println(str1.intern() == str1);

        String str2 = new StringBuilder("ja").append("va").toString();
        System.out.println(str2.intern() == str2);
    }
}
```

这段代码在JDK 6中运行，会得到两个false，而在JDK 7中运行，会得到一个true和一个false。产生差异的原因是，在JDK 6中，intern()方法会把首次遇到的字符串实例复制到永久代的字符串常量池中存储，返回的也是永久代里面这个字符串实例的引用，而由StringBuilder创建的字符串对象实例在Java堆上，所以必然不可能是同一个引用，结果将返回false。

而JDK 7（以及部分其他虚拟机，例如JRockit）的intern()方法实现就不需要再拷贝字符串的实例到永久代了，既然字符串常量池已经移到Java堆中，那只需要在常量池里记录一下首次出现的实例引用即可，因此intern()返回的引用和由StringBuilder创建的那个字符串实例就是同一个。而对str2比较返回false，这是因为“java”这个字符串在执行String-Builder.toString()之前就已经出现过了，字符串常量池中已经有它的引用，不符合intern()方法要求“首次遇到”的原则，“计算机软件”这个字符串则是首次出现的，因此结果返回true。

### 方法区溢出

方法区溢出也是一种常见的内存溢出异常，一个类如果要被垃圾收集器回收，要达成的条件是比较苛刻的。在经常运行时生成大量动态类的应用场景里，就应该特别关注这些类的回收状况。这类场景除了之前提到的程序使用了CGLib字节码增强和动态语言外，常见的还有：大量JSP或动态产生JSP文件的应用（JSP第一次运行时需要编译为Java类）、基于OSGi的应用（即使是同一个类文件，被不同的加载器加载也会视为不同的类）等。

在JDK 8以后，永久代便完全退出了历史舞台，元空间作为其替代者登场。在默认设置下，前面列举的那些正常的动态创建新类型的测试用例已经很难再迫使虚拟机产生方法区的溢出异常了。不过为了让使用者有预防实际应用里出现类似于代码清单2-9那样的破坏性的操作，HotSpot还是提供了一些参数作为元空间的防御措施，主要包括：

- -XX：MaxMetaspaceSize：设置元空间最大值，默认是-1，即不限制，或者说只受限于本地内存大小。
- -XX：MetaspaceSize：指定元空间的初始空间大小，以字节为单位，达到该值就会触发垃圾收集进行类型卸载，同时收集器会对该值进行调整：如果释放了大量的空间，就适当降低该值；如果释放了很少的空间，那么在不超过-XX：MaxMetaspaceSize（如果设置了的话）的情况下，适当提高该值。
- -XX：MinMetaspaceFreeRatio：作用是在垃圾收集之后控制最小的元空间剩余容量的百分比，可减少因为元空间不足导致的垃圾收集的频率。类似的还有-XX：Max-MetaspaceFreeRatio，用于控制最大的元空间剩余容量的百分比。

## 本机直接内存溢出

直接内存（Direct Memory）的容量大小可通过-XX：MaxDirectMemorySize参数来指定，如果不去指定，则默认与Java堆最大值（由-Xmx指定）一致，代码清单2-10越过了DirectByteBuffer类直接通过反射获取Unsafe实例进行内存分配（Unsafe类的getUnsafe()方法指定只有引导类加载器才会返回实例，体现了设计者希望只有虚拟机标准类库里面的类才能使用Unsafe的功能，在JDK 10时才将Unsafe的部分功能通过VarHandle开放给外部使用），因为虽然使用DirectByteBuffer分配内存也会抛出内存溢出异常，但它抛出异常时并没有真正向操作系统申请分配内存，而是通过计算得知内存无法分配就会在代码里手动抛出溢出异常，真正申请分配内存的方法是Unsafe::allocateMemory()。

```java
/**
 * VM Args: -Xmx20M -XX:MaxDirectMemorySize=10M
 * @author zzm
 */
public class DirectMemoryOOM {
    private static final int _1MB = 1024 * 1024;

    public static void main(String[] args) throws Exception {
        Field unsafeField = Unsafe.class.getDeclaredFields()[0];
        unsafeField.setAccessible(true);
        Unsafe unsafe = (Unsafe) unsafeField.get(null);
        while (true) {
            unsafe.allocateMemory(_1MB);
        }
    }
}
```

运行结果

```
Exception in thread "main" java.lang.OutOfMemoryError
	at sun.misc.Unsafe.allocateMemory(Native Method)
	at org.fenixsoft.oom.DMOOM.main(DMOOM.java:20)

```

由直接内存导致的内存溢出，一个明显的特征是在Heap Dump文件中不会看见有什么明显的异常情况，如果读者发现内存溢出之后产生的Dump文件很小，而程序中又直接或间接使用了 DirectMemory（典型的间接使用就是NIO），那就可以考虑重点检查一下直接内存方面的原因了。

# 对象

## 对象的创建

在Java虚拟机（JVM）中，对象的创建过程遵循一定的步骤，这些步骤确保了对象的正确分配和初始化。以下是对象创建的一般过程：

1. **类加载检查**：
   - 当JVM遇到一个new指令时，首先会检查这个指令的参数是否能在常量池中定位到一个类的符号引用，并检查这个类是否已经被加载、解析和初始化。如果没有，JVM需要先执行类的加载过程。

2. **分配内存**：
   - 在类加载检查通过后，JVM需要为新对象分配内存。对象所需内存的大小在类加载完成后便可完全确定。分配内存的方式取决于JVM的内存分配策略，常见的策略有“指针碰撞”和“空闲列表”。
   - 如果Java堆中的内存是绝对规整的，使用“指针碰撞”方式分配内存，即通过移动指针来分配内存。
   - 如果Java堆中的内存不是规整的，使用“空闲列表”方式分配内存，即维护一个列表记录哪些内存块是可用的。

3. **分配内存时的线程安全**：
   - 在Java虚拟机（JVM）中，对象的创建和内存分配是频繁发生的操作，特别是在多线程环境下，这些操作必须是线程安全的。为了保证线程安全，JVM采用了多种机制来管理内存分配，其中就包括了CAS（Compare-And-Swap）操作和本地线程分配缓冲（TLAB）。
   - **CAS**：CAS是一种无锁的同步机制，它通过硬件支持来实现原子操作。在JVM中，CAS操作通常用于更新对象的引用，即在分配内存时更新指向新对象的指针。CAS操作会检查内存中的值是否与预期值相同，如果相同，则将内存中的值更新为新值，并返回成功；如果不同，则不更新值，并返回失败。由于CAS操作是原子的，因此可以保证在并发环境下，对象的分配是线程安全的。
   - **TLAB**：称为本地线程分配缓冲，TLAB是JVM为每个线程在堆内存中预先分配的一小块区域。每个线程在自己的TLAB中分配对象，只有本地缓冲区用完
了，分配新的缓存区时才需要同步锁定，这样可以避免多线程同时在堆上分配对象时的同步开销。当线程的TLAB用完后，它需要向JVM申请新的TLAB，这个过程可能会涉及到同步锁定。但是，由于TLAB的使用频率远高于申请新TLAB的频率，因此整体上可以减少同步操作，提高内存分配的效率。在JVM启动时，可以通过设置JVM参数 -XX:+UseTLAB 来启用或禁用TLAB。默认情况下JVM会启用TLAB。TLAB（Thread Local Allocation Buffer）的默认大小在不同的JVM实现和版本中可能会有所不同。在HotSpot JVM中，TLAB的默认大小是根据Eden空间的大小动态计算的，通常情况下，TLAB的大小大约是Eden空间的1%。这个比例可以通过JVM参数-XX:TLABWasteTargetPercent 来调整，但通常使用默认值即可。如果需要更精确的控制，可以使用-XX:TLABSize参数来设置一个固定的初始大小。

4. **内存空间初始化为零值**：
   - 内存分配完成后，JVM需要将分配到的内存空间（不包括对象头）初始化为零值（对于对象头，JVM会初始化为默认值）。这一步保证了对象的实例字段在Java代码中未显式初始化前，可以拥有一个确定的初始值。

5. **设置对象头**：
   - 接下来，JVM需要设置对象头（Object Header），包括对象的哈希码、GC分代年龄、锁状态标志、线程持有的锁、偏向线程ID、偏向时间戳等信息。这些信息是对象运行时数据的一部分。

6. **执行`<init>`方法**：
   - 在对象头设置完成后，JVM需要执行对象的初始化方法（即构造方法），为对象的实例变量赋予初始值，执行其他必要的初始化操作。这个过程是通过执行构造方法来完成的。

7. **对象创建完成**：
   - 当构造方法执行完毕后，一个对象就创建完成了。此时，对象已经准备好被使用。

整个对象创建过程在Java虚拟机中是线程安全的，即使多个线程同时创建对象，JVM也能保证对象的正确分配和初始化。在多线程环境下，JVM通过同步机制（如CAS操作）来确保对象的正确分配。

需要注意的是，上述过程是针对普通对象的创建过程。对于数组对象，其创建过程与普通对象类似，但会额外处理数组的长度信息。此外，JVM还提供了多种优化手段，如TLAB（Thread Local Allocation Buffer）技术，用于减少线程间的同步开销，提高对象分配的效率。


### 内存分配策略

为对象分配空间的任务实际上便等同于把一块确定大小的内存块从Java堆中划分出来

#### 指针碰撞（Bump-the-Pointer）

假设Java堆中内存是绝对规整的，所有被使用过的内存都被放在一边，空闲的内存被放在另一边，中间放着一个指针作为分界点的指示器，那所分配内存就仅仅是把那个指针向空闲空间方向挪动一段与对象大小相等的距离，这种分配方式称为“指针碰撞”（Bump The Pointer）。

这种策略的优点是简单且高效，因为它避免了复杂的内存搜索和管理。然而，它要求堆内存必须是连续的，且在分配过程中不会产生内存碎片。

#### 空闲列表（Free List）

空闲列表是一种更为复杂的内存分配策略，适用于内存空间不连续的情况。在这种策略中，JVM维护一个列表，记录了堆内存中所有空闲的内存块。当需要为新对象分配内存时，JVM会遍历这个列表，找到一个足够大的空闲块来存放新对象。分配完成后，这个空闲块会被分割成两部分：一部分用于新对象，另一部分如果足够大，可能会被重新加入到空闲列表中。

空闲列表策略的优点是灵活，能够处理内存碎片问题，允许内存空间不连续。然而，它需要额外的内存空间来存储空闲列表，并且在分配内存时需要进行搜索和管理，这可能会增加内存分配的开销。

#### 实际应用

选择哪种分配方式由Java堆是否规整决定，而Java堆是否规整又由所采用的垃圾收集器是否带有空间压缩整理（Compact）的能力决定。因此，在实际的JVM实现中，如HotSpot虚拟机，通常会结合使用这两种策略。例如，对于使用TLAB（Thread Local Allocation Buffer）的线程，会使用指针碰撞策略来快速分配内存。而对于非TLAB内存分配，可能会使用空闲列表策略来管理内存。

此外，现代JVM还引入了其他内存分配技术，如G1垃圾回收器中的Region分配策略，它将堆内存划分为多个区域（Region），每个区域可以独立地进行垃圾回收和内存分配。

总之，指针碰撞和空闲列表是JVM内存分配的两种基本策略，它们各有优缺点，JVM会根据不同的情况和需求选择合适的策略来优化内存分配的效率和性能。随着JVM技术的发展，还会有更多先进的内存分配技术被引入，以适应不断变化的应用场景和性能需求。

## 对象的内存结构

在HotSpot虚拟机中，对象的内存结构主要分为以下几个部分：

1. **对象头（Object Header）**：
   - **Mark Word**：对象的运行时数据，如哈希码（HashCode）、GC分代年龄、锁状态标志、线程持有的锁、偏向线程ID、偏向时间戳等。Mark Word的大小在32位和64位虚拟机中有所不同，32位虚拟机中为4字节，64位虚拟机中为8字节（如果开启指针压缩则为4字节）。
   - **类型指针（Class Pointer）**：指向对象的类元数据的指针，用于确定对象是哪个类的实例。在启用压缩指针的情况下，这个指针的大小会减少。

2. **实例数据（Instance Data）**：
   - 实例数据是对象真正存储数据的地方，包括对象的字段（Field），无论是基本类型还是引用类型。实例数据的排列顺序会受到虚拟机分配策略和字段声明顺序的影响。

3. **对齐填充（Padding）**：
   - 这并不是必然存在的，也没有特别的含义，它仅仅起着占位符的作用。由于HotSpot虚拟机的自动内存管理系统要求对象起始地址必须是8字节的整数倍，换句话说就是，任何对象的大小都必须是8字节的整数倍。为了保证对象的大小是某个字节大小的整数倍（通常是8字节），在实例数据之后可能会有对齐填充。这主要是为了提高内存访问效率，因为现代计算机系统通常对内存访问有对齐要求。

在64位的HotSpot虚拟机中，对象头的大小通常是12字节（Mark Word 8字节 + 类指针4字节），如果启用了压缩指针（-XX:+UseCompressedOops），则类指针会减少到4字节，对象头总共为12字节。如果对象是数组类型，对象头还会包含一个额外的数组长度字段。

对象的内存布局在不同的JVM实现和版本中可能会有所不同，但上述描述的是HotSpot虚拟机中对象内存布局的基本情况。JVM的内存布局设计考虑了内存分配的效率、对象访问的速度以及垃圾回收的便利性等因素。通过合理地组织对象的内存布局，JVM能够有效地支持Java语言的特性，同时保证运行时的性能。

### 对象头

#### Mark Word

对象需要存储的运行时数据很多，其实已经超出了32、64位Bitmap结构所能记录的最大限度，但对象头里的信息是与对象自身定义的数据，无关的额外存储成本，考虑到虚拟机的空间效率，Mark Word 被设计成一个有着动态定义的数据结构，以便在极小的空间内存储尽量多的数据，根据对象的状态复用自己的存储空间。

例如在32位的HotSpot虚拟机中，如对象未被同步锁锁定的状态下，Mark Word的32个比特存储空间中的25个比特用于存储对象哈希码，4个比特用于存储对象分代年龄，2个比特用于存储锁标志位，1个比特固定为0，在其他状态（轻量级锁定、重量级锁定、GC标记、可偏向）下对象的存储内容如表所示

| 存储内容                                    | 标志位 | 状态             |
|--------------------------------------------|--------|------------------|
| 对象哈希码、对象分代年龄                    | 01      | 未锁定           |
| 指向锁记录的指针                            | 00      | 轻量级锁定       |
| 指向重量级锁的指针                          | 10      | 膨胀（重量级锁定）|
| 空，不需要记录信息                          | 11      | GC标记           |
| 偏向线程ID、偏向时间戳、对象分代年龄        | 01      | 可偏向            |

#### 类型指针

对象头的另外一部分是类型指针，即对象指向它的类型元数据的指针，Java虚拟机通过这个指针来确定该对象是哪个类的实例，从而访问该类的方法和字段。

并不是所有的虚拟机实现都必须在对象数据上保留类型指针，换句话说，查找对象的元数据信息并不一定要经过对象本身。在某些JVM实现中，为了优化性能，可能会采用其他机制来确定对象的类型，而不需要在每个对象上都保留类型指针。例如，某些JVM可能会使用对象的内存地址来推断对象的类型，或者使用其他内部数据结构来存储对象类型信息。这些优化措施可以减少内存占用，提高对象访问速度。

此外，如果对象是一个Java数组，那在对象头中还必须有一块用于记录数组长度的数据，因为虚拟机可以通过普通Java对象的元数据信息确定Java对象的大小，但是如果数组的长度是不确定的，将无法通过元数据中的信息推断出数组的大小。数组长度信息使得JVM能够知道数组的边界，从而在进行数组操作时避免越界错误。

### 实例数据

在HotSpot虚拟机中，实例数据部分是对象存储实际数据的地方，包括对象的字段（Fields）。这些字段可以是基本数据类型（如int、long、float、double、byte、char、short、boolean）或引用类型（如对象引用）。实例数据的存储顺序受到虚拟机的分配策略（-XX：FieldsAllocationStyle 参数）和字段在Java源码中定义的顺序的影响。

**实例数据的存储顺序**

HotSpot虚拟机默认的字段分配顺序如下：

1. **longs/doubles**：首先存储所有long和double类型的字段。
2. **ints**：接着存储所有int类型的字段。
3. **shorts/chars**：然后存储所有short和char类型的字段。
4. **bytes/booleans**：接着存储所有byte和boolean类型的字段。
5. **oops（Ordinary Object Pointers，OOPs）**：最后存储所有对象引用类型的字段。

**父类与子类字段的存储**

在父类和子类的字段存储上，HotSpot虚拟机遵循以下规则：

- **父类字段优先**：在子类中定义的字段会紧跟在父类字段之后存储。这意味着，如果子类继承了父类的字段，这些字段会按照它们在父类中定义的顺序存储，然后才是子类中定义的新字段。

- **字段宽度优先**：相同宽度的字段会被分配到一起存放，以提高内存访问的效率。

**CompactFields参数**

`-XX:+CompactFields`参数（默认为true）允许子类中较窄的字段插入到父类字段的空隙中。这样做可以更有效地利用内存空间，尤其是在父类字段之间存在未使用的空间时。例如，如果父类有一个int字段，而子类有一个byte字段，那么子类的byte字段可以存储在父类int字段的空隙中，而不是单独占用一个空间。

# 垃圾收集器与内存分配策略

上文绍了Java内存运行时区域的各个部分，其中程序计数器、虚拟机栈、本地方法栈3个区域随线程而生，随线程而灭，栈中的栈帧随着方法的进入和退出而有条不紊地执行着出栈和入栈操作。每一个栈帧中分配多少内存基本上是在类结构确定下来时就已知的（尽管在运行期会由即时编译器进行一些优化，但在基于概念模
型的讨论里，大体上可以认为是编译期可知的），因此这几个区域的内存分配和回收都具备确定性，在这几个区域内就不需要过多考虑如何回收的问题，当方法结束或者线程结束时，内存自然就跟随着回收了。

而Java堆和方法区这两个区域则有着很显著的不确定性：一个接口的多个实现类需要的内存可能会不一样，一个方法所执行的不同条件分支所需要的内存也可能不一样，只有处于运行期间，我们才能知道程序究竟会创建哪些对象，创建多少个对象，这部分内存的分配和回收是动态的。垃圾收集器所关注的正是这部分内存该如何管理，本文后续讨论中的“内存”分配与回收也仅仅特指这一部分内存。

## 对象存活的判定

### 引用计数算法

很多教科书描述对象存活判断的算法是这样的：在对象中添加一个引用计数器，每当有一个地方引用它时，计数器值就加一；当引用失效时，计数器值就减一；任何时刻计数器为零的对象就是不可能再被使用的。

客观来说，引用计数算法（Reference Counting）虽然占用了一些额外的内存空间来进行计数，但它的原理简单，判定效率也很高，在大多数情况下它都是一个不错的算法。确实，有一些比较著名的应用案例，例如微软的COM（Component Object Model）技术、使用ActionScript 3的FlashPlayer、Python语言以及在游戏脚本领域得到广泛应用的Squirrel中都使用了引用计数算法进行内存管理。

然而，在Java领域，至少主流的Java虚拟机里面都没有选用引用计数算法来管理内存。主要原因是，这个看似简单的算法有很多例外情况要考虑，必须配合大量额外处理才能保证正确地工作。例如，单纯的引用计数就很难解决对象之间相互循环引用的问题。

举个简单的例子

```
/**
 * testGC()方法执行后，objA和objB会不会被GC呢？
 */
public class ReferenceCountingGC {
    public Object instance = null;
    private static final int _1MB = 1024 * 1024;

    /**
     * 这个成员属性的唯一意义就是占点内存，以便能在GC日志中看清楚是否有回收过
     */
    private byte[] bigSize = new byte[2 * _1MB];

    public static void testGC() {
        ReferenceCountingGC objA = new ReferenceCountingGC();
        ReferenceCountingGC objB = new ReferenceCountingGC();
        objA.instance = objB;
        objB.instance = objA;
        objA = null;
        objB = null;
        // 假设在这行发生GC，objA和objB是否能被回收？
        System.gc();
    }
}
```

考虑代码中的`testGC()`方法：对象`objA`和`objB`都有字段`instance`，通过赋值`objA.instance = objB`和`objB.instance = objA`，使得这两个对象互相引用。除此之外，这两个对象再无任何引用。实际上，这两个对象已经不可能再被访问，但是它们因为互相引用着对方，导致它们的引用计数都不为零。因此，引用计数算法无法回收它们。

引用计数算法虽然在某些场景下非常有用，但在处理复杂对象引用关系时，特别是在Java这样的语言中，它并不能完全满足内存管理的需求。

### 可达性分析算法

这个算法的基本思路就是通过一系列称为“GC Roots”的根对象作为起始节点集，从这些节点开始，根据引用关系向下搜索，搜索过程所走过的路径称为“引用链”（Reference Chain），如果某个对象到GC Roots间没有任何引用链相连，或者用图论的话来说就是从GC Roots到这个对象不可达时，则证明此对象是不可能再被使用的。

如图所示，对象object 5、object 6、object 7虽然互有关联，但是它们到GC Roots是不可达的，因此它们将会被判定为可回收的对象。

![](https://raw.githubusercontent.com/MrSunflowers/images/main/note/spring/202204021527548.png)

在Java技术体系里面，固定可作为GC Roots的对象包括以下几种：

- 在**虚拟机栈（栈帧中的本地变量表）中引用的对象**，譬如各个线程被调用的方法堆栈中使用到的参数、局部变量、临时变量等。
- 在**方法区中类静态属性引用的对象**，譬如Java类的引用类型静态变量。
- 在**方法区中常量引用的对象**，譬如字符串常量池（String Table）里的引用。
- 在**本地方法栈中**JNI（即通常所说的Native方法）引用的对象。
- **Java虚拟机内部的引用**，如基本数据类型对应的Class对象，一些常驻的异常对象（比如NullPointExcepiton、OutOfMemoryError）等，还有系统类加载器。
- 所有**被同步锁（synchronized关键字）持有的对象**。
- 反映Java虚拟机内部情况的JMXBean、JVMTI中注册的回调、本地代码缓存等。

除了这些固定的GC Roots集合以外，根据用户所选用的垃圾收集器以及当前回收的内存区域不同，还可以有其他对象“临时性”地加入，共同构成完整GC Roots集合。譬如后文将会提到的**分代收集**和**局部回收**（Partial GC），如果只针对Java堆中某一块区域发起垃圾收集时（如最典型的只针对新生代的垃圾收集），必须考虑到内存区域是虚拟机自己的实现细节（在用户视角里任何内存区域都是不可见的），更不是孤立封闭的，所以某个区域里的对象完全有可能被位于堆中其他区域的对象所引用，这时候就需要将这些关联区域的对象也一并加入GC Roots集合中去，才能保证可达性分析的正确性。

目前最新的几款垃圾收集器无一例外都具备了局部回收的特征，为了避免GC Roots包含过多对象而过度膨胀，它们在实现上也做出了各种优化处理。

## 引用

无论是通过引用计数算法判断对象的引用数量，还是通过可达性分析算法判断对象是否引用链可达，判定对象是否存活都和“引用”离不开关系。在JDK 1.2版之前，Java里面的引用是很传统的定义：如果reference类型的数据中存储的数值代表的是另外一块内存的起始地址，就称该reference数据是代表某块内存、某个对象的引用，但是一个对象在这种定义下只有“被引用”或者“未被引用”两种状态，譬如我们希望能描述一类对象：当内存空间还足够时，能保留在内存之中，如果内存空间在进行垃圾收集后仍然非常紧张，那就可以抛弃这些对象(很多系统的缓存功能都符合这样的应用场景),此时这个引用就显得无能为力了。

在JDK 1.2版之后，Java对引用的概念进行了扩充，将引用分为4种，这4种引用强度依次逐渐减弱

- **强引用**（Strongly Re-ference）: 最传统的“引用”的定义，是指在程序代码之中普遍存在的引用赋值，即类似 `Objectobj=new Object()` 这种引用关系。无论任何情况下，**只要强引用关系还存在，垃圾收集器就永远不会回收掉被引用的对象**。

- **软引用**（Soft Reference）: 用来描述一些还有用，但非必须的对象。只被软引用关联着的对象，**在系统将要发生内存溢出异常前，会把这些对象列进回收范围之中进行第二次回收**，如果这次回收还没有足够的内存，才会抛出内存溢出异常。在JDK 1.2版之后提供了 `SoftReference` 类来实现软引用。

像软引用这种如果内存充足，GC时就保留，内存不够，GC再来收集的功能很适合用在缓存的引用场景中。在使用缓存时有一个原则，如果缓存中有就从缓存获取，如果没有就从数据库中获取，缓存的存在是为了加快计算速度，如果因为缓存导致了内存不足进而整个程序崩溃，那就得不偿失了。

```java
public class T1 {
    private List list;
    private SoftReference sr;
    //假设这里有个与redis连接的bean
    @Bean
    private RedisTemplate redis;

    public List getList(){
        if (sr.get() == null){
            //从redis中获取
            list = redis.getList();
            sr = new SoftReference(list);
            return list;
        }else {
            return (List)sr.get();
        }
    }
}
```

上例在实际应用中是有缺陷的，因为如果`sr.get()==null`,虽然实际的list被回收了，但sr这个对象还没有被回收，如果出现了大量这类的没回收的软引用，有可能导致内存溢出。所以软引用需要和一个引用队列（ReferenceQueue）联合使用，如果软引用所引用的对象被垃圾回收器回收，Java虚拟机就会把这个软引用加入到与之关联的引用队列中，然后需要程序员手动对这些没用的软引用就行回收。

```java
public class T1 {
    private List list;
    private SoftReference sr;
    private ReferenceQueue rfq = new ReferenceQueue();
    //假设这里有个与redis连接的bean
    @Bean
    private RedisTemplate redis;

    public List getList(){
        if (sr.get() == null){
            //从redis中获取
            list = redis.getList();
            sr = new SoftReference(list,rfq);
            return list;
        }else {
            return (List)sr.get();
        }
    }

    //需要另起一个线程调用此方法清除无用的软引用
    public void clearCache(){
        SoftReference ref = null;
        while ((ref = (SoftReference)rfq.poll()) != null) {
            // 清除ref
        }
    }
}
```

- **弱引用**（Weak Reference）: 也是用来描述那些非必须对象，但是它的强度比软引用更弱一些，**被弱引用关联的对象只能生存到下一次垃圾收集发生为止**。当垃圾收集器开始工作，无论当前内存是否足够，都会回收掉只被弱引用关联的对象。在JDK 1.2版之后提供了 `WeakReference` 类来实现弱引用。

弱引用关联的对象是否回收取决于这个对象有没有其他强引用指向它，典型使用弱引用的案例就是 `WeakHashMap` 和 `ThreadLocal` 。

设计 WeakHashMap 类是为了解决一个有趣的问题。如果 map 中有一个值，对应的键已经不再使用了，将会出现什么情况呢？假定对某个键的最后一次引用已经消亡，不再有任何途径引用这个值的对象了。但是，由于在程序中的任何部分没有再出现这个键，所以，这个键/值对无法从 Map 中删除。为什么垃圾回收器不能够删除它呢？难道删除无用的对象不是垃圾回收器的工作吗？

遗憾的是，事情没有这样简单。垃圾回收器跟踪活动的对象。只要 Map 对象是活动的，其中的所有的键/值对也是活动的，因此它们不能被回收。所以需要由程序负责从长期存活的 Map 中删除那些无用的值。或者使用 WeakHashMap 完成这件事情。当对键的唯一引用来自 WeakHashMap 时， 这一数据结构将与垃圾回收器协同工作删除键/值对。

WeakHashMap 使用弱引用（weak references) 保存 key。 WeakReference 对象将引用保存到另外一个对象中，在这里就是散列键。对于这种类型的对象，垃圾回收器用一种特有的方式进行处理。通常如果垃圾回收器发现某个特定的对象已经没有他人引用了，就将其回收。然而，如果某个对象只能由 WeakReference 引用，垃圾回收器仍然回收它，但要将引用这个对象的弱引用放人队列中。WeakHashMap 将周期性地检查队列，以便找出新添加的弱引用。一个弱引用进人队列意味着这个键不再被他人使用，并且已经被收集起来。于是，WeakHashMap 将删除对应的条目。

- **虚引用**（Phantom Reference）: 也称为“幽灵引用”或者“幻影引用”，它是最弱的一种引用关系。一个对象是否有虚引用的存在，完全不会对其生存时间构成影响，**也无法通过虚引用来取得一个对象实例**。为一个对象设置虚引用关联的**唯一目的只是为了能在这个对象被收集器回收时收到一个系统通知**。在JDK 1.2版之后提供了 `PhantomReference` 类来实现虚引用。

jdk 中直接内存的回收就用到虚引用，由于 jvm 自动内存管理的范围是堆内存，而直接内存是在堆内存之外，所以直接内存的分配和回收都是有 Unsafe 类去操作，java 在申请一块直接内存之后，会在堆内存分配一个对象保存这个堆外内存的引用，这个对象被垃圾收集器管理，一旦这个对象被回收，相应的用户线程会收到通知并对直接内存进行清理工作。

**总结**

- 强引用：从来不会被回收
- 软引用：当内存不足时会被回收
- 弱引用：正常垃圾回收时回收
- 虚引用：任何时刻都会被垃圾回收器回收

## finalize() 

即使在可达性分析算法中判定为不可达的对象，也不是“非死不可”的，这时候它们暂时还处于“缓刑”阶段，要真正宣告一个对象死亡，**至少要经历两次标记过程**：如果对象在进行可达性分析后发现没有与GC Roots相连接的引用链，那它将会被第一次标记，随后进行一次筛选，筛选的条件是此对象是否有必要执行 `finalize()` 方法。**假如对象没有覆盖 `finalize()` 方法，或者 `finalize()` 方法已经被虚拟机调用过，那么虚拟机将这两种情况都视为“没有必要执行”**。

如果这个对象被判定为确有必要执行 `finalize()` 方法，那么该对象将会被放置在一个名为 F-Queue 的队列之中，并在稍后由一条由虚拟机自动建立的、低调度优先级的 `Finalizer` 线程去执行它们的 `finalize()` 方法。**这里所说的“执行”是指虚拟机会触发这个方法开始运行，但并不承诺一定会等待它运行结束。**这样做的原因是，如果某个对象的 `finalize()` 方法执行缓慢，或者更极端地发生了死循环，将很可能导致 F-Queue 队列中的其他对象永久处于等待，甚至导致整个内存回收子系统的崩溃。`finalize()` 方法是对象逃脱死亡命运的最后一次机会，稍后收集器将对 F-Queue 中的对象进行第二次小规模的标记，如果对象要在 `finalize()` 中成功拯救自己，只要重新与引用链上的任何一个对象建立关联即可，譬如把自己（this关键字）赋值给某个类变量或者对象的成员变量，那在第二次标记时它将被移出“即将回收”的集合；如果对象这时候还没有逃脱，那基本上它就真的要被回收了。

另外一个值得注意的地方就是，任何一个对象的 `finalize()` 方法都**只会被系统自动调用一次**，如果对象面临下一次回收，它的 `finalize()` 方法**不会被再次执行**。

## 方法区的回收

有些人认为方法区（如HotSpot虚拟机中的元空间或者永久代）是没有垃圾收集行为的，《Java虚拟机规范》中提到过可以不要求虚拟机在方法区中实现垃圾收集，事实上也确实有未实现或未能完整实现方法区类型卸载的收集器存在（如JDK 11时期的ZGC收集器就不支持类卸载），方法区垃圾收集的“性价比”通常也是比较低的：在Java堆中，尤其是在新生代中，对常规应用进行一次垃圾收集通常可以回收70%至99%的内存空间，相比之下，方法区回收囿于苛刻的判定条件，其区域垃圾收集的回收成果往往远低于此。

方法区的垃圾收集主要回收两部分内容：**废弃的常量**和**不再使用的类型**。

- **回收废弃常量** : 与回收Java堆中的对象非常类似。举个常量池中字面量回收的例子，假如一个字符串“java”曾经进入常量池中，但是当前系统又没有任何一个字符串对象的值是“java”，换句话说，已经没有任何字符串对象引用常量池中的“java”常量，且虚拟机中也没有其他地方引用这个字面量。如果在这时发生内存回收，而且垃圾收集器判断确有必要的话，这个“java”常量就将会被系统清理出常量池。常量池中其他类（接口）、方法、字段的符号引用也与此类似。

- **回收不再使用的类型** : 判定一个常量是否“废弃”还是相对简单，而要判定一个类型是否属于“不再被使用的类”的条件就比较苛刻了。需要同时满足下面三个条件：
  - 该类所有的实例都已经被回收，也就是 Java 堆中不存在该类及其任何派生子类的实例。
  - 加载该类的类加载器已经被回收，这个条件除非是经过精心设计的可替换类加载器的场景，如 OSGi、JSP 的重加载等，否则通常是很难达成的。
  - 该类对应的 java.lang.Class 对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。

Java 虚拟机被允许对满足上述三个条件的无用类进行回收，这里说的仅仅是“被允许”，而并不是和对象一样，没有引用了就必然会回收。关于是否要对类型进行回收，HotSpot 虚拟机提供了-Xnoclassgc 参数进行控制，还可以使用 -verbose：class 以及 -XX：+TraceClass-Loading、-XX：+TraceClassUnLoading 查看类加载和卸载信息，其中 -verbose：class 和 -XX：+TraceClassLoading 可以在 Product 版的虚拟机中使用，-XX：+TraceClassUnLoading 参数需要 FastDebug 版的虚拟机支持。

在大量使用反射、动态代理、CGLib 等字节码框架，动态生成 JSP 以及 OSGi 这类频繁自定义类加载器的场景中，通常都需要 Java 虚拟机具备类型卸载的能力，以保证不会对方法区造成过大的内存压力。

# 垃圾收集算法理论基础

从如何判定对象消亡的角度出发，垃圾收集算法可以划分为

- “引用计数式垃圾收集”（Reference Counting GC）也称作“直接垃圾收集”。
- “追踪式垃圾收集”（Tracing GC）也称作“间接垃圾收集”。

由于引用计数式垃圾收集算法在本书讨论到的主流 Java 虚拟机中均未涉及，所以我们暂不把它作为正文主要内容来讲解，本节介绍的所有算法均属于追踪式垃圾收集的范畴。

## 分代收集理论

当前商业虚拟机的垃圾收集器，大多数都遵循了“分代收集”（Generational Collection）的理论进行设计，分代收集名为理论，实质是一套符合大多数程序运行实际情况的经验法则，它建立在两个分代假说之上：

1. **弱分代假说**（Weak Generational Hypothesis）：绝大多数对象都是朝生夕灭的。
2. **强分代假说**（Strong Generational Hypothesis）：熬过越多次垃圾收集过程的对象就越难以消亡。

这两个分代假说共同奠定了多款常用的垃圾收集器的一致的设计原则：**收集器应该将Java堆划分出不同的区域，然后将回收对象依据其年龄（年龄即对象熬过垃圾收集过程的次数）分配到不同的区域之中存储**。

这么做的好处有两点

- **如果一个区域中大多数对象都是朝生夕灭，难以熬过垃圾收集过程的话，那么把它们集中放在一起，每次回收时只关注如何保留少量存活而不是去标记那些大量将要被回收的对象，就能以较低代价回收到大量的空间；**
- **如果剩下的都是难以消亡的对象，那把它们集中放在一块，虚拟机便可以使用较低的频率来回收这个区域，这就同时兼顾了垃圾收集的时间开销和内存的空间有效利用。**

在 Java 堆划分出不同的区域之后，垃圾收集器才可以每次只回收其中某一个或者某些部分的区域 ———— 因而才有了 “Minor GC”“Major GC”“Full GC” 这样的回收类型的划分；也才能够针对不同的区域安排与里面存储对象存亡特征相匹配的垃圾收集算法 ———— 因而发展出了“标记-复制算法”“标记-清除算法”“标记-整理算法”等针对性的垃圾收集算法。

把分代收集理论具体放到现在的商用 Java 虚拟机里，设计者一般至少会把Java堆划分为**新生代（Young Generation）**和**老年代（Old Generation）**两个区域。顾名思义，在新生代中，每次垃圾收集时都发现有大批对象死去，而每次回收后存活的少量对象，将会逐步晋升到老年代中存放。

事实上，分代收集并非只是简单划分一下内存区域那么容易，它至少存在一个明显的困难：对象不是孤立的，对象之间会存在跨代引用。假如要现在进行一次只局限于新生代区域内的收集（Minor GC），但新生代中的对象是完全有可能被老年代所引用的，为了找出该区域中的存活对象，不得不在固定的 GC Roots 之外，再额外遍历整个老年代中所有对象来确保可达性分析结果的正确性，反过来也是一样。遍历整个老年代所有对象的方案虽然理论上可行，但无疑会为内存回收带来很大的性能负担。为了解决这个问题，就需要对分代收集理论添加第三条经验法则：

3. **跨代引用假说**（Intergenerational Reference Hypothesis）：跨代引用相对于同代引用来说仅占极少数。

这其实是可根据前两条假说逻辑推理得出的隐含推论：存在互相引用关系的两个对象，是应该倾向于同时生存或者同时消亡的。举个例子，如果某个新生代对象存在跨代引用，由于老年代对象难以消亡，该引用会使得新生代对象在收集时同样得以存活，进而在年龄增长之后晋升到老年代中，这时跨代引用也随即被消除了。

依据这条假说，我们就不应再为了少量的跨代引用去扫描整个老年代，也不必浪费空间专门记录每一个对象是否存在及存在哪些跨代引用，只需在新生代上建立一个全局的数据结构（该结构被称为“记忆集”，Remembered Set），这个结构把老年代划分成若干小块，标识出老年代的哪一块内存会存在跨代引用。此后当发生 Minor GC 时，只有包含了跨代引用的小块内存里的对象才会被加入到 GCRoots 进行扫描。虽然这种方法需要在对象改变引用关系（如将自己或者某个属性赋值）时维护记录数据的正确性，会增加一些运行时的开销，但比起收集时扫描整个老年代来说仍然是划算的。

关于垃圾收集的一些名词信息：

- 部分收集（Partial GC）：指目标不是完整收集整个Java堆的垃圾收集，其中又分为：
  - 新生代收集（Minor GC/Young GC）：指目标只是新生代的垃圾收集。
  - 老年代收集（Major GC/Old GC）：指目标只是老年代的垃圾收集。目前只有CMS收集器会有单独收集老年代的行为。另外请注意“Major GC”这个说法现在有点混淆，在不同资料上常有不同所指，读者需按上下文区分到底是指老年代的收集还是整堆收集。
  - 混合收集（Mixed GC）：指目标是收集整个新生代以及部分老年代的垃圾收集。目前只有G1收集器会有这种行为。
- 整堆收集（Full GC）：收集整个Java堆和方法区的垃圾收集。

## 标记-清除算法

最早出现也是最基础的垃圾收集算法是“标记-清除”（Mark-Sweep）算法，算法分为“标记”和“清除”两个阶段：首先标记出所有需要回收的对象，在标记完后，统一回收掉所有被标记的对象，也可以反过来，标记存活的对象，统一回收所有未被标记的对象。标记过程就是对象是否属于垃圾的判定过程。

之所以说它是最基础的收集算法，是因为后续的收集算法大多都是以标记-清除算法为基础，对其缺点进行改进而得到的。它的主要缺点有两个：

- 执行效率不稳定，如果Java堆中包含大量对象，而且其中大部分是需要被回收的，这时必须进行大量标记和清除的动作，导致标记和清除两个过程的执行效率都随对象数量增长而降低；
- 内存空间的碎片化问题，标记、清除之后会产生大量不连续的内存碎片，空间碎片太多可能会导致当以后在程序运行过程中需要分配较大对象时无法找到足够的连续内存而不得不提前触发另一次垃圾收集动作。

![](https://raw.githubusercontent.com/MrSunflowers/images/main/note/spring/202204131126933.png)

## 新生代收集算法

上文已经讲过，**如果一个区域中大多数对象都是朝生夕灭，难以熬过垃圾收集过程的话，那么把它们集中放在一起，每次回收时只关注如何保留少量存活而不是去标记那些大量将要被回收的对象，就能以较低代价回收到大量的空间；** 这个空间指的就是新生代，正是因为新生代的这一特点，针对新生代的优化算法就出现了：标记-复制算法

### 标记-复制算法

#### 半区复制

标记-复制算法常被简称为复制算法。为了解决标记-清除算法面对大量可回收对象时执行效率低的问题，1969 年 Fenichel 提出了一种称为“半区复制”（Semispace Copying）的垃圾收集算法，**它将可用内存按容量划分为大小相等的两块，每次只使用其中的一块**。当这一块的内存用完了，就将还存活着的对象复制到另外一块上面，然后再把已使用过的内存空间一次清理掉。如果内存中多数对象都是存活的，这种算法将会产生大量的内存间复制的开销，但对于多数对象都是可回收的情况，算法需要复制的就是占少数的存活对象，而且每次都是针对整个半区进行内存回收，分配内存时也就不用考虑有空间碎片的复杂情况，只要移动堆顶指针，按顺序分配即可。这样实现简单，运行高效，不过其缺陷也显而易见，这种复制回收算法的代价是将可用内存缩小为了原来的一半，空间浪费未免太多了一点。

![](https://raw.githubusercontent.com/MrSunflowers/images/main/note/spring/202204131129593.png)

现在的商用Java虚拟机大多都优先采用了这种收集算法去回收新生代，IBM 公司曾有一项专门研究对新生代“朝生夕灭”的特点做了更量化的诠释————新生代中的对象有98%熬不过第一轮收集。因此并不需要按照1∶1的比例来划分新生代的内存空间。

#### Appel 式回收

在1989年，Andrew Appel 针对具备“朝生夕灭”特点的对象，提出了一种更优化的半区复制分代策略，现在称为“Appel式回收”。**HotSpot 虚拟机的 Serial、ParNew 等新生代收集器均采用了这种策略来设计新生代的内存布局**。

Appel 式回收的具体做法是把新生代分为一块较大的 Eden 空间和两块较小的 Survivor 空间，每次分配内存只使用 Eden 和其中一块 Survivor。发生垃圾回收时，将 Eden 和 Survivor 中仍然存活的对象一次性复制到另外一块 Survivor 空间上，然后直接清理掉 Eden 和已用过的那块 Survivor 空间。

HotSpot 虚拟机默认 Eden 和 Survivor 的大小比例是 8∶1，也即每次新生代中可用内存空间为整个新生代容量的 90%（Eden的80%加上一个Survivor的10%），只有一个 Survivor 空间，即 10% 的新生代是会被“浪费”的。

当然，98% 的对象可被回收仅仅是“普通场景”下测得的数据，任何人都没有办法百分百保证每次回收都只有不多于 10% 的对象存活，因此 Appel 式回收还有一个充当罕见情况的“逃生门”的安全设计，当 Survivor 空间不足以容纳一次 Minor GC之后存活的对象时，就需要依赖其他内存区域（实际上大多就是老年代）进行分配担保（Handle Promotion）。

内存的分配担保好比我们去银行借款，如果我们信誉很好，在 98% 的情况下都能按时偿还，于是银行可能会默认我们下一次也能按时按量地偿还贷款，只需要有一个担保人能保证如果我不能还款时，可以从他的账户扣钱，那银行就认为没有什么风险了。内存的分配担保也一样，如果另外一块 Survivor 空间没有足够空间存放上一次新生代收集下来的存活对象，这些对象便将通过分配担保机制直接进入老年代，这对虚拟机来说就是安全的。

#### 算法细节

而对于把新生代分为一块较大的 Eden 空间和两块较小的 Survivor 空间的空间分配方式则是由于算法实现决定的

1. **减少复制开销**：在复制算法中，每次垃圾回收时，存活的对象需要被复制到新的空间。如果只有一块Survivor空间，那么在每次垃圾回收后，存活的对象都需要被复制到这块Survivor空间中。如果有两块Survivor空间，那么在垃圾回收时，可以将存活的对象复制到其中一块Survivor空间中，而另一块Survivor空间则可以作为下一次垃圾回收时的复制目标。这样，每次垃圾回收时，只需要复制一半的存活对象，从而减少了复制开销。

2. **提高内存利用率**：如果只有一块Survivor空间，那么在垃圾回收后，这块空间中会有一半是空闲的，而Eden空间则完全被清空。这样，新生代的总可用空间只有Eden空间加上一半的Survivor空间。如果有两块Survivor空间，那么在垃圾回收后，Eden空间和一块Survivor空间被清空，而另一块Survivor空间则可以继续使用。这样，新生代的总可用空间可以达到Eden空间加上一块Survivor空间的大小，提高了内存利用率。

3. **减少内存碎片**：如果只有一块Survivor空间，那么在垃圾回收后，这块空间可能会因为对象的复制而产生内存碎片。如果有两块Survivor空间，那么在垃圾回收时，可以将存活的对象复制到一块Survivor空间中，而另一块Survivor空间则可以保持连续的内存空间，从而减少了内存碎片。

4. **优化对象分配**：在垃圾回收后，Eden空间和一块Survivor空间被清空，可以作为新的对象分配空间。这样，对象分配时可以直接在Eden空间中分配，如果Eden空间不足，再考虑在Survivor空间中分配。这种分配策略可以减少内存分配的复杂性，提高分配效率。

在复制算法中，新生代的内存空间被划分为Eden区和Survivor区。Eden区是对象主要的分配区域，而Survivor区则用于存放经过垃圾回收后仍然存活的对象。在HotSpot虚拟机中，通常会设置两个Survivor区，称为From Survivor和To Survivor。

复制算法的基本步骤如下：

1. **对象分配**：新创建的对象首先被分配到Eden区。如果Eden区满了，就会触发Minor GC（新生代垃圾回收）。

2. **垃圾回收**：在Minor GC过程中，虚拟机会遍历Eden区和From Survivor区中的所有对象，标记出存活的对象。

3. **对象复制**：将标记为存活的对象复制到To Survivor区。如果To Survivor区空间不足，存活的对象会被直接复制到老年代。

4. **空间交换**：复制完成后，Eden区和From Survivor区会被清空，**然后交换From Survivor和To Survivor的角色**，即原本的To Survivor成为新的From Survivor，而原本的 From Survivor 区则成为新的 To Survivor 区。此时，在上一次 GC 后存活的对象就保存到了 From Survivor 区中，等待下一次 GC 的遍历和标记，而 To Survivor 则已经被清空了。

5. **晋升策略**：经过多次Minor GC后，如果对象仍然存活，它会被晋升到老年代。晋升的条件通常**包括对象的年龄（经历的Minor GC次数）达到一定阈值，或者Survivor区空间不足**。

如果只有一块Survivor区，那么在每次垃圾回收后，所有存活的对象都需要被复制到这块Survivor区中。这意味着每次垃圾回收时，都需要复制所有存活的对象，这会增加复制的开销，尤其是当存活对象较多时。

然而，使用两块Survivor区可以显著减少复制开销。在垃圾回收时，可以将存活的对象复制到一块Survivor区（例如To Survivor），而另一块Survivor区（例如From Survivor）则可以作为下一次垃圾回收时的复制目标。这样，每次垃圾回收时，只需要复制一半的存活对象，从而减少了复制开销。

这种策略不仅减少了复制开销，还提高了内存的使用效率，因为每次垃圾回收后，Eden区和一块Survivor区会被清空，可以立即用于新的对象分配，而另一块Survivor区则用于存放存活的对象。这种设计使得新生代的垃圾回收更加高效，同时减少了对应用程序性能的影响。

## 老年代收集算法

同样的，在**如果剩下的都是难以消亡的对象，那把它们集中放在一块，虚拟机便可以使用较低的频率来回收这个区域，这就同时兼顾了垃圾收集的时间开销和内存的空间有效利用。** 的思路的指导下，衍生出了针对老年代收集算法：标记-整理算法

### 标记-整理算法

标记-复制算法在对象存活率较高时就要进行较多的复制操作，效率将会降低。更关键的是，如果不想浪费50%的空间，就需要有额外的空间进行分配担保，以应对被使用的内存中所有对象都100%存活的极端情况，所以在老年代一般不能直接选用这种算法。

针对老年代对象的存亡特征，1974 年 Edward Lueders 提出了另外一种有针对性的“标记-整理”（Mark-Compact）算法，其中的标记过程仍然与“标记-清除”算法一样，但后续步骤不是直接对可回收对象进行清理，而是**让所有存活的对象都向内存空间一端移动**，然后直接清理掉边界以外的内存。

标记-清除算法与标记-整理算法的本质差异在于前者是一种非移动式的回收算法，而后者是移动式的。是否移动回收后的存活对象是一项优缺点并存的风险决策：

![](https://raw.githubusercontent.com/MrSunflowers/images/main/note/spring/202204131348393.png)

如果移动存活对象，尤其是在老年代这种每次回收都有大量对象存活区域，**移动存活对象并更新所有引用这些对象的地方将会是一种极为负重的操作，而且这种对象移动操作必须全程暂停用户应用程序才能进行**，这就更加让使用者不得不小心翼翼地权衡其弊端了，像这样的停顿被最初的虚拟机设计者形象地描述为“Stop The World”。

但如果跟标记-清除算法那样完全不考虑移动和整理存活对象的话，弥散于堆中的存活对象导致的空间碎片化问题就只能依赖更为复杂的内存分配器和内存访问器来解决。譬如通过“分区空闲分配链表”来解决内存分配问题（计算机硬盘存储大文件就不要求物理连续的磁盘空间，能够在碎片化的硬盘上存储和访问就是通过硬盘分区表实现的）。内存的访问是用户程序最频繁的操作，甚至都没有之一，假如在这个环节上增加了额外的负担，势必会直接影响应用程序的吞吐量。

基于以上两点，是否移动对象都存在弊端，移动则内存回收时会更复杂，不移动则内存分配时会更复杂。从垃圾收集的停顿时间来看，不移动对象停顿时间会更短，甚至可以不需要停顿，但是从整个程序的吞吐量来看，移动对象会更划算。此语境中，吞吐量的实质是赋值器与收集器的效率总和。即使不移动对象会使得收集器的效率提升一些，但因内存分配和访问相比垃圾收集频率要高得多，这部分的耗时增加，总吞吐量仍然是下降的。

HotSpot 虚拟机里面关注吞吐量的 Parallel Scavenge 收集器是基于标记-整理算法的，而关注延迟的 CMS 收集器则是基于标记-清除算法的，这也从侧面印证这点。

另外，还有一种“和稀泥式”解决方案可以不在内存分配和访问上增加太大额外负担，做法是让虚拟机平时多数时间都采用标记-清除算法，暂时容忍内存碎片的存在，直到内存空间的碎片化程度已经大到影响对象分配时，再采用标记-整理算法收集一次，以获得规整的内存空间。前面提到的基于标记-清除算法的 CMS 收集器面临空间碎片过多时采用的就是这种处理办法。

# 经典垃圾收集器

## Serial 收集器

Serial收集器是Java虚拟机（JVM）中最早出现的垃圾收集器之一，它采用单线程进行垃圾收集工作。在JDK 1.3.1之前，是 HotSpot 虚拟机新生代垃圾收集的唯一选择。Serial收集器的"单线程"特性意味着在垃圾收集期间，它会暂停所有其他工作线程（Stop-The-World，STW），这在多线程应用中可能会导致应用响应时间的显著下降。

但事实上，迄今为止，它依然是HotSpot虚拟机运行在客户端模式下的默认新生代收集器，有着优于其他收集器的地方，那就是简单而高效（与其他收集器的单线程相比），对于内存资源受限的环境，它**是所有收集器里额外内存消耗（Memory Footprint）最小的**；对于单核处理器或处理器核心数较少的环境来说，Serial收集器由于没有线程交互的开销，专心做垃圾收集自然可以获得最高的单线程收集效率。在用户桌面的应用场景以及近年来流行的部分微服务应用中，分配给虚拟机管理的内存一般来说并不会特别大，收集几十兆甚至一两百兆的新生代（仅仅是指新生代使用的内存，桌面应用甚少超过这个容量），垃圾收集的停顿时间完全可以控制在十几、几十毫秒，最多一百多毫秒以内，只要不是频繁发生收集，这点停顿时间对许多用户来说是完全可以接受的。所以，**Serial收集器对于运行在客户端模式下的虚拟机来说是一个很好的选择**。

![1719473948924.png](https://raw.githubusercontent.com/MrSunflowers/images/main/note/images/1719473948924.png)

**适用场景**：

1. **客户端模式**：在JVM的客户端模式下，Serial收集器是默认的新生代收集器。客户端模式通常用于桌面应用程序，这些应用程序通常运行在资源受限的环境中，如内存和处理器资源有限。

2. **内存资源受限的环境**：在内存资源受限的环境中，Serial收集器由于其较小的内存占用和单线程的高效性，可以提供较好的性能。

3. **单核处理器**：在单核处理器的系统上，由于没有线程间通信的开销，Serial收集器可以提供较高的垃圾收集效率。

## ParNew收集器


















































































